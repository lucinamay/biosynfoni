{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "\n",
    "from biosynfoni.moldrawing import draw, _get_highlight_loc_and_col\n",
    "\n",
    "\n",
    "colourDict = {\n",
    "    \"taxonomy\": {\n",
    "        \"Viridiplantae\": \"#B9C311\",  # green\n",
    "        \"Bacteria\": \"#9BC2BA\",  # teal\n",
    "        \"Fungi\": \"#CFC0D6\",  # purple\n",
    "        \"Metazoa\": \"#FFAD61\",  # light orange\n",
    "        \"Archaea\": \"#EB6737\",  # soft red\n",
    "        \"Eukaryota\": \"#D2CEC4\",  # pale grey\n",
    "        \"Cellular organisms\": \"#FFEAA0\",  # yellow\n",
    "        \"Opisthokonta\": \"#FFC4CE\",  # pink\n",
    "    },\n",
    "    \"separation\": {\n",
    "        \"1\": \"#081d58\",  #'#57BAC0',  # navy,\n",
    "        \"2\": \"#225ea8\",  #'#77BC4D',  # royal blue,\n",
    "        \"3\": \"#41b6c4\",  #'#F3C55F',  # teal,\n",
    "        \"4\": \"#7fcdbb\",  #'#F48861',  # turquoise,\n",
    "        \"5\": \"#c7e9b4\",  #'#F7A8B8',  # lemon green,\n",
    "        \"6\": \"#edf8b1\",  #'#F9CDAE',  # pale green,\n",
    "        \"7\": \"#FFEAA0\",  # yellow\n",
    "        \"8\": \"#FF8B61\",  # orange\n",
    "        # \"-1\": \"#c7e9b4\",  #'#797979',  # lemon green,\n",
    "        \"-1\": \"#797979\",  #'#797979',  # grey,\n",
    "        \"random pairs\": \"#c7e9b4\",\n",
    "        \"control\": \"#c7e9b4\",\n",
    "    },\n",
    "    \"pathways\": {\n",
    "        \"shikimate\": \"#A783B6\",  # purple\n",
    "        \"acetate\": \"#FF8B61\",  # orange,\n",
    "        \"mevalonate\": \"#B9C311\",  # green,\n",
    "        \"methylerythritol\": \"#6FB5C6\",  # blue\n",
    "        \"sugar\": \"#FFC4CE\",  # pink\n",
    "        \"amino\": \"#FFEAA0\",  # yellow\n",
    "        \"amino_acid\": \"#FFEAA0\",  # yellow\n",
    "    },\n",
    "    \"class\": {\n",
    "        # \"Terpenoids\": \"#9BC2BA\",  # soft bluegreen\n",
    "        \"Terpenoids\": \"#B9C311\",  # green\n",
    "        \"Alkaloids\": \"#B4CAD8\",  # purple\n",
    "        \"Shikimates and Phenylpropanoids\": \"#A783B6\",  # purple\n",
    "        \"Fatty acids\": \"#FF8B61\",  # orange\n",
    "        \"Carbohydrates\": \"#FFC4CE\",  # pink\n",
    "        \"Polyketides\": \"#C21100\",  # soft red\n",
    "        \"Amino acids and Peptides\": \"#FFEAA0\",  # yellow\n",
    "        \"No NP-Classifier prediction\": \"#797979\",\n",
    "        \"None\": \"#595959\",\n",
    "        \"Synthetic\": \"#393939\",\n",
    "        \"Multiple\": \"#BBBBBB\",\n",
    "        # lowercase\n",
    "        # \"terpenoids\": \"#9BC2BA\",  # soft bluegreen\n",
    "        \"terpenoids\": \"#B9C311\",  # green\n",
    "        \"alkaloids\": \"#B4CAD8\",  # purple\n",
    "        \"shikimates and phenylpropanoids\": \"#A783B6\",  # purple\n",
    "        \"fatty acids\": \"#FF8B61\",  # orange\n",
    "        \"carbohydrates\": \"#FFC4CE\",  # pink\n",
    "        \"polyketides\": \"#C21100\",  # soft red\n",
    "        \"amino acids and peptides\": \"#FFEAA0\",  # yellow\n",
    "        # chebi:\n",
    "        \"phenylpropanoid\": \"#A783B6\",  # purple\n",
    "        \"fatty_acid\": \"#FF8B61\",  # orange\n",
    "        \"polyketide\": \"#C21100\",  # soft red\n",
    "        \"alkaloid\": \"#B4CAD8\",  # purple\n",
    "        # \"isoprenoid\": \"#9BC2BA\",  # soft bluegreen\n",
    "        \"isoprenoid\": \"#B9C311\",  # green\n",
    "        \"carbohydrate\": \"#FFC4CE\",  # pink\n",
    "        \"amino_acid\": \"#FFEAA0\",  # yellow\n",
    "        \"synthetic\": \"#393939\",  # grey\n",
    "    },\n",
    "    \"NPClassifier prediction\": {\n",
    "        \"Terpenoids\": \"#B9C311\",  # green\n",
    "        \"Alkaloids\": \"#B4CAD8\",  # purple\n",
    "        \"Shikimates and Phenylpropanoids\": \"#A783B6\",  # purple\n",
    "        \"Fatty acids\": \"#FF8B61\",  # orange\n",
    "        \"Carbohydrates\": \"#FFC4CE\",  # pink\n",
    "        \"Polyketides\": \"#C21100\",  # soft red\n",
    "        \"Amino acids and Peptides\": \"#FFEAA0\",  # yellow\n",
    "        \"No NP-Classifier prediction\": \"#797979\",\n",
    "        \"None\": \"#595959\",\n",
    "        \"Synthetic\": \"#393939\",\n",
    "        \"Multiple\": \"#BBBBBB\",\n",
    "    },\n",
    "    \"chebi class\": {\n",
    "        \"phenylpropanoid\": \"#A783B6\",  # purple\n",
    "        \"fatty_acid\": \"#FF8B61\",  # orange\n",
    "        \"polyketide\": \"#C21100\",  # soft red\n",
    "        \"alkaloid\": \"#B4CAD8\",  # purple\n",
    "        # \"isoprenoid\": \"#9BC2BA\",  # soft bluegreen\n",
    "        \"isoprenoid\": \"#B9C311\",  # green\n",
    "        \"carbohydrate\": \"#FFC4CE\",  # pink\n",
    "        \"amino_acid\": \"#FFEAA0\",  # yellow\n",
    "        \"synthetic\": \"#393939\",  # grey\n",
    "    },\n",
    "}\n",
    "\n",
    "# set the biosynfoni style\n",
    "plt.style.use(\"biostylefoni.mplstyle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1: fingerprint example, pathway similarity example, biosynthetic distance results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## biosynthetic distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanfmt(text):\n",
    "    \"\"\"\n",
    "    Clean a string or list of strings to be used as labels in a plot\n",
    "\n",
    "        Args:\n",
    "            text (str or list): text to clean\n",
    "\n",
    "        Returns:\n",
    "            str or list: cleaned text\n",
    "\n",
    "    Remarks:\n",
    "        - replaces underscores with spaces\n",
    "        - makes all text lowercase\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text.replace(\"_\", \" \").lower()\n",
    "    elif isinstance(text, list):\n",
    "        newtext = []\n",
    "        for t in text:\n",
    "            if isinstance(t, str):\n",
    "                newtext.append(t.replace(\"_\", \" \").lower())\n",
    "            else:\n",
    "                newtext.append(t)\n",
    "        return newtext\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n",
    "def _set_ax_boxplot_i_colour(\n",
    "    ax_boxplot: mpl.container.BarContainer,\n",
    "    i: int,\n",
    "    colour: str,\n",
    "    inner_alpha: float = 0.6,\n",
    "):\n",
    "    \"\"\"\n",
    "    Set the colour of a boxplot element\n",
    "\n",
    "        Args:\n",
    "            ax_boxplot (matplotlib.container.BarContainer): the boxplot to change\n",
    "            i (int): the index of the element to change\n",
    "            colour (str): the colour to change to\n",
    "            inner_alpha (float): the alpha of the inner colour, optional. Default is 0.6\n",
    "\n",
    "        Returns:\n",
    "            matplotlib.container.BarContainer: the changed boxplot\n",
    "\n",
    "    \"\"\"\n",
    "    translucent = mpl.colors.to_rgba(colour, inner_alpha)\n",
    "\n",
    "    ax_boxplot[\"boxes\"][i].set_facecolor(translucent)\n",
    "    ax_boxplot[\"boxes\"][i].set_edgecolor(colour)\n",
    "    ax_boxplot[\"medians\"][i].set_color(colour)\n",
    "    ax_boxplot[\"whiskers\"][i * 2].set_color(colour)\n",
    "    ax_boxplot[\"whiskers\"][i * 2 + 1].set_color(colour)\n",
    "    ax_boxplot[\"caps\"][i * 2].set_color(colour)\n",
    "    ax_boxplot[\"caps\"][i * 2 + 1].set_color(colour)\n",
    "    ax_boxplot[\"fliers\"][i].set_markeredgecolor(translucent)\n",
    "    return ax_boxplot\n",
    "\n",
    "\n",
    "def scatter_boxplots(\n",
    "    df: pd.DataFrame,\n",
    "    col_x: str,\n",
    "    col_y: str,\n",
    "    color_by: str = \"stepnum\",\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Make a scatterplot with boxplots on the axes\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): dataframe to plot\n",
    "            col_x (str): column to plot on the x-axis\n",
    "            col_y (str): column to plot on the y-axis\n",
    "            figtitle (str): title of the figure\n",
    "            color_by (str): column to colour by, optional. Default is \"stepnum\"\n",
    "            *args: other arguments to pass to scatterplot\n",
    "            **kwargs: other keyword arguments to pass to scatterplot\n",
    "        Returns:\n",
    "            plt.Figure: the figure\n",
    "\n",
    "    \"\"\"\n",
    "    # make a square figure\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    # fig, ax = plt.subplots()\n",
    "    # add gridspec for subplots\n",
    "\n",
    "    gs = fig.add_gridspec(\n",
    "        2,\n",
    "        2,\n",
    "        # width_ratios=(4, 1),\n",
    "        # height_ratios=(1, 4),\n",
    "        # left=0.1, right=0.9, bottom=0.1, top=0.9,\n",
    "        wspace=-1,\n",
    "        # hspace=-5,\n",
    "    )\n",
    "\n",
    "    sc_ax = fig.add_subplot(gs[1, 0])\n",
    "    legax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    # Set aspect of the Axes manually to have points on 0 and 1 show better\n",
    "    # ax.set_xlim(-0.05, 1.05)\n",
    "    # ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "    # Get Data\n",
    "    all_data_x = [\n",
    "        np.array(df[df[color_by] == category][col_x].to_numpy(dtype=float))\n",
    "        for category in df[color_by].unique()\n",
    "    ]\n",
    "    all_data_x = [x[~np.isnan(x)] for x in all_data_x]\n",
    "    all_data_y = [\n",
    "        np.array(df[df[color_by] == category][col_y].tolist())\n",
    "        for category in df[color_by].unique()\n",
    "    ]\n",
    "    all_data_y = [y[~np.isnan(y)] for y in all_data_y]\n",
    "\n",
    "\n",
    "    top_bp_ax = fig.add_subplot(gs[0, 0], sharex=sc_ax)\n",
    "    right_bp_ax = fig.add_subplot(gs[1, 1], sharey=sc_ax)\n",
    "\n",
    "\n",
    "    top_bp_ax.tick_params(length=0, labelbottom=False, labelsize=5)\n",
    "    right_bp_ax.tick_params(length=0, labelrotation=-30, labelleft=False, labelsize=5)\n",
    "    legax.tick_params(length=0, labelleft=False, labelbottom=False, labelsize=0)\n",
    "    sc_ax.tick_params(length=0)\n",
    "\n",
    "    labels = [\n",
    "        f\"{category}\" if category != \"-1\" else \"control\"\n",
    "        for category in df[color_by].unique()\n",
    "    ]\n",
    "    # make boxplots where the boxes are 5px apart\n",
    "    xplot = top_bp_ax.boxplot(all_data_x, vert=False, patch_artist=True, labels=labels, positions=[0.6*i for i in range(len(all_data_x))])\n",
    "    yplot = right_bp_ax.boxplot(all_data_y, vert=True, patch_artist=True, labels=labels, positions=[0.6*i for i in range(len(all_data_y))])\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for category in df[color_by].unique()[::-1]:\n",
    "        colour = colourDict[color_by][category]\n",
    "\n",
    "        label = f\"{category}\" if category != \"-1\" else \"random pairs\"\n",
    "\n",
    "        scatterplot = sc_ax.scatter(\n",
    "            x=col_x,\n",
    "            y=col_y,\n",
    "            data=df[df[color_by] == category],\n",
    "            c=colour,\n",
    "            label=label,\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"none\",\n",
    "            zorder=3,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    for category in df[color_by].unique():\n",
    "        colour = colourDict[color_by][category]\n",
    "        alpha = 0.6\n",
    "        _set_ax_boxplot_i_colour(xplot, i, colour, inner_alpha=alpha)\n",
    "        _set_ax_boxplot_i_colour(yplot, i, colour, inner_alpha=alpha)\n",
    "        label = f\"{category}\" if category != \"-1\" else \"random pairs\"\n",
    "\n",
    "        # scatter empty df, to get legend in right format in right position\n",
    "        leg = legax.scatter(\n",
    "            x=col_x,\n",
    "            y=col_y,\n",
    "            data=df[df[color_by] == category][0:0],\n",
    "            c=colour,\n",
    "            label=label,\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"none\",\n",
    "            s=10,\n",
    "        )\n",
    "        leg.set_facecolor(mpl.colors.to_rgba(colour, alpha=alpha))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # ==================================================\n",
    "\n",
    "    legax.legend(loc=\"lower left\", prop={\"size\": 6}, frameon=False)\n",
    "\n",
    "    # # info for square drawing\n",
    "    # squareside = 0.2\n",
    "    # s_color = \"#7A7979AA\"\n",
    "    # s_color = mpl.colors.to_rgba(\"#7A7979AA\", alpha=0.3)\n",
    "    # linewidth = 1\n",
    "\n",
    "    # ax.set_xticklabels([0,0.2,0.4,0.6,0.8,1.0])\n",
    "    sc_ax.set_xlabel(cleanfmt(col_x), labelpad=10)\n",
    "    sc_ax.set_ylabel(cleanfmt(col_y), labelpad=10)\n",
    "    # ax_xobs[0].set_title(figtitle, loc=\"center\", pad=20)\n",
    "\n",
    "    sc_ax.grid(True, alpha=0.3, linewidth=0.5, mouseover=True)\n",
    "    gs.tight_layout(fig)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/output/biosynthetic_distances.tsv\", sep=\"\\t\"\n",
    ")  # , index_col=0)\n",
    "df.separation = df.separation.astype(str).replace(\"control\", \"-1\")\n",
    "\n",
    "fig = scatter_boxplots(\n",
    "    df,\n",
    "    \"bsf\",\n",
    "    \"maccs\",\n",
    "    color_by=\"separation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.bsf < 0.2) & (df.separation==\"1\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # scatter = scatter_boxplots(\n",
    "# #             df,\n",
    "# #             col_x=\"bsf\",\n",
    "# #             col_y=\"maccs\",\n",
    "# #             figtitle=f\"Tanimoto for different reaction step numbers\",\n",
    "# #             color_by=\"separation\",\n",
    "# #         )\n",
    "\n",
    "# palette = \"mako\"\n",
    "# # df = df[df.separation != -1]\n",
    "# # df.replace(-1, 100, inplace=True)\n",
    "# # df = df[df.separation <= 4]\n",
    "\n",
    "\n",
    "# sns.scatterplot(data=df, x=\"bsf\", y=\"maccs\", hue='separation', palette=palette, alpha=0.7, edgecolor='none',s=7)\n",
    "# # add diagonal line\n",
    "# plt.plot([0,1], [0,1], color='black', linestyle='--')\n",
    "# # add the center of gravity per separation\n",
    "# for i,sep in enumerate(df.separation.unique()):\n",
    "#     color = sns.color_palette(palette, n_colors=len(df.separation.unique()))[i]\n",
    "#     if sep == -1:\n",
    "#         color = 'pink'\n",
    "#     # add center of gravity and std in y and x direction\n",
    "#     plt.plot(df[df.separation == sep].bsf.mean(), df[df.separation == sep].maccs.mean(), '*', color=color, markersize=15, label=f'sep {sep}')\n",
    "#     # add std to both sides\n",
    "#     plt.plot([df[df.separation == sep].bsf.mean()-df[df.separation == sep].bsf.std(), df[df.separation == sep].bsf.mean()+df[df.separation == sep].bsf.std()],\n",
    "#              [df[df.separation == sep].maccs.mean(), df[df.separation == sep].maccs.mean()], color=color, linestyle='-', linewidth=1)\n",
    "#     plt.plot([df[df.separation == sep].bsf.mean(), df[df.separation == sep].bsf.mean()],\n",
    "#                 [df[df.separation == sep].maccs.mean()-df[df.separation == sep].maccs.std(), df[df.separation == sep].maccs.mean()+df[df.separation == sep].maccs.std()], color=color, linestyle='-', linewidth=1)\n",
    "\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pathway visualisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pathway reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{Path().home()}/article_bsf/output/reconstructed_pathways.tsv\",sep=\"\\t\", header=0,index_col=0)\n",
    "# read in lists as lists\n",
    "import ast\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if not pd.isna(x) else x)\n",
    "# find where bsf_independent is same as true but maccs_independent is different\n",
    "\n",
    "df[\"true_r\"] = df[\"true\"].apply(lambda x: x[::-1])\n",
    "\n",
    "for key, val in {\"bsf\":\"biosynfoni\", \"maccs\": \"maccs\", \"rdk\":\"rdkit\", \"morgan\":\"morgan\"}.items():\n",
    "    print(val, \"independent: \", df[(df[f\"{key}_independent\"] == df.true )| (df[f\"{key}_independent\"] == df.true_r)].index.tolist())\n",
    "    print(val,\"with hint: \", df[(df[f\"{key}_f_start\"] == df.true) | (df[f\"{key}_f_end\"] == df.true)].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"true\"] = df[\"true\"].apply(ast.literal_eval)\n",
    "len(df.loc['PWY-8133'].true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the pathway\n",
    "from rdkit import Chem\n",
    "\n",
    "id_to_mol = {mol.GetProp(\"compound_id\"): mol for mol in Chem.SDMolSupplier(f'{Path().home()}/article_bsf/data/input/metacyc.sdf')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pws = ['PWY-6915', 'PWY-7135', 'PWY-7483', 'PWY-7711', 'PWY-7736', 'PWY-8133', 'PWY2DNV-5']\n",
    "compare = ['bsf_f_start', 'rdk_f_start']\n",
    "# for pw in pws[1:]:\n",
    "for pw in pws[0:]:\n",
    "    mols = [id_to_mol[cpd] for cpd in df.loc[pw].true]\n",
    "    # draw mols to grid\n",
    "    print(*[id_ for id_ in zip(df.loc[pw].true, df.loc[pw][compare[0]], df.loc[pw][compare[1]])], sep='\\n')\n",
    "    break\n",
    "Chem.Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(200,200), legends=[mol.GetProp(\"_Name\") for mol in mols])\n",
    "# get similarities between the mols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fingerprint example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biosynfoni import draw_with_highlights\n",
    "\n",
    "mols = \n",
    "draw_with_highlights(mols,  legends=[mol.GetProp(\"_Name\") for mol in mols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2: Applicability domain - calculation times, coverage, substructure distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sdf_path = f\"{Path().home()}/article_bsf/data/input/coconut.sdf\"\n",
    "\n",
    "def sizes(sdf_path) -> np.array:\n",
    "    return np.array([mol.GetNumHeavyAtoms() for mol in Chem.SDMolSupplier(sdf_path)])\n",
    "\n",
    "def times(fp_name) -> np.array:\n",
    "    return np.loadtxt(f\"{Path().home()}/article_bsf/coconut_{fp_name}_times.csv\", delimiter=\",\", dtype=float)\n",
    "\n",
    "def time_size_stats(times, sizes) -> np.array:\n",
    "    \"\"\"\n",
    "    Function to get the data per fingerprint\n",
    "    \"\"\"\n",
    "    assert len(times) == len(sizes), \"The length of times and sizes should be the same\"\n",
    "    \n",
    "    unique_sizes = np.unique(sizes)\n",
    "\n",
    "    average_times = []\n",
    "    for size in unique_sizes:\n",
    "        average_times.append(np.mean(times[sizes == size]))\n",
    "\n",
    "    std_times = []\n",
    "    for size in unique_sizes:\n",
    "        std_times.append(np.std(times[sizes == size]))\n",
    "\n",
    "    return np.array([(size, avg_time, std_time) for size, avg_time, std_time in zip(unique_sizes, average_times, std_times)], \n",
    "                    dtype=[('size', int), ('average_time', float), ('std_time', float)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = sizes(sdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x axis coconut size, y axis time, line through averages per size, a 50% confidence interval around the line\n",
    "fp_colour = {\"maccs\": \"lightblue\", \"morgan\": \"violet\", \"rdk\": \"lightcoral\", \"bsf\": \"yellowgreen\"}\n",
    "for fp_name, colour in fp_colour.items():\n",
    "    # plt.scatter(sizes, times(fp_name), s=1, color=colour, alpha=0.1)\n",
    "    plt.xlabel(\"Number of heavy atoms\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "\n",
    "    # plot the average time per size\n",
    "    \n",
    "    data = time_size_stats(times(fp_name), sizes)\n",
    "    plt.plot(data[\"size\"], data[\"average_time\"], color=colour)\n",
    "\n",
    "    # plot the 50% confidence interval around the average time per size\n",
    "    plt.fill_between(\n",
    "        data[\"size\"],\n",
    "        data[\"average_time\"] - 0.5 * data[\"std_time\"],\n",
    "        data[\"average_time\"] + 0.5 * data[\"std_time\"],\n",
    "        color=colour,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "# plot the sizes behind it with the y axis on the right\n",
    "plt.twinx()\n",
    "# as a histogram\n",
    "plt.hist(sizes, bins=np.linspace(0, data[\"size\"].max(), data[\"size\"].max()), alpha=0.1, color=\"black\")\n",
    "plt.ylabel(\"Number of molecules\")\n",
    "\n",
    "\n",
    "# make handles for the legend\n",
    "handles = [plt.Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=colour, label=actual_names[fp_name]) for fp_name, colour in fp_colour.items()]\n",
    "plt.legend(handles=handles, title=\"Fingerprint\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# density plot of am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x axis coconut size, y axis time, line through averages per size, a 50% confidence interval around the line\n",
    "fp_colour = {\"maccs\": \"lightblue\", \"morgan\": \"violet\", \"rdk\": \"lightcoral\", \"bsf\": \"yellowgreen\"}\n",
    "actual_names = {\"maccs\": \"MACCS\", \"morgan\": \"ECFP4\", \"rdk\": \"Daylight-like\", \"bsf\": \"Biosynfoni\"}\n",
    "for fp_name, colour in fp_colour.items():\n",
    "    # plt.scatter(sizes, times(fp_name), s=1, color=colour, alpha=0.1)\n",
    "    plt.xlabel(\"Number of heavy atoms\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "\n",
    "    # plot the average time per size\n",
    "    \n",
    "    data = time_size_stats(times(fp_name), sizes)\n",
    "\n",
    "    plt.plot(data[\"size\"], data[\"average_time\"], color=colour)\n",
    "    \n",
    "\n",
    "    # plot the 50% confidence interval around the average time per size\n",
    "    plt.fill_between(\n",
    "        data[\"size\"],\n",
    "        data[\"average_time\"] - 0.5 * data[\"std_time\"],\n",
    "        data[\"average_time\"] + 0.5 * data[\"std_time\"],\n",
    "        color=colour,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "# plot the sizes behind it with the y axis on the right\n",
    "plt.twinx()\n",
    "# as a histogram\n",
    "plt.hist(sizes, bins=np.linspace(0, data[\"size\"].max(), data[\"size\"].max()), alpha=0.1, color=\"black\")\n",
    "plt.ylabel(\"Number of molecules\")\n",
    "\n",
    "\n",
    "# make handles for the legend\n",
    "handles = [plt.Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=colour, markersize=8, label=actual_names[fp_name]) for fp_name, colour in fp_colour.items()]\n",
    "handles.reverse()\n",
    "plt.legend(handles=handles, title=\"Fingerprint\")\n",
    "\n",
    "# show x only until 100\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# density plot of am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(times(\"maccs\")))\n",
    "print(np.average(times(\"morgan\")))\n",
    "print(np.average(times(\"rdk\")))\n",
    "print(np.average(times(\"bsf\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biosynfoni import Biosynfoni\n",
    "\n",
    "sdf_path = f\"{Path().home()}/article_bsf/data/input/coconut.sdf\"\n",
    "# mols = [mol for i, mol in enumerate(Chem.SDMolSupplier(sdf_path)) if i < 10]\n",
    "mols = []\n",
    "for i, mol in enumerate(Chem.SDMolSupplier(sdf_path)):\n",
    "    if i < 10000:\n",
    "        mols.append(mol)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "sizes = [mol.GetNumHeavyAtoms() for mol in mols]\n",
    "coverages = [Biosynfoni(mol).get_coverage() for mol in mols]\n",
    "# coverage against mol size in a hexbin plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get mako-r, but make the first 0.1 white and from there slowly go to the colours\n",
    "\n",
    "cmap = sns.color_palette(\"mako_r\", as_cmap=True)\n",
    "# cmap = [cmap(i) for i in range(256)]\n",
    "# cmap[0:5] = [(cmap[i][0],cmap[i][1],cmap[i][2], (i+1)/5) for i in range(1, 5)]\n",
    "# cmap[0] = (1, 1, 1, 1)\n",
    "# cmap = mpl.colors.ListedColormap(cmap)\n",
    "\n",
    "df = pd.DataFrame.from_dict({\"sizes\": sizes, \"coverages\": coverages}, orient=\"index\").T\n",
    "df = df[df.sizes < 100]\n",
    "plt.hexbin(df.sizes, df.coverages, gridsize=50, cmap=cmap, edgecolors='white', linewidths=0.1)\n",
    "plt.colorbar(label=\"Number of molecules\")\n",
    "plt.xlabel(\"Molecular size\")\n",
    "plt.ylabel(\"Coverage\")\n",
    "plt.title(\"Biosynfoni's coverage of natural products\")\n",
    "# make sure all hexagons are hexagonal despite the limits\n",
    "\n",
    "# plt.scatter(sizes, coverages, s=1, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_coverage = np.mean(coverages)\n",
    "std_coverage = np.std(coverages)\n",
    "\n",
    "print(mean_coverage, std_coverage)\n",
    "# print as violin plot with the mean and std as a line and the instances scatterd around it\n",
    "sns.violinplot(data=coverages, inner=\"box\", edgecolor=\"none\", alpha=0.6, scale='width')\n",
    "# sns.violinplot(data=coverages, inner=\"point\", edgecolor=\"none\", alpha=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0, 1)\n",
    "size_coverage = np.array([(s, c) for s, c in zip(sizes, coverages)], dtype=[('size', int), ('coverage', float)])\n",
    "\n",
    "sns.scatterplot(data=pd.DataFrame(size_coverage), x=\"size\", y=\"coverage\",ax=ax, edgecolor='none', alpha=0.1, s=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substructure occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from biosynfoni.subkeys import get_names, get_smarts\n",
    "\n",
    "names = get_names()\n",
    "\n",
    "df = pd.read_csv(f\"{Path().home()}/article_bsf/fps/coconut_bsf.csv\", names=names)\n",
    "\n",
    "# make a violin plot of each of the columns\n",
    "fig, ax = plt.subplots()\n",
    "# sns.violinplot(data=df, ax=ax, inner=\"point\", density_norm=\"width\")\n",
    "sns.barplot(data=df, ax=ax, errorbar='sd', capsize=0.1, err_kws={'linewidth': 0.5}, edgecolor=\"none\", linewidth=0.5)\n",
    "plt.title(\"Distribution of substructure counts within natural products\")\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# # instead of the xtick labels, place mol images\n",
    "# from rdkit import Chem\n",
    "\n",
    "# mols = [Chem.MolFromSmarts(smarts) for smarts in get_smarts()]\n",
    "# from rdkit.Chem import Draw\n",
    "# imgs = [Draw.MolToImage(mol, size=(1,1), ) for mol in mols]\n",
    "# ax.set_xticklabels([f\"{df.columns[i]}\\n\" for i in range(len(df.columns))], rotation=90)\n",
    "# ax.set_xticklabels([])\n",
    "\n",
    "# # add the images to the plot\n",
    "# for i, img in enumerate(imgs):\n",
    "#     ax.text(i, 0, f\"{df.columns[i]}\\n\", ha='center', va='center', rotation=90, fontsize=6)\n",
    "#     ax.imshow(img, extent=(i-0.5, i+0.5, 0, 1), aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMI map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse, logging, os\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from helper import  set_label_colors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_minuses(heatmap, array):\n",
    "    for i in range(array.shape[0]):\n",
    "        for j in range(array.shape[1]):\n",
    "            text = \"\"\n",
    "            # if array[i, j] > 0:\n",
    "            #     text = \"+\"\n",
    "            if array[i, j] < 0:\n",
    "                text = \"-\"\n",
    "            heatmap.text(\n",
    "                j + 0.5,\n",
    "                i + 0.5,\n",
    "                text,\n",
    "                horizontalalignment=\"center\",\n",
    "                verticalalignment=\"center\",\n",
    "                color=\"white\",\n",
    "            )\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_labels() -> list[str]:\n",
    "    keys = [\n",
    "        \"coa\",\n",
    "        \"nadh\",\n",
    "        \"nadph\",\n",
    "        \"all standard aminos\",\n",
    "        \"non-standard aminos\",\n",
    "        \"open pyranose\",\n",
    "        \"open furanose\",\n",
    "        \"pyranose\",\n",
    "        \"furanose\",\n",
    "        \"indoleC2N\",\n",
    "        \"phenylC2N\",\n",
    "        \"c5n\",\n",
    "        \"c4n\",\n",
    "        \"phenylC3\",\n",
    "        \"phenylC2\",\n",
    "        \"phenylC1\",\n",
    "        \"isoprene\",\n",
    "        \"acetyl\",\n",
    "        \"methylmalonyl\",\n",
    "        \"ethyl\",\n",
    "        \"methyl\",\n",
    "        \"phosphate\",\n",
    "        \"sulfonate\",\n",
    "        \"fluorine\",\n",
    "        \"chlorine\",\n",
    "        \"bromine\",\n",
    "        \"iodine\",\n",
    "        \"nitrate\",\n",
    "        \"epoxy\",\n",
    "        \"ether\",\n",
    "        \"hydroxyl\",\n",
    "        \"c3 ring\",\n",
    "        \"c4 ring\",\n",
    "        \"c5 ring\",\n",
    "        \"c6 ring\",\n",
    "        \"c7 ring\",\n",
    "        \"c8 ring\",\n",
    "        \"c9 ring\",\n",
    "        \"c10 ring\",\n",
    "    ]\n",
    "    return keys\n",
    "\n",
    "\n",
    "def get_colours() -> list[str]:\n",
    "    colours = [\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"#FFEAA0\",\n",
    "        \"#FFEAA0\",\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#B9C311\",  # green\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "    ]\n",
    "    return colours\n",
    "\n",
    "\n",
    "def _pearson_correlation_matrix(fps: np.array) -> np.array:\n",
    "    # randomly subsample 10000\n",
    "\n",
    "    # fps = fps[np.random.choice(fps.shape[0], 10000, replace=False), 3:]\n",
    "    # fps = fps[:, 3:]\n",
    "    mat = np.corrcoef(fps, rowvar=False, dtype=np.float16)\n",
    "    # print(fps.shape)\n",
    "    # print(mat.shape)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def correlation_heatmap(fps: np.array) -> None:\n",
    "    keys = get_labels()\n",
    "    correlations = _pearson_correlation_matrix(fps)\n",
    "    np.savetxt(\"correlations.tsv\", correlations, delimiter=\"\\t\", fmt=\"%.2f\")\n",
    "    logging.warning(correlations.shape)\n",
    "    hm = sns.heatmap(\n",
    "        correlations,\n",
    "        xticklabels=keys,\n",
    "        yticklabels=keys,\n",
    "        # cmap=\"coolwarm\",\n",
    "        cmap=\"PiYG\",  # more colorblind-friendly diverging colormap\n",
    "        vmin=np.min(fps),\n",
    "        vmax=np.max(fps),\n",
    "        center=0,  # center of the colormap\n",
    "    )\n",
    "    # hm.text(0.5, 0.5, \"test\", horizontalalignment=\"center\", verticalalignment=\"center\")\n",
    "    # for all negative values, add a minus sign\n",
    "    add_minuses(hm, fps)\n",
    "    colours = get_colours()\n",
    "    xt, yt = hm.get_xticklabels(), hm.get_yticklabels()\n",
    "    # set_label_colors(hm.get_xticklabels(), colours)\n",
    "    # set_label_colors(hm.get_yticklabels(), colours)\n",
    "    return hm\n",
    "\n",
    "\n",
    "\n",
    "fps = np.loadtxt(Path.home() / \"article_bsf\" / \"fps\" / \"coconut_bsf.csv\", delimiter=\",\")\n",
    "\n",
    "\n",
    "# Count the number of times each bit is set.\n",
    "cx = Counter()\n",
    "cxy = Counter()\n",
    "\n",
    "for idx in tqdm(range(fps.shape[0])):\n",
    "    for bit_idx, bit in enumerate(fps[idx]):\n",
    "        if bit > 0:\n",
    "            cx[bit_idx] += bit\n",
    "\n",
    "        for bit_idx2, bit2 in enumerate(fps[idx]):\n",
    "            # if bit_idx == bit_idx2:\n",
    "            #     continue\n",
    "            if bit > 0 and bit2 > 0:\n",
    "                # cxy[(bit_idx, bit_idx2)] += 1\n",
    "                cxy[(bit_idx, bit_idx2)] += min(bit, bit2)\n",
    "\n",
    "# Create lookup between key and fingerprint index.\n",
    "x2i, i2x = {}, {}\n",
    "keys = get_labels()\n",
    "for i, x in enumerate(keys):\n",
    "    x2i[x] = i\n",
    "    i2x[i] = x\n",
    "\n",
    "# Build sparse PMI matrix.\n",
    "sx = sum(cx.values())\n",
    "sxy = sum(cxy.values())\n",
    "data, rows, cols = [], [], []\n",
    "for (x, y), n in cxy.items():\n",
    "    rows.append(x)\n",
    "    cols.append(y)\n",
    "    data.append(math.log((n / sxy) / (cx[x] / sx) / (cx[y] / sx)))\n",
    "\n",
    "PMI = csc_matrix((data, (rows, cols)))\n",
    "mat = PMI.toarray()\n",
    "\n",
    "# Visualize matrix.\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "# sns.set(font_scale=0.5)\n",
    "hm = sns.heatmap(\n",
    "    mat,\n",
    "    xticklabels=keys,\n",
    "    yticklabels=keys,\n",
    "    # cmap=\"coolwarm\",\n",
    "    cmap=\"PiYG\",  # more colorblind-friendly diverging colormap\n",
    "    vmin=np.min(mat),\n",
    "    vmax=np.max(mat),\n",
    "    center=0,  # center of the colormap\n",
    ")\n",
    "# hm.text(0.5, 0.5, \"test\", horizontalalignment=\"center\", verticalalignment=\"center\")\n",
    "# for all negative values, add a minus sign\n",
    "add_minuses(hm, mat)\n",
    "\n",
    "# make ticklabels bold\n",
    "hm.set_yticklabels(hm.get_yticklabels(), fontweight=\"bold\")\n",
    "hm.set_xticklabels(hm.get_xticklabels(), fontweight=\"bold\")\n",
    "\n",
    "# set_label_colors(hm.get_xticklabels(), colours)\n",
    "# set_label_colors(hm.get_yticklabels(), colours)\n",
    "colours = get_colours()\n",
    "# set_label_colors(hm.get_xticklabels(), colours)\n",
    "# set_label_colors(hm.get_yticklabels(), colours)\n",
    "\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.yticks(rotation=0)\n",
    "\n",
    "plt.ylabel(\"Substructues\")\n",
    "plt.xlabel(\"Substructues\")\n",
    "plt.title(\n",
    "    f\"Pointwise Mutual Information of Biosynfoni Substructures\", size=12\n",
    ")\n",
    "\n",
    "# plt.savefig( bbox_inches=\"tight\")\n",
    "# plt.close()\n",
    "\n",
    "# # get a correlation heatmap as well\n",
    "# corr_hm = correlation_heatmap(fps)\n",
    "# plt.title(\"Pearson correlation - non-overlap Biosynfoni on COCONUT\", size=12)\n",
    "# plt.savefig(args.o.replace(\".png\", \"_correlation.png\"), bbox_inches=\"tight\")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import chain\n",
    "len(set(chain(*[match for match in Biosynfoni(Chem.SDMolSupplier(sdf_path)[0]).matches for match in match])))\n",
    "# Chem.SDMolSupplier(sdf_path)[0].GetNumHeavyAtoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{Path().home()}/article_bsf/data/raw_data/coconut_complete-10-2024.csv\")\n",
    "df = df[~df.organisms.isna()]\n",
    "\n",
    "# from rdkit.Chem import PandasTools\n",
    "# coconut_ = PandasTools.LoadSDF(f\"{Path().home()}/article_bsf/data/_old_raw_data/COCONUT_DB.sdf\")\n",
    "# print(len(coconut_))\n",
    "\n",
    "# coconut_ = coconut_.query(\"textTaxa != '[notax]'\").copy()\n",
    "# print(len(coconut_))\n",
    "# coconut_\n",
    "# r\"textTaxa.*\\n\\[[^n]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[df.organisms.str.lower().str.contains(\"fungus\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(f\"{Path().home()}/article_bsf/data/input/coconut_taxonomy.csv\", header=None, names=[\"compounds\", \"taxonomy\"])\n",
    "print(df_.shape) #695133\n",
    "df_ = df_[~df_.taxonomy.isna()]\n",
    "print(df_.shape) # 11286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the projected data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(projected_X, columns=[\"x\", \"y\"])\n",
    "df[\"class\"] = np.loadtxt(f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\", delimiter=\",\", dtype=str, usecols=1)[:1000]\n",
    "\n",
    "sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"class\", palette=\"tab20\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "X = pd.DataFrame(X,columns = iris.feature_names)\n",
    "from tmap.tda import mapper, Filter\n",
    "from tmap.tda.cover import Cover\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "# Step1. initiate a Mapper\n",
    "tm = mapper.Mapper(verbose=1)\n",
    "# Step2. Projection\n",
    "lens = [Filter.MDS(components=[0, 1],random_state=100)]\n",
    "projected_X = tm.filter(X, lens=lens)\n",
    "clusterer = DBSCAN(eps=0.75, min_samples=1)\n",
    "cover = Cover(projected_data=MinMaxScaler().fit_transform(projected_X), resolution=20, overlap=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3: Applications - unsupervised clustering, supervised classification, biosynthetic pathway reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# sim = np.loadtxt(Path.home() / \"article_bsf\" / \"output\" / \"bsf_sim.csv\", delimiter=\",\")\n",
    "\n",
    "# sim = np.triu(sim) + np.triu(sim, 1).T\n",
    "# np.fill_diagonal(sim, 1)\n",
    "\n",
    "# # sns.heatmap(sim, cmap=\"coolwarm\", center=0,vmax=1, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(f\"{Path.home()}/article_bsf/output/maccs_umap.csv\", header=None)\n",
    "df.columns = [\"x\", \"y\"]\n",
    "df[\"class\"] = np.loadtxt(f\"{Path.home()}/article_bsf/data/input/chebi_classes.csv\", delimiter=\",\", dtype=str, usecols=1)[:1000]\n",
    "\n",
    "sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"class\", palette=\"tab20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import PandasTools\n",
    "from rdkit import Chem \n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"{Path().home()}/article_bsf/output/bsf_tsne.csv\", header=None, names=[\"x\", \"y\"])\n",
    "df[\"class\"] = np.loadtxt(f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\", delimiter=\",\", dtype=str, usecols=1)\n",
    "df[\"id\"] = np.loadtxt(f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\", delimiter=\",\", dtype=str, usecols=0)\n",
    "\n",
    "# get a df from the sdf\n",
    "sdf_path = f\"{Path().home()}/article_bsf/data/input/chebi.sdf\"\n",
    "sdf_df = PandasTools.LoadSDF(sdf_path)\n",
    "# merge with df\n",
    "\n",
    "df = pd.merge(df, sdf_df, left_on=\"id\", right_on=\"ChEBI ID\")\n",
    "\n",
    "\n",
    "\n",
    "print(df[~df[\"class\"].str.contains(\";\")].shape)\n",
    "df = df[~df[\"class\"].str.contains(\";\")]\n",
    "sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"class\", palette=\"Spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "o_f = Path.home() / \"article_bsf\" / \"output\"\n",
    "labels = np.loadtxt(o_f/\"classifications.tsv\", delimiter=\"\\t\", dtype=str)\n",
    "def multilabel_and_dict(classifications: np.array) -> tuple[np.array, dict]:\n",
    "    classes = set(\";\".join(map(str, classifications)).split(\";\"))\n",
    "    class_to_id = {class_: i for i, class_ in enumerate(sorted(classes))}\n",
    "    id_to_class = {i: class_ for class_, i in class_to_id.items()}\n",
    "    classification_array = np.zeros((len(classifications), len(classes)), dtype=int)\n",
    "    for i, classification in enumerate(classifications):\n",
    "        for class_ in re.split(r\"[;,]\", classification):\n",
    "            classification_array[i, class_to_id[class_]] = 1\n",
    "    return classification_array, id_to_class\n",
    "\n",
    "y_true, id_to_class = multilabel_and_dict(labels)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(5, 5))\n",
    "\n",
    "\n",
    "df = pd.read_csv(o_f/\"ids.tsv\", sep=\"\\t\", dtype=str, header=None)\n",
    "df[\"y_true\"] = y_true.tolist()\n",
    "for n, file in enumerate(o_f.glob(\"*_proba.tsv\")):\n",
    "    fp_name = file.stem.split(\"_\")[0]\n",
    "    df[f\"y_proba_{fp_name}\"] = np.loadtxt(file, delimiter=\"\\t\", dtype=float).tolist()\n",
    "    df[f\"y_pred_{fp_name}\"] = df[f\"y_proba_{fp_name}\"].apply(lambda x: (np.array(x) > 0.5).astype(int).tolist())\n",
    "    df[\"class\"] = labels\n",
    "\n",
    "    # get an ROC per class\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    auc=[]\n",
    "    for i in range(y_true.shape[1]):\n",
    "    =    print(id_to_class[i])\n",
    "        fpr, tpr, roc = roc_curve(y_true[:, i], df[f\"y_proba_{fp_name}\"].apply(lambda x: x[i]))\n",
    "        auc.append(roc_auc_score(y_true[:, i], df[f\"y_proba_{fp_name}\"].apply(lambda x: x[i])))\n",
    "        ax[n // 2, n % 2].plot(fpr, tpr, label=f\"{id_to_class[i]} AUC: {auc}\", alpha=0.7)\n",
    "        ax[n // 2, n % 2].set_title(fp_name)\n",
    "    ax[n // 2, n % 2].legend(labels = [f\"{id_to_class[i]} (AUC: {auc[i]:.3f})\" for i in id_to_class.keys()], loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1 - Chemical space of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import seaborn as sns\n",
    "\n",
    "import umap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maccs_path = f\"{Path().home()}/article_bsf/coconut_maccs.csv\"\n",
    "maccs = np.loadtxt(maccs_path, delimiter=\",\", dtype=int)\n",
    "label = pd.read_csv(f\"{Path().home()}/article_bsf/data/raw_data/coconut_complete-10-2024.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "random_subset = np.random.choice(maccs.shape[0], 10000, replace=False)\n",
    "subset_maccs = maccs[random_subset]\n",
    "subset_labels = label.iloc[random_subset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding = reducer.fit_transform(subset_maccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=embedding[:, 0], y=embedding[:, 1], hue=subset_labels[\"rotatable_bond_count\"])#,  legend=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices of points that have embedding x < -10 and 0 < y < 5\n",
    "points = embedding[(embedding[:, 0] < -10) & (0 < embedding[:, 1]) & (embedding[:, 1] < 5)]\n",
    "indices = np.where((embedding[:, 0] < -10) & (0 < embedding[:, 1]) & (embedding[:, 1] < 5))[0]\n",
    "\n",
    "\n",
    "\n",
    "of_interest = subset_labels.iloc[indices]\n",
    "\n",
    "# draw molecules from smiles\n",
    "mols = [Chem.MolFromSmiles(smiles) for smiles in of_interest[\"canonical_smiles\"]]\n",
    "\n",
    "Chem.Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(200, 200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the molecules corresponding to the close points\n",
    "sdf = Chem.SDMolSupplier(sdf_path)\n",
    "\n",
    "for i, j in zip(*close_points):\n",
    "    mol_i = sdf[int(random_subset[i][0])]\n",
    "    mol_j = sdf[int(random_subset[j][0])]\n",
    "    break\n",
    "mol_i, mol_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2 - Biosynthetic distance visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # later for visualisation:\n",
    "\n",
    "# def get_square(\n",
    "#     df: pd.DataFrame,\n",
    "#     col1: str,\n",
    "#     col2: str,\n",
    "#     range1: tuple[float, float],\n",
    "#     range2: tuple[float, float],\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"returns the molecule pair's inchis for 'dots' in a given square of the scatter plot\"\"\"\n",
    "#     square = df.loc[\n",
    "#         (df[col1] >= range1[0])\n",
    "#         & (df[col1] <= range1[1])\n",
    "#         & (df[col2] >= range2[0])\n",
    "#         & (df[col2] <= range2[1])\n",
    "#     ]\n",
    "#     return square\n",
    "\n",
    "\n",
    "# def draw_molpair(\n",
    "#     pair: list[Chem.Mol], annotation: str = \"\", highlighting: bool = True\n",
    "# ) -> None:\n",
    "#     for i in range(len(pair)):\n",
    "#         highlighting_info = None\n",
    "#         if highlighting:\n",
    "#             highlighting_info = get_highlight_mapping(mol=pair[i])\n",
    "#         svg_text = moldrawing.draw(\n",
    "#             pair[i], highlight_atoms_bonds_mappings=highlighting_info\n",
    "#         )\n",
    "#         if annotation:\n",
    "#             svg_text = svg_text.replace(\n",
    "#                 \"</svg>\",\n",
    "#                 f'<text x=\"30\" y=\"30\" font-size=\"20\" font-family=\"montserrat\">{annotation}</text></svg>',\n",
    "#             )\n",
    "#         with open(f\"{annotation}_{i}.svg\", \"w\") as f:\n",
    "#             f.write(svg_text)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def draw_squares(\n",
    "#     square_df: pd.DataFrame,\n",
    "#     pair_columns: tuple[str, str] = (\"mol1\", \"mol2\"),\n",
    "#     squarename: str = \"origin\",\n",
    "#     highlighting: bool = True,\n",
    "# ) -> None:\n",
    "#     \"\"\"draws the molecules in the squares\n",
    "#     input: (pd.DataFrame) square_df -- the dataframe containing the squares\n",
    "#     (str) pair_columns -- the name of the column containing the molecule pairs\n",
    "#     (str) squarename -- the name of the square\n",
    "#     \"\"\"\n",
    "#     if square_df.empty:\n",
    "#         return None\n",
    "#     for _, row in tqdm(\n",
    "#         square_df.iterrows(),\n",
    "#         desc=f\"drawing {squarename} squares\",\n",
    "#         total=square_df.shape[0],\n",
    "#         position=1,\n",
    "#     ):\n",
    "#         pair = [row[pair_columns[0]], row[pair_columns[1]]]\n",
    "#         pathway = row[\"pathway\"]\n",
    "#         outfilename = outfile_namer(f\"{squarename}_{pathway}\")\n",
    "#         draw_molpair(pair, annotation=outfilename, highlighting=highlighting)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def loopsquares(\n",
    "#     df: pd.DataFrame,\n",
    "#     x_fp: str = \"biosynfoni\",\n",
    "#     y_fps: list[str] = [\"rdkit\", \"maccs\", \"morgan\"],\n",
    "#     size: int = 0.2,\n",
    "# ) -> None:\n",
    "#     for i, y_fp in tqdm(\n",
    "#         enumerate(y_fps), desc=\"looping squares\", leave=False, position=0\n",
    "#     ):\n",
    "#         _, iwd = output_direr(f\"./{x_fp}_{y_fp}_squares\")\n",
    "#         min_val, max_val = 0.0, 1.0\n",
    "#         min_border = 0.0 + size\n",
    "#         max_border = 1.0 - size\n",
    "#         left_bottom = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (min_val, min_border),\n",
    "#             (min_val, min_border),\n",
    "#         )\n",
    "#         left_top = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (min_val, min_border),\n",
    "#             (max_border, max_val),\n",
    "#         )\n",
    "#         right_bottom = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (max_border, max_val),\n",
    "#             (min_val, min_border),\n",
    "#         )\n",
    "#         right_top = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (max_border, max_val),\n",
    "#             (max_border, max_val),\n",
    "#         )\n",
    "#         exactly_middle = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (0.5, 0.5),\n",
    "#             (min_val, max_val),\n",
    "#         )\n",
    "#         draw_squares(left_bottom, squarename=f\"{y_fp}_origin\")\n",
    "#         draw_squares(left_top, squarename=f\"{y_fp}_left_top\")\n",
    "#         draw_squares(right_bottom, squarename=f\"{y_fp}_right_bottom\")\n",
    "#         draw_squares(right_top, squarename=f\"{y_fp}_right_top\")\n",
    "#         if i == 0:\n",
    "#             draw_squares(exactly_middle, squarename=f\"{x_fp}_middle\")\n",
    "#         os.chdir(iwd)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def biosynthetic_distance_analysis(pairs_df, metric):\n",
    "#     df = pd.read_csv(structures_path, sep=\"\\t\", header=None, index_col=0)\n",
    "#     logging.info(\n",
    "#         f\"{old_n_rows[0]-df.shape[0]} pathways dropped due to lack of mol pairs\\n\\n\"\n",
    "#     )\n",
    "\n",
    "#     _, iwd = output_direr(\"./biosynthetic_distance\")  # move to outputdir\n",
    "\n",
    "#     pairs = pairs_per_separation(df)\n",
    "\n",
    "#     dist_df = f\"{outfile_namer(metric)}.tsv\"\n",
    "#     mols_pkl = f\"{outfile_namer('mols')}.pkl\"\n",
    "#     if not os.path.exists(dist_df) or not os.path.exists(mols_pkl):\n",
    "#         df = add_fp_to_df(\n",
    "#             pairs,\n",
    "#             fp_types=FP_FUNCTIONS.keys(),\n",
    "#         )\n",
    "#         df = get_all_similarity_scores(df, metric=metric)\n",
    "#         mols = df.copy()\n",
    "#         # save mols as pickle\n",
    "#         mols.to_pickle(f\"{outfile_namer('mols')}.pkl\")\n",
    "#         # remove mols from df\n",
    "#         df = df.drop(columns=[\"mol1\", \"mol2\"])\n",
    "#         df.to_csv(dist_df, sep=\"\\t\", index=True)\n",
    "\n",
    "#     mols = pd.read_pickle(f\"{outfile_namer('mols')}.pkl\")\n",
    "#     df = mols\n",
    "#     df[\"pathway\"] = df.index\n",
    "\n",
    "#     logging.debug(df.shape, mols.shape, df.columns)\n",
    "#     logging.debug(df, pairs, pairs.columns)\n",
    "\n",
    "#     # if args.annotate:\n",
    "#     #     # pw_tax_file = \"../../../metacyc/pathways_taxid.txt\"\n",
    "#     #     # tax_text_file = \"../../../metacyc/cleaner_classes.dat\"\n",
    "#     #     pw_tax_file, tax_text_file = args.annotate\n",
    "#     #     annotated_df = annotate_pathways(comparison_df, pw_tax_file, tax_text_file)\n",
    "\n",
    "#     df[\"stepnum\"] = df[\"separation\"].apply(str)\n",
    "\n",
    "#     logging.info(\"getting scatterplots...\")\n",
    "#     fp_combs = list(itertools.combinations(fp_names, 2))\n",
    "#     for combination in tqdm(fp_combs, desc=\"getting scatterplots\"):\n",
    "#         scatter = fm.scatter_boxplots(\n",
    "#             df,\n",
    "#             col_x=combination[0],\n",
    "#             col_y=combination[1],\n",
    "#             figtitle=f\"{args.metric} for different reaction step numbers\",\n",
    "#             color_by=\"stepnum\",\n",
    "#         )\n",
    "#         filename = outfile_namer(f\"{combination[0]}_{combination[1]}_{args.metric}.png\")\n",
    "#         fm.savefig(scatter, filename)\n",
    "\n",
    "#     onestep = df[df[\"stepnum\"] == \"1\"]\n",
    "#     onestep.to_csv(f'{outfile_namer(\"onestep\")}.tsv', sep=\"\\t\", index=False)\n",
    "#     logging.info(\"getting squares...\")\n",
    "#     for fp in [\n",
    "#         \"biosynfoni\",\n",
    "#         \"overlap_binosynfoni\",\n",
    "#         \"overlap_biosynfoni\",\n",
    "#         \"interoverlap_biosynfoni\",\n",
    "#     ]:\n",
    "#         loopsquares(\n",
    "#             onestep,\n",
    "#             fp,\n",
    "#             [\"rdkit\", \"maccs\", \"morgan\", \"maccsynfoni\", \"overlap\"],\n",
    "#             size=0.2,\n",
    "#         )\n",
    "#     # loopsquares(\n",
    "#     #     onestep,\n",
    "#     #     \"biosynfoni\",\n",
    "#     #     [\"rdkit\", \"maccs\", \"morgan\", \"maccsynfoni\", \"overlap\"],\n",
    "#     #     size=0.2,\n",
    "#     # )\n",
    "\n",
    "#     # save the biosynfoni version for reference\n",
    "#     logging.info(\"saving current biosynfoni version...\")\n",
    "#     save_version(defaultVersion)\n",
    "\n",
    "#     os.chdir(iwd)\n",
    "#     logging.info(\"done\\nbyebye\")\n",
    "#     exit(0)\n",
    "#     return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3 - Fingerprint heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, os, logging\n",
    "# import argparse\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "\n",
    "# matplotlib.use(\"Agg\")\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.ioff()\n",
    "\n",
    "\n",
    "# from biosynfoni.inoutput import outfile_namer\n",
    "# from biosynfoni.subkeys import fpVersions, defaultVersion, get_names, get_pathway\n",
    "# from utils.figures import (\n",
    "#     heatmap,\n",
    "#     annotate_heatmap,\n",
    "#     savefig,\n",
    "#     set_label_colors_from_categories,\n",
    "#     custom_cmap,\n",
    "# )\n",
    "# from utils import set_style\n",
    "# from utils.colours import colourDict\n",
    "\n",
    "\n",
    "# def cli():\n",
    "#     \"\"\"Command line interface for fingerprint average plotter\"\"\"\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description=\"Plot fingerprint pull-up plot (i.e. fingerprint count per substructure)\"\n",
    "#     )\n",
    "#     # parser.add_argument(\"fingerprintfile_coco\", type=str)\n",
    "#     # parser.add_argument(\"fingerprintfile_zinc\", type=str)\n",
    "#     # parser.add_argument(\"bsf_name\", type=str, default=defaultVersion)\n",
    "#     parser.add_argument(\n",
    "#         \"fingerprints\", type=str, help=\"path to tsv or csv file of fingerprints\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"-n\",\n",
    "#         \"--name\",\n",
    "#         type=str,\n",
    "#         help=\"name of compound collection for title and filename\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"-c\",\n",
    "#         \"--classes\",\n",
    "#         type=str,\n",
    "#         required=False,\n",
    "#         help=\"path to tsv or csv file of classes, uses first column as class label. pass if you want to also plot classes separately\",\n",
    "#     )\n",
    "#     args = parser.parse_args()\n",
    "#     args.fingerprints = os.path.abspath(args.fingerprints)\n",
    "#     args.classes = os.path.abspath(args.classes) if args.classes else None\n",
    "#     return args\n",
    "\n",
    "\n",
    "# def count_distributions(coco, zinc, substructure_names):\n",
    "#     \"\"\"WIP: Plots substructure count distribution for coco and zinc\"\"\"\n",
    "#     npcs = np.loadtxt(\n",
    "#         \"npcs.tsv\", dtype=\"str\", delimiter=\"\\t\"\n",
    "#     )  # just added, not checked\n",
    "#     s_coco = coco[npcs[:, 0] == \"Alkaloids\"]\n",
    "#     # random subsample of zinc\n",
    "#     np.random.seed(42)\n",
    "#     s_zinc = zinc[np.random.choice(zinc.shape[0], size=s_coco.shape[0], replace=False)]\n",
    "\n",
    "#     for i in range(3, len(substructure_names)):\n",
    "#         # np.histogram(coco[:,i])\n",
    "#         # print(np.mean(coco[:,i]))\n",
    "#         fig = plt.figure()\n",
    "#         nonzero = s_coco[:, i][s_coco[:, i] > 0]\n",
    "#         if np.max(nonzero) == 0:\n",
    "#             continue\n",
    "#         n, bins, edges = plt.hist(\n",
    "#             nonzero,\n",
    "#             bins=np.max(nonzero) - 1,\n",
    "#             color=\"green\",\n",
    "#             alpha=0.7,\n",
    "#             histtype=\"step\",\n",
    "#             align=\"left\",\n",
    "#         )\n",
    "\n",
    "#         plt.title(\n",
    "#             f\"substructure counts for {substructure_names[i]}, {len(nonzero)} nonzero values\"\n",
    "#         )\n",
    "#         plt.xticks(bins)\n",
    "#         plt.xlabel(\"substructure counts\")\n",
    "#         plt.ylabel(\"number of compounds\")\n",
    "#         plt.tight_layout()\n",
    "\n",
    "#     for i in range(3, len(substructure_names)):\n",
    "#         # np.histogram(coco[:,i])\n",
    "#         # print(np.mean(zinc[:,i]))\n",
    "#         fig = plt.figure()\n",
    "#         nonzero = s_zinc[:, i][s_zinc[:, i] != 0]\n",
    "#         if np.max(nonzero) < 2:\n",
    "#             continue\n",
    "#         n, bins, edges = plt.hist(\n",
    "#             nonzero,\n",
    "#             bins=np.max(nonzero) - 1,\n",
    "#             color=\"purple\",\n",
    "#             alpha=0.7,\n",
    "#             rwidth=1,\n",
    "#             histtype=\"step\",\n",
    "#             align=\"mid\",\n",
    "#         )\n",
    "#         plt.title(\n",
    "#             f\"histogram of substructure counts for {substructure_names[i]}, {len(nonzero)} nonzero values\"\n",
    "#         )\n",
    "#         plt.xticks(bins)\n",
    "#         plt.xlabel(\"substructure counts\")\n",
    "#         plt.ylabel(\"number of compounds\")\n",
    "\n",
    "#     plt.close()\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def write_stats(fp_arr: np.array) -> np.array:\n",
    "#     \"\"\"\n",
    "#     Write stats of fingerprint array to file\n",
    "\n",
    "#         Args:\n",
    "#             fp_arr (np.array): fingerprint array\n",
    "\n",
    "#         Returns:\n",
    "#             np.array: mean fingerprint count per substructure\n",
    "#     \"\"\"\n",
    "#     mean_fp = fp_arr.mean(axis=0)\n",
    "#     std_fp = fp_arr.std(axis=0)\n",
    "#     median_fp = np.median(fp_arr, axis=0)\n",
    "#     with open(\"stats.tsv\", \"w\") as f:\n",
    "#         f.write(\"mean\\n\")\n",
    "#         f.write(\"\\t\".join([str(x) for x in mean_fp]))\n",
    "#         f.write(\"\\nstdev\\n\")\n",
    "#         f.write(\"\\t\".join([str(x) for x in std_fp]))\n",
    "#         f.write(\"\\nmedian\\n\")\n",
    "#         f.write(\"\\t\".join([str(x) for x in median_fp]))\n",
    "#     return mean_fp\n",
    "\n",
    "\n",
    "# def heatmap_array(\n",
    "#     fps: np.array,\n",
    "#     max_height: int = 30,\n",
    "#     percentages=False,\n",
    "#     accumulative=True,\n",
    "#     end_accumulative=False,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Make an array for a heatmap of fingerprint count per substructure\n",
    "\n",
    "#         Args:\n",
    "#             fps (np.array): fingerprint array\n",
    "#             max_height (int): maximum height of heatmap\n",
    "#             percentages (bool): whether to return in percentages\n",
    "#             accumulative (bool): whether to return accumulative counts\n",
    "#             end_accumulative (bool): whether to return accumulative counts only for the last height\n",
    "#         Returns:\n",
    "#             np.array: array for heatmap (height x substructures)\n",
    "\n",
    "#     Remarks:\n",
    "#         - if accumulative is True, then the heatmap will show the number of compounds that have at least that many substructures\n",
    "#         - if accumulative is False, then the heatmap will show the number of compounds that have exactly that many substructures\n",
    "#         - if end_accumulative is True, then the heatmap will show the number of compounds that have at least that many substructures for the last height\n",
    "\n",
    "#     \"\"\"\n",
    "#     heat_array = np.zeros((max_height, fps.shape[1]))\n",
    "#     for i in range(max_height):\n",
    "#         if accumulative:\n",
    "#             countrow = np.count_nonzero(fps > i, axis=0)\n",
    "#         else:\n",
    "#             if end_accumulative and i == max_height - 1:\n",
    "#                 # for last height, count all remaining values\n",
    "#                 countrow = np.count_nonzero(fps > i, axis=0)\n",
    "#             else:\n",
    "#                 countrow = np.count_nonzero((fps == i + 1), axis=0)\n",
    "#         heat_array[max_height - 1 - i] = countrow\n",
    "\n",
    "#     if percentages:\n",
    "#         heat_array = heat_array / fps.shape[0] * 100\n",
    "#     return heat_array.astype(int)\n",
    "\n",
    "\n",
    "# def fp_heatmap(\n",
    "#     fp_hm_array: np.array,\n",
    "#     subslabels: list = [],\n",
    "#     size: tuple[int] = (10, 6),\n",
    "#     percentages: bool = False,\n",
    "#     annotate: bool = False,\n",
    "#     color_scheme: str = \"Purples\",\n",
    "#     title: str = \"Representative substructure count for compound collection\",\n",
    "#     top_acc_array=None,\n",
    "#     standard_colour: bool = False,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Plot a heatmap of fingerprint count per substructure\n",
    "\n",
    "#         Args:\n",
    "#             fp_hm_array (np.array): array for heatmap (height x substructures)\n",
    "#             subslabels (list): list of substructure labels\n",
    "#             size (tuple): size of plot\n",
    "#             percentages (bool): whether to return in percentages\n",
    "#             annotate (bool): whether to annotate the heatmap\n",
    "#             color_scheme (str): colour scheme for heatmap\n",
    "#             title (str): title of plot\n",
    "#             top_acc_array (np.array): array for heatmap of top accumulative counts.\n",
    "#                                         if None, then no top accumulative counts will be plotted.\n",
    "#                                         default is None.\n",
    "#             standard_colour (bool): whether to colour substructure labels according to biosynfoni pathway\n",
    "#         Returns:\n",
    "#             matplotlib.figure.Figure: figure of heatmap\n",
    "#     \"\"\"\n",
    "#     cbarlab = \"number of compounds\"\n",
    "#     if percentages:\n",
    "#         cbarlab = \"% of compounds\"\n",
    "\n",
    "#     logging.info(\"saving heatmap\")\n",
    "#     height = fp_hm_array.shape[0]\n",
    "#     fig, ax = plt.subplots(figsize=size, dpi=500)\n",
    "#     if not subslabels:\n",
    "#         subslabels = [f\"subs{i}\" for i in range(1, fp_hm_array.shape[1] + 1)]\n",
    "#     subslabels = [x.replace(\"_\", \" \") for x in subslabels]\n",
    "\n",
    "#     yaxlabels = [(height + 1 - i) for i in range(1, height + 1)]\n",
    "#     if top_acc_array is not None:\n",
    "#         yaxlabels[0] = f\"{height}\"\n",
    "#         maxtop = top_acc_array[~np.isnan(top_acc_array)].max()\n",
    "#         maxfp = fp_hm_array[~np.isnan(fp_hm_array)].max()\n",
    "#         maxval = max(maxtop, maxfp)\n",
    "#         im2, cbar2 = heatmap(\n",
    "#             top_acc_array,\n",
    "#             # ['>11']+[(height+1-i) for i in range(1, height + 1)],\n",
    "#             yaxlabels,\n",
    "#             subslabels,\n",
    "#             ax=ax,\n",
    "#             cmap=custom_cmap(\"Greys\", first_color=\"#ffffff00\"),\n",
    "#             # cmap = \"PiYG\",\n",
    "#             cbar_kw={\n",
    "#                 \"drawedges\": False,\n",
    "#                 \"shrink\": 0.3,\n",
    "#                 \"pad\": -0.05,\n",
    "#                 \"aspect\": 10,\n",
    "#             },\n",
    "#             vmin=0,\n",
    "#             vmax=maxval,\n",
    "#         )\n",
    "#         # rotate cbar labels -90\n",
    "#         cbar2.set_label(f\"{cbarlab} {height}\", rotation=90, va=\"bottom\", labelpad=10)\n",
    "\n",
    "#     im, cbar = heatmap(\n",
    "#         fp_hm_array,\n",
    "#         # [(height+1-i) for i in range(1, height + 1)],\n",
    "#         yaxlabels,\n",
    "#         subslabels,\n",
    "#         ax=ax,\n",
    "#         cmap=custom_cmap(color_scheme, first_color=\"#ffffff00\"),\n",
    "#         # cmap = \"PiYG\",\n",
    "#         cbarlabel=cbarlab,\n",
    "#         vmin=0,\n",
    "#         cbar_kw={\"drawedges\": False, \"shrink\": 0.3, \"pad\": 0.02, \"aspect\": 10},\n",
    "#     )\n",
    "#     cbar.set_label(f\"{cbarlab}\", rotation=90, va=\"bottom\", labelpad=10)\n",
    "\n",
    "#     # texts = annotate_heatmap(im, valfmt=\"{x:.1f}\")\n",
    "#     if annotate:\n",
    "#         texts = annotate_heatmap(im, valfmt=\"{x:.0f}\", size=7)\n",
    "#     if standard_colour:\n",
    "#         set_label_colors_from_categories(\n",
    "#             ax.get_xticklabels(),\n",
    "#             get_pathway(version=defaultVersion),\n",
    "#             colourDict[\"pathways\"],\n",
    "#         )\n",
    "#     # plt.figure(figsize=(10,6))\n",
    "#     ax.set_xlabel(\"substructure\", labelpad=10)\n",
    "#     ax.set_ylabel(\"counts\", labelpad=10)\n",
    "#     ax.set_title(title, loc=\"center\", pad=20)\n",
    "#     fig.tight_layout()\n",
    "#     return fig\n",
    "\n",
    "\n",
    "# def over_under_divide(fps: np.array, limit: int = 10, percentages: bool = True):\n",
    "#     \"\"\"\n",
    "#     Divide the heatmap array into two arrays: one for values under the limit, and one for values over the limit.\n",
    "#     \"\"\"\n",
    "#     full = heatmap_array(\n",
    "#         fps,\n",
    "#         max_height=limit + 1,\n",
    "#         percentages=percentages,\n",
    "#         accumulative=False,\n",
    "#         end_accumulative=True,\n",
    "#     )\n",
    "#     under, over = full.astype(float).copy(), full.astype(float).copy()\n",
    "#     under[0] = np.nan\n",
    "#     over[1:] = np.nan\n",
    "#     return under, over\n",
    "\n",
    "\n",
    "# def fp_heatmap_accumulative(fp_arr: np.array, limit: int = 10, *args, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Make a heatmap of fingerprint count per substructure, with accumulative end counts\n",
    "\n",
    "#         Args:\n",
    "#             fp_arr (np.array): fingerprint array\n",
    "#             limit (int): maximum height of heatmap\n",
    "#         Returns:\n",
    "#             matplotlib.figure.Figure: figure of heatmap\n",
    "\n",
    "#     Remarks:\n",
    "#         - the heatmap will show the number of compounds that have at least that many substructures for the last height\n",
    "#         - this helps reduce the height of the heatmap, as the top accumulative counts are often much higher than the rest\n",
    "#     \"\"\"\n",
    "#     under, over = over_under_divide(fp_arr, limit, percentages=True)\n",
    "#     hm = fp_heatmap(\n",
    "#         under,\n",
    "#         *args,\n",
    "#         percentages=True,\n",
    "#         top_acc_array=over,\n",
    "#         **kwargs,\n",
    "#     )\n",
    "#     return hm\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     logging.info(\"hello\")\n",
    "#     set_style()\n",
    "#     ft = \"png\"\n",
    "#     args = cli()\n",
    "#     fps = np.loadtxt(args.fingerprints, dtype=int, delimiter=\",\")\n",
    "\n",
    "#     fp_name = \"_\".join(args.fingerprints.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1:])\n",
    "#     set_name = args.fingerprints.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "\n",
    "#     iwd = os.getcwd()\n",
    "#     os.makedirs(f\"{iwd}/heatmaps/{set_name}/{fp_name}\", exist_ok=True)\n",
    "#     os.chdir(f\"{iwd}/heatmaps/{set_name}/{fp_name}\")\n",
    "#     fp_name = fp_name.replace(\"_\", \" \")\n",
    "\n",
    "#     # save mean, std, median, etc of fps\n",
    "#     write_stats(fps)\n",
    "\n",
    "#     substructure_names = get_names(version=defaultVersion)\n",
    "#     if fps.shape[1] != len(substructure_names):\n",
    "#         substructure_names = [f\"{i}\" for i in range(1, fps.shape[1] + 1)]\n",
    "\n",
    "#     # if all values in fps are 0 or 1, then it's a binary fingerprint\n",
    "#     if np.all(np.isin(fps, [0, 1])):\n",
    "#         fp_heatmap(\n",
    "#             heatmap_array(fps, max_height=1, percentages=True, accumulative=False),\n",
    "#             subslabels=substructure_names,\n",
    "#             title=f\"Distribution of {fp_name} substructure counts\",\n",
    "#             color_scheme=\"Greys\",\n",
    "#             percentages=True,\n",
    "#             size=(15, 1),\n",
    "#             standard_colour=True,\n",
    "#         )\n",
    "#         plt.savefig(f\"{fp_name}_heatmap.{ft}\")\n",
    "#         return None\n",
    "\n",
    "#     hm = fp_heatmap_accumulative(\n",
    "#         fps,\n",
    "#         limit=10,\n",
    "#         title=f\"Distribution of {fp_name} substructure counts\",\n",
    "#         subslabels=substructure_names,\n",
    "#         color_scheme=\"GnBu\",\n",
    "#         standard_colour=True,\n",
    "#     )\n",
    "#     savefig(hm, f\"heatmap.{ft}\")\n",
    "\n",
    "#     if args.classes:\n",
    "#         classes = np.loadtxt(args.classes, dtype=\"str\", delimiter=\"\\t\", usecols=0)\n",
    "#         classes[classes == \"fatty_acid,isoprenoid\"] = \"isoprenoid\"\n",
    "#         classes = np.where(\n",
    "#             np.core.defchararray.find(classes, \",\") != -1, \"multiple\", classes\n",
    "#         )\n",
    "#         classes[classes == \"\"] = \"None\"\n",
    "\n",
    "#         if len(classes) != fps.shape[0]:\n",
    "#             logging.warning(\n",
    "#                 \"classes file not same length as fingerprints file; will lead to errors\"\n",
    "#             )\n",
    "#         for classif in np.unique(classes):\n",
    "#             idx = np.where(classes == classif)\n",
    "#             focus = fps[idx]\n",
    "#             if not classif:\n",
    "#                 classif = \"None\"\n",
    "\n",
    "#             hm = fp_heatmap_accumulative(\n",
    "#                 focus,\n",
    "#                 limit=10,\n",
    "#                 title=f\"Distribution of {fp_name} substructure counts for {len(focus)} {classif.replace('_', ' ')} compounds\",\n",
    "#                 subslabels=substructure_names,\n",
    "#                 color_scheme=\"GnBu\",\n",
    "#                 standard_colour=True,\n",
    "#             )\n",
    "#             savefig(hm, f\"{classif}_heatmap.{ft}\")\n",
    "\n",
    "#     os.chdir(iwd)\n",
    "#     # fp_means_plots(coco_mean, zinc_mean, outfile_namer(f\"{coco_name}_{zinc_name}.svg\"))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4 - Clustermaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, os, argparse, logging\n",
    "\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import scipy.cluster.hierarchy as sch\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pylab as plt\n",
    "# from matplotlib.patches import Patch\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # matplotlib.use('Agg')       #if in background\n",
    "\n",
    "# from biosynfoni.subkeys import get_names, get_pathway\n",
    "# from utils import set_style\n",
    "# from utils.colours import colourDict\n",
    "# from utils.figures import set_label_colors_from_categories\n",
    "\n",
    "\n",
    "# def cli():\n",
    "#     \"\"\"\n",
    "#     Command line interface for clustermap\n",
    "#     \"\"\"\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     parser.add_argument(\"fingerprints\", help=\"Fingerprint file\")\n",
    "#     parser.add_argument(\"labels\", help=\"Labels file\")\n",
    "#     parser.add_argument(\n",
    "#         \"-s\",\n",
    "#         \"--subsample\",\n",
    "#         required=False,\n",
    "#         type=int,\n",
    "#         help=\"subsample size\",\n",
    "#         default=None,\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"-r\",\n",
    "#         \"--seed\",\n",
    "#         \"--randomseed\",\n",
    "#         required=False,\n",
    "#         type=int,\n",
    "#         help=\"seed for subsampling\",\n",
    "#         default=None,\n",
    "#     )\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "#     args.fingerprints = os.path.abspath(args.fingerprints)\n",
    "#     args.labels = os.path.abspath(args.labels)\n",
    "#     return args\n",
    "\n",
    "\n",
    "# class recursion_depth:\n",
    "#     def __init__(self, limit):\n",
    "#         self.limit = limit\n",
    "#         self.default_limit = sys.getrecursionlimit()\n",
    "\n",
    "#     def __enter__(self):\n",
    "#         sys.setrecursionlimit(self.limit)\n",
    "\n",
    "#     def __exit__(self, type, value, traceback):\n",
    "#         sys.setrecursionlimit(self.default_limit)\n",
    "\n",
    "\n",
    "# class ClusterMap:\n",
    "#     def __init__(self, df, labels, metric, method) -> None:\n",
    "#         self.df = df\n",
    "#         self.indexes = df.index.values\n",
    "#         self.labels = labels\n",
    "#         self.colordict = self.get_colordict()\n",
    "#         self.metric = metric\n",
    "#         self.method = method\n",
    "#         logging.debug(f\"calculating distances with {metric} and {method}...\")\n",
    "#         self.distances = self.get_distances()\n",
    "#         self.clustering = self.get_clustering()\n",
    "#         # self.distances = None\n",
    "#         # self.clustering = None\n",
    "#         # self.tree = self.get_tree()\n",
    "#         self.colors, self.handles = self._get_category_colors_handles(self.labels)\n",
    "#         logging.debug(f\"plotting clustermap with {metric} and {method}...\")\n",
    "#         self.clustermap = self.seacluster()\n",
    "#         self.clusterfig = self.get_clusterplot()\n",
    "#         plt.close()\n",
    "#         pass\n",
    "\n",
    "#     def get_distances(self):\n",
    "#         \"\"\"\n",
    "#         calculates distances from data frame using metric\n",
    "#         \"\"\"\n",
    "#         return sch.distance.pdist(self.df, metric=self.metric)\n",
    "\n",
    "#     def set_distances(self, distances):\n",
    "#         \"\"\"\n",
    "#         sets distances from data frame\n",
    "#         \"\"\"\n",
    "#         self.distances = distances\n",
    "#         return None\n",
    "\n",
    "#     def get_clustering(self):\n",
    "#         \"\"\"\n",
    "#         calculates clustering from distances using method\n",
    "#         \"\"\"\n",
    "#         # plt.title(out_file)\n",
    "#         with recursion_depth(10000):\n",
    "#             clustering = sch.linkage(self.distances, method=self.method)\n",
    "#         # plt.close()\n",
    "#         return clustering\n",
    "\n",
    "#     def get_tree(self):\n",
    "#         \"\"\"returns dendrogram tree\"\"\"\n",
    "#         tree = sch.dendrogram(\n",
    "#             self.clustering, leaf_font_size=2, color_threshold=4, labels=self.indexes\n",
    "#         )\n",
    "#         return tree\n",
    "\n",
    "#     def seacluster(self):\n",
    "#         \"\"\"\n",
    "#         Makes a seaborn clustermap\n",
    "\n",
    "#         Returns:\n",
    "#         seacluster: seaborn clustermap object\n",
    "#         \"\"\"\n",
    "#         # comp_color, comp_handles = get_gnsr_diff_color() #compounds\n",
    "\n",
    "#         cmap = _cmap_makezerowhite(\"mako\")\n",
    "\n",
    "#         # self.distances = self.set_distances(self.get_distances())\n",
    "#         # self.clustering = self.get_clustering()\n",
    "#         # fig, ax = plt.subplots(figsize=(15,6))\n",
    "#         # sns.set(font_scale=0.5)\n",
    "#         with recursion_depth(20000):\n",
    "#             seacluster = sns.clustermap(\n",
    "#                 self.df,\n",
    "#                 method=self.method,\n",
    "#                 metric=self.metric,\n",
    "#                 xticklabels=1,  # every 1: label\n",
    "#                 # robust = True,\n",
    "#                 # square = True,\n",
    "#                 row_colors=self.colors,\n",
    "#                 # col_colors = phyl_color,\n",
    "#                 # z_score = 1,\n",
    "#                 # figsize= (len(list(data_frame)), min(200, len(data_frame.index.values))),\n",
    "#                 cmap=cmap,\n",
    "#                 cbar_kws={\n",
    "#                     \"shrink\": 0.3,\n",
    "#                     \"label\": \"counts\",\n",
    "#                     # \"orientation\": \"horizontal\",\n",
    "#                     # \"labelweight\": \"bold\",\n",
    "#                 },\n",
    "#                 cbar_pos=(1.05, 0.2, 0.03, 0.4),\n",
    "#             )\n",
    "#         # make x tick labels bold\n",
    "\n",
    "#         return seacluster\n",
    "\n",
    "#     def get_clusterplot(self, legend_title: str = \"class\") -> plt.gca:\n",
    "#         \"\"\"returns plt of clustermap with legend of categories\"\"\"\n",
    "\n",
    "#         # plt.figure(figsize=(15,6))\n",
    "\n",
    "#         # plt.setp(seacluster.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "#         # plt.setp(seacluster.ax_heatmap.xaxis.get_majorticklabels(), rotation=30, fontsize=8)\n",
    "#         # plt.setp(seacluster.ax_heatmap.xaxis.get_majorticklabels(), rotation=-30)\n",
    "#         # seacluster.set_xlim([0,2])\n",
    "\n",
    "#         # seacluster.set_title(TITLE, fontsize=16, fontdict={})\n",
    "#         # plt.title(\n",
    "#         #     f\"Hierarchical clustering of compounds and substructures {self.method}, {self.metric}\",\n",
    "#         #     loc=\"center\",\n",
    "#         # )  # + 'z scored')\n",
    "#         self.clustermap.fig.suptitle(\n",
    "#             f\"Hierarchical clustering of compounds and substructures {self.method}, {self.metric}\",\n",
    "#             x=0.6,\n",
    "#             y=1.1,\n",
    "#             weight=\"bold\",\n",
    "#             size=18,\n",
    "#         )\n",
    "#         self.clustermap.ax_heatmap.set_xticklabels(\n",
    "#             self.clustermap.ax_heatmap.get_xmajorticklabels(),\n",
    "#             fontsize=10,\n",
    "#             fontweight=\"semibold\",\n",
    "#         )\n",
    "#         self._set_substructure_colours()\n",
    "\n",
    "#         # seacluster = self.seacluster()\n",
    "\n",
    "#         # improve layout\n",
    "#         # plt.tight_layout()\n",
    "\n",
    "#         # add legend\n",
    "#         handles = self.handles\n",
    "#         legend_colors = [\n",
    "#             Patch(facecolor=handles[name], edgecolor=\"#FFFFFF00\")\n",
    "#             for name in handles.keys()\n",
    "#         ]\n",
    "\n",
    "#         plt.legend(\n",
    "#             legend_colors,\n",
    "#             handles.keys(),\n",
    "#             title=legend_title,\n",
    "#             bbox_to_anchor=(1, 0.9),\n",
    "#             bbox_transform=plt.gcf().transFigure,\n",
    "#             loc=\"upper left\",\n",
    "#             frameon=False,\n",
    "#             edgecolor=\"#FFFFFF\",\n",
    "#             fontsize=10,\n",
    "#         )\n",
    "#         # set legend title size\n",
    "#         plt.setp(plt.gca().get_legend().get_title(), fontsize=10)\n",
    "\n",
    "#         # plt.show()\n",
    "#         # return dendrogram_linkage\n",
    "#         return plt.gca()\n",
    "\n",
    "#     def save_clustermap(self, fmt: str = \"svg\") -> None:\n",
    "#         \"\"\"saves clustermap to file\n",
    "\n",
    "#         Args:\n",
    "#             fmt: str, file format\n",
    "#         Returns:\n",
    "#             None\n",
    "#         \"\"\"\n",
    "#         out_file = f\"clustermap_{self.method}_{self.metric}.{fmt}\"\n",
    "#         # self.clusterfig.savefig(out_file, format=fmt)\n",
    "#         self.clustermap.savefig(out_file, format=fmt)\n",
    "#         # plt.savefig(out_file, format=fmt)\n",
    "#         return None\n",
    "\n",
    "#     def get_dendogram_tree(self):\n",
    "#         \"\"\"returns dendrogram tree object for branch cutting\"\"\"\n",
    "#         return self.clustermap.dendrogram_row.dendrogram\n",
    "\n",
    "#     def get_dendogram_linkage(self) -> np.ndarray:\n",
    "#         \"\"\"returns dendrogram linkage object\"\"\"\n",
    "#         return self.clustermap.dendrogram_row.linkage\n",
    "\n",
    "#     def get_colordict(self) -> dict:\n",
    "#         \"\"\"returns colour dictionary for categories\n",
    "#         Returns:\n",
    "#             colordict: dict, category: color\n",
    "#         \"\"\"\n",
    "#         # colordict = {\n",
    "#         #     \"Terpenoids\": sns.color_palette(\"Set3\")[6],  # green\n",
    "#         #     \"Alkaloids\": sns.color_palette(\"Set3\")[9],  # purple\n",
    "#         #     \"Shikimates and Phenylpropanoids\": sns.color_palette(\"Set3\")[4],  # blue\n",
    "#         #     \"Fatty acids\": sns.color_palette(\"Set3\")[5],  # orange\n",
    "#         #     \"Carbohydrates\": sns.color_palette(\"Set3\")[7],  # pink\n",
    "#         #     \"Polyketides\": sns.color_palette(\"Set3\")[3],  # light red\n",
    "#         #     \"Amino acids and Peptides\": \"bisque\",\n",
    "#         #     # \"No NP-Classifier prediction\": \"grey\",\n",
    "#         #     \"None\": \"grey\",\n",
    "#         #     \"Synthetic\": \"black\",\n",
    "#         # }\n",
    "#         if self.labels[0][0].isupper():\n",
    "#             colordict = colourDict[\"NPClassifier prediction\"]\n",
    "#         else:\n",
    "#             colordict = colourDict[\"chebi class\"]\n",
    "#         return colordict\n",
    "\n",
    "#     def _get_category_colors_handles(\n",
    "#         self, categories: pd.Series\n",
    "#     ) -> tuple[pd.DataFrame, dict]:\n",
    "#         \"\"\"uses colour dictionary to assign colors to the categories\"\"\"\n",
    "#         network_dict = {}\n",
    "#         categories.fillna(\"None\", inplace=True)\n",
    "\n",
    "#         for ind, cat in categories.items():\n",
    "#             # network_dict[ind] = [self.colordict[str(cat).split(',')[0]]] #in case of multiple categories, take the first one\n",
    "#             network_dict[ind] = [self.colordict[str(cat)]]\n",
    "#         network_colors = pd.DataFrame.from_dict(network_dict, orient=\"index\")\n",
    "#         network_colors.columns = [\"\"]\n",
    "#         handles = self.colordict\n",
    "#         return network_colors, handles\n",
    "\n",
    "#     def _set_substructure_colours(self):\n",
    "#         \"\"\"sets substructure colours in clustermap\"\"\"\n",
    "#         pathways = get_pathway()\n",
    "#         substructures = self.df.columns\n",
    "#         subs_to_pathways = {a: b for a, b in zip(substructures, pathways)}\n",
    "#         ticklabels = self.clustermap.ax_heatmap.get_xticklabels()\n",
    "#         # access text from ticklabels\n",
    "#         pathways = [subs_to_pathways[x.get_text()] for x in ticklabels]\n",
    "#         if len(pathways) != len(ticklabels):\n",
    "#             logging.warning(\n",
    "#                 f\"cannot set {pathways} substructure for {ticklabels} colours\"\n",
    "#             )\n",
    "#             return None\n",
    "#         else:\n",
    "#             set_label_colors_from_categories(\n",
    "#                 ticklabels, pathways, colourDict[\"pathways\"]\n",
    "#             )\n",
    "\n",
    "\n",
    "# def _cmap_makezerowhite(\n",
    "#     default_cmap: str = \"mako\",\n",
    "# ) -> mpl.colors.LinearSegmentedColormap:\n",
    "#     # define color map:-------------------------------------------------\n",
    "#     cmap = sns.color_palette(default_cmap, as_cmap=True)  # define the colormap\n",
    "#     # extract all colors from the .jet map\n",
    "#     cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "#     # force the first color entry to be white (to distinguish 0 from low values)\n",
    "#     cmaplist[0] = (1.0, 1.0, 1.0, 0)\n",
    "#     # create the new map\n",
    "#     cmap = mpl.colors.LinearSegmentedColormap.from_list(\"Custom cmap\", cmaplist, cmap.N)\n",
    "#     return cmap\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     set_style()\n",
    "#     args = cli()\n",
    "\n",
    "#     filetype = \"svg\"\n",
    "#     # version = input_file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "#     substructure_names = [x.replace(\"_\", \" \") for x in get_names()]\n",
    "\n",
    "#     fp = pd.read_csv(args.fingerprints, sep=\",\", header=None, dtype=int)\n",
    "#     if fp.shape[1] == len(substructure_names):\n",
    "#         fp.columns = substructure_names\n",
    "#     db_name = args.fingerprints.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "#     fp_name = args.fingerprints.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1]\n",
    "\n",
    "#     npcs = pd.read_csv(\n",
    "#         args.labels,\n",
    "#         sep=\"\\t\",\n",
    "#         header=None,\n",
    "#         dtype=str,\n",
    "#         usecols=[0],\n",
    "#     )\n",
    "\n",
    "#     # as all isoprenoids are fatty acids according to chebi:\n",
    "#     npcs.replace(\"fatty_acid,isoprenoid\", \"isoprenoid\", inplace=True)\n",
    "#     # filter out multiple-prediction compounds\n",
    "#     npcs.fillna(\",\", inplace=True)\n",
    "#     fp = fp[~npcs[0].str.contains(\",\")]\n",
    "#     npcs = npcs[~npcs[0].str.contains(\",\")]\n",
    "\n",
    "#     # # filter out only-zero columns in df ~~~~~~~~~~~~~~~ CHECK IF THIS APPLIES TO YOUR PURPOSES ~~~~~~~~~~~~~~~\n",
    "#     # fp = fp.loc[:, (fp != 0).any(axis=0)]\n",
    "#     # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "#     # subsample indexes\n",
    "#     if args.subsample:\n",
    "#         np.random.seed(args.seed)\n",
    "#         idx = np.random.choice(fp.index, args.subsample, replace=False)\n",
    "#         fp = fp.loc[idx]\n",
    "#         npcs = npcs.loc[idx]\n",
    "\n",
    "#     npcs_series = npcs.iloc[:, 0]\n",
    "\n",
    "#     # check if indexes are the same\n",
    "#     assert fp[fp.index != npcs.index].empty\n",
    "#     assert npcs[npcs.index != npcs_series.index].empty\n",
    "#     assert type(npcs_series) == pd.Series\n",
    "\n",
    "#     # if args.synthetic: #under construction\n",
    "#     #     synthetic_fp = pd.read_csv(args.synthetic, dtype=int)\n",
    "#     #     synthetic_fp = np.random.choice(\n",
    "#     #         synthetic_fp.shape[0], fp.shape[0], replace=False\n",
    "#     #     )\n",
    "#     #     fp = np.concatenate((fp, synthetic_fp))\n",
    "#     #     synthetic_labels = np.array([\"synthetic\" for _ in range(synthetic_fp.shape[0])])\n",
    "#     #     labels = np.concatenate((labels, synthetic_labels))\n",
    "\n",
    "#     iwd = os.getcwd()\n",
    "#     # make a directory in grandparent directory called clustermaps\n",
    "#     # os.chdir(\"../../\")\n",
    "#     os.makedirs(f\"clustermaps/{db_name}/{fp_name}\", exist_ok=True)\n",
    "#     os.chdir(f\"clustermaps/{db_name}/{fp_name}\")\n",
    "\n",
    "#     # # debugging\n",
    "#     # clustermap = ClusterMap(fp, npcs_series, \"euclidean\", \"average\")\n",
    "#     # clustermap.save_clustermap(fmt=filetype)\n",
    "\n",
    "#     for method in tqdm([\"average\", \"complete\", \"single\", \"weighted\"]):\n",
    "#         for metric in tqdm(\n",
    "#             [\n",
    "#                 \"euclidean\",\n",
    "#                 \"cityblock\",\n",
    "#                 \"cosine\",\n",
    "#                 \"correlation\",\n",
    "#                 \"hamming\",\n",
    "#                 \"jaccard\",\n",
    "#                 \"mahalanobis\",\n",
    "#                 \"chebyshev\",\n",
    "#                 \"canberra\",\n",
    "#                 \"braycurtis\",\n",
    "#                 \"dice\",\n",
    "#                 \"kulsinski\",\n",
    "#                 \"matching\",\n",
    "#                 \"rogerstanimoto\",\n",
    "#                 \"russellrao\",\n",
    "#                 \"sokalmichener\",\n",
    "#                 \"sokalsneath\",\n",
    "#                 \"yule\",\n",
    "#             ],\n",
    "#             leave=False,\n",
    "#         ):\n",
    "#             # errors can occur for some metrics if they have too small sample sets, or with certain combinations:\n",
    "#             try:\n",
    "#                 clustermap = ClusterMap(fp, npcs_series, metric, method)\n",
    "#                 clustermap.save_clustermap(fmt=filetype)\n",
    "#             except:\n",
    "#                 logging.warning(f\"failed for {method} and {metric}\")\n",
    "#             pass\n",
    "#         pass\n",
    "\n",
    "#     os.chdir(iwd)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5 - Importances Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sys import argv\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib as mpl\n",
    "\n",
    "# from biosynfoni.subkeys import defaultVersion, get_values, get_pathway\n",
    "# from utils.figures import cat_to_colour\n",
    "# from utils.colours import colourDict\n",
    "# from utils import set_style\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"\n",
    "#     Plot the feature importances from a random forest model as a barplot\n",
    "#     \"\"\"\n",
    "#     importances = np.loadtxt(argv[1], delimiter=\"\\t\", dtype=float)\n",
    "#     bsf_name = defaultVersion\n",
    "#     substructure_names = get_values(\"name\", version=bsf_name)\n",
    "#     pathways = get_pathway(version=bsf_name)\n",
    "#     colors = cat_to_colour(pathways, colourDict[\"pathways\"])\n",
    "#     if len(substructure_names) != importances.shape[1]:\n",
    "#         print(\"WARNING: substructure names not equal to importances\")\n",
    "#         substructure_names = [f\"{i}\" for i in range(importances.shape[1])]\n",
    "#         colors = [\"#888888\" for _ in range(importances.shape[1])]\n",
    "#     set_style()\n",
    "\n",
    "#     means = np.mean(importances, axis=0)\n",
    "\n",
    "#     # set plot size\n",
    "#     # default: 6.4, 4.8\n",
    "#     ratio = importances.shape[1] / 39\n",
    "#     plt.figure(figsize=(ratio * 6.4, 4.8))\n",
    "\n",
    "#     # plot barplot\n",
    "#     barplot = plt.bar(substructure_names, means)\n",
    "#     # add standard deviations as error bars\n",
    "#     stds = np.std(importances, axis=0)\n",
    "#     print(stds.shape)\n",
    "#     e1 = plt.errorbar(substructure_names, means, yerr=stds, fmt=\"o\", color=\"#606060\")\n",
    "#     e2 = plt.errorbar(substructure_names, means, yerr=stds, fmt=\"none\", color=\"#606060\")\n",
    "\n",
    "#     plt.xticks(range(len(substructure_names)), substructure_names, rotation=90)\n",
    "#     # set bar colours\n",
    "#     for i, bar in enumerate(barplot):\n",
    "#         bar.set_color(colors[i])\n",
    "\n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.ylabel(\"feature importance\")\n",
    "#     plt.xlabel(\"substructure\")\n",
    "#     plt.suptitle(\"Feature importances for random forest model\", weight=\"bold\")\n",
    "#     plt.title(\"(averaged over k-fold cross validation with k=5)\", weight=\"light\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(argv[1].replace(\".tsv\", \".png\"), bbox_inches=\"tight\")\n",
    "#     return None\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6 - Confusion Matrix heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse, logging\n",
    "# import os\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def set_style() -> None:\n",
    "#     \"\"\"\n",
    "#     Set the style of the plot to biostylefoni\n",
    "#     \"\"\"\n",
    "#     # get path of this script\n",
    "#     script_path = os.path.dirname(os.path.realpath(__file__))\n",
    "#     parent_path = os.path.dirname(script_path)\n",
    "#     utils_path = os.path.join(parent_path, \"utils\")\n",
    "#     print(utils_path)\n",
    "#     style_path = os.path.join(utils_path, \"biostylefoni.mplstyle\")\n",
    "#     # set style\n",
    "#     plt.style.use(style_path)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def parse_cms_files(m_path: str) -> tuple[np.array, np.array]:\n",
    "#     \"\"\"\n",
    "#     Parse the confusion matrices and names from a file\n",
    "\n",
    "#     Args:\n",
    "#         m_path (str): path to file with confusion matrices\n",
    "\n",
    "#     Returns:\n",
    "#         tuple[np.array, np.array]: array of confusion matrices and array of names (i.e. )\n",
    "#     \"\"\"\n",
    "#     cms = np.loadtxt(\n",
    "#         m_path,\n",
    "#         delimiter=\"\\t\",\n",
    "#         dtype=int,\n",
    "#         skiprows=1,\n",
    "#         usecols=(1, 2, 3, 4),\n",
    "#     )\n",
    "#     # for each row, split the array into a 2x2 array\n",
    "#     cms = cms.reshape(cms.shape[0], 2, 2)\n",
    "\n",
    "#     # now get only the 'index names'\n",
    "#     cm_names = np.loadtxt(\n",
    "#         m_path,\n",
    "#         delimiter=\"\\t\",\n",
    "#         dtype=str,\n",
    "#         skiprows=1,\n",
    "#         usecols=(0),\n",
    "#     )\n",
    "#     return cms, cm_names\n",
    "\n",
    "\n",
    "# def get_matrices(cms: np.array) -> tuple[list[np.array], list[np.array]]:\n",
    "#     \"\"\"\n",
    "#     Take an array of confusion matrices and return a list of matrices and a list of normalised matrices\n",
    "\n",
    "#     Args:\n",
    "#         cms (np.array): array of confusion matrices\n",
    "\n",
    "#     Returns:\n",
    "#         tuple[list[np.array], list[np.array]]: a list of matrices and a list of normalised matrices\n",
    "#     \"\"\"\n",
    "#     matrices = []\n",
    "#     norm_matrices = []\n",
    "#     perc_matrices = []\n",
    "#     for i in range(cms.shape[0]):\n",
    "#         # # make random matrix with values between 0 and 100000\n",
    "#         # matrix = np.random.randint(0, 100000, size=(2, 2))\n",
    "#         matrix = cms[i]\n",
    "#         # normalise matrix\n",
    "#         norm_matrix = matrix / matrix.sum(axis=1, keepdims=True)\n",
    "#         # turn normalised matrix into percentages\n",
    "#         perc_matrix = norm_matrix * 100\n",
    "#         # append matrices to list\n",
    "#         matrices.append(matrix)\n",
    "#         norm_matrices.append(norm_matrix)\n",
    "#         perc_matrices.append(perc_matrix)\n",
    "#     assert len(matrices) == len(perc_matrices), \"#matrices don't match\"\n",
    "#     return matrices, perc_matrices\n",
    "\n",
    "\n",
    "# def main(matrix_path, ):\n",
    "#     matrix_path = Path(matrix_path)\n",
    "#     ml_input = matrix_path.stem.split(\"_\")[-1]\n",
    "\n",
    "#     # read in the confusion matrix and names\n",
    "#     cms, cm_names = parse_cms_files(matrix_path)\n",
    "#     # print(cms, cm_names)\n",
    "\n",
    "#     # get the matrices and the percentage versions for each category\n",
    "#     matrices, perc_matrices = get_matrices(cms)\n",
    "#     assert len(matrices) == len(cm_names), \"#matrices and #categories don't match\"\n",
    "\n",
    "#     # make subplots\n",
    "#     fig, axs = plt.subplots(\n",
    "#         1, len(matrices), figsize=(len(matrices), 2), dpi=500\n",
    "#     )  # , sharey=True) #sharing y makes the y axis ticks appear in each subplot\n",
    "\n",
    "#     # make a heatmap in each subplot\n",
    "#     for i, ax in enumerate(axs):\n",
    "#         cmap_name = \"Greys\"\n",
    "#         cmap = mpl.colormaps[cmap_name]\n",
    "#         # plot heatmap\n",
    "#         im = ax.imshow(perc_matrices[i], cmap=cmap_name, vmin=0, vmax=100)\n",
    "#         # remove ticks\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#         ax.set_xticklabels([])\n",
    "#         ax.set_yticklabels([])\n",
    "#         # set title\n",
    "#         title = cm_names[i].replace(\"_\", \"\\n\")\n",
    "#         axtitle = ax.set_title(title, fontsize=7, fontweight=600, wrap=True)\n",
    "#         # force the wrap line width to be shorter\n",
    "#         axtitle._get_wrap_line_width = lambda: 600.0  #  wrap to 600 screen pixels\n",
    "#         # annotate values in each box, with dark text for light background and light text for dark background\n",
    "#         fontweight = 500\n",
    "#         a_size = 5\n",
    "#         for j in range(2):\n",
    "#             for k in range(2):\n",
    "#                 if perc_matrices[i][j][k] < 50:\n",
    "#                     text = ax.text(\n",
    "#                         k,\n",
    "#                         j,\n",
    "#                         f\"{round(matrices[i][j][k], 2)}\\n({round(perc_matrices[i][j][k], 2)}%)\",\n",
    "#                         ha=\"center\",\n",
    "#                         va=\"center\",\n",
    "#                         color=cmap(1.0),\n",
    "#                         fontsize=a_size,\n",
    "#                         fontweight=fontweight,\n",
    "#                     )\n",
    "#                 else:\n",
    "#                     text = ax.text(\n",
    "#                         k,\n",
    "#                         j,\n",
    "#                         # round(matrices[i][j][k], 2),\n",
    "#                         f\"{round(matrices[i][j][k], 2)}\\n({round(perc_matrices[i][j][k], 2)}%)\",\n",
    "#                         ha=\"center\",\n",
    "#                         va=\"center\",\n",
    "#                         color=cmap(0.0),\n",
    "#                         fontsize=a_size,\n",
    "#                         fontweight=fontweight,\n",
    "#                     )\n",
    "\n",
    "#     # set ticks\n",
    "#     axs[0].set_yticks([0, 1])\n",
    "#     axs[0].set_yticklabels([\"P\", \"N\"], fontsize=6, fontweight=500)\n",
    "#     axs[0].set_xticks([0, 1])\n",
    "#     axs[0].set_xticklabels([\"P\", \"N\"], fontsize=6, fontweight=500)\n",
    "\n",
    "#     # set y label\n",
    "#     axs[0].set_ylabel(\"truth\", fontsize=7, fontweight=600)\n",
    "#     axs[0].set_xlabel(\"prediction\", fontsize=7, fontweight=600)\n",
    "\n",
    "#     # set common title\n",
    "#     fig.suptitle(\n",
    "#         f\"confusion matrices for multilabel RF on {ml_input}\",\n",
    "#         fontsize=9,\n",
    "#         fontweight=600,\n",
    "#     )\n",
    "\n",
    "#     # set suptitle on y axis (for later when looping across all folders)\n",
    "#     # fig.text(0.02, 0.5, \"confusion matrices for multilable RF on\", fontsize=8, fontweight=600, rotation=90, va=\"center\")\n",
    "\n",
    "#     # set tight layout\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # set colorbar\n",
    "#     cbar = fig.colorbar(im, ax=axs, shrink=0.8, orientation=\"horizontal\")\n",
    "#     cbar.ax.tick_params(labelsize=6)\n",
    "#     # add label to colorbar\n",
    "#     cbar.ax.set_xlabel(\"% of compounds\", fontsize=7)\n",
    "\n",
    "#     # get path to folder where confusion matrices are, using os.path.dirname\n",
    "#     save_path = \"/\".join(matrix_path.split(\"/\")[:-1])\n",
    "#     logging.info(matrix_path, save_path)\n",
    "#     # save figure\n",
    "#     plt.savefig(\n",
    "#         matrix_path.replace(\"_matrix.txt\", \"_heatmap.png\"), dpi=500, bbox_inches=\"tight\"\n",
    "#     )\n",
    "#     plt.clf()\n",
    "#     plt.close()\n",
    "#     exit(0)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7 - Butina Clustering with distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters = Butina.ClusterData(\n",
    "#         dist_matrix, num_fps, 0.2, isDistData=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory: chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from biosynfoni.inoutput import *\n",
    "\n",
    "pathway_data = pd.read_csv(\"~/article_bsf/data/input/metacyc_pathways.tsv\", sep=\"\\t\", index_col=0)\n",
    "pathway_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for idx, info in pathway_data.groupby(\"pathway_id\"):\n",
    "    lengths.append(len(info[\"reaction_id\"].tolist()))\n",
    "\n",
    "# histogram of chain lengths\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.show()\n",
    "\n",
    "# lengths above 10\n",
    "lengths = [length for length in lengths if length > 10]\n",
    "\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_info = pathway_data[[\"reaction_id\", \"left\",\"direction\", \"right\"]]\n",
    "reaction_info[reaction_info[\"left\"].str.contains(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pathway_graphs(pathway_data):\n",
    "    pathways = {}\n",
    "    for pathway_id, info in pathway_data.groupby(\"pathway_id\"):\n",
    "        pathways[pathway_id] = nx.DiGraph()\n",
    "        for _, row in info.iterrows():\n",
    "            pathways[pathway_id].add_edge(row[\"left\"], row[\"right\"], reaction_id = row[\"reaction_id\"])\n",
    "    return pathways\n",
    "\n",
    "def get_longest_chains(pathways: dict): #, with_compounds: list | None = None):\n",
    "    for pathway_id, pathway_graph in pathways.items():\n",
    "        # if not with_compounds is None:\n",
    "        #     nodes_to_remove = [node for node in pathway_graph.nodes if node not in with_compounds]\n",
    "        #     pathway_graph.remove_nodes_from(nodes_to_remove)\n",
    "        # if graph is cyclic, iterate over all nodes to find the longest path with all_simple_paths\n",
    "        if not nx.is_directed_acyclic_graph(pathway_graph):\n",
    "            longest_path = []\n",
    "            for node in pathway_graph.nodes:\n",
    "                for path in nx.all_simple_paths(pathway_graph, source=node, target=pathway_graph.nodes):\n",
    "                    if len(path) > len(longest_path):\n",
    "                        longest_path = path\n",
    "        else:\n",
    "            longest_path = nx.dag_longest_path(pathway_graph)\n",
    "        yield pathway_id, longest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = get_pathway_graphs(pathway_data)\n",
    "longest_chains = dict(get_longest_chains(pathways))#, with_compounds=compounds[\"UNIQUE-ID\"].tolist()))\n",
    "\n",
    "longest_chains = dict(sorted(longest_chains.items(), key=lambda x: len(x[1]), reverse=True))\n",
    "\n",
    "# get the edge information\n",
    "# nx_graph[longest_path[i]][longest_path[i+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(longest_chains[\"PWY-8152\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph\n",
    "nx.draw(pathways[\"PWY-8152\"], with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the graphs\n",
    "if not os.path.exists(\"pathway_graphs\"):\n",
    "    Path(\"pathway_graphs\").mkdir(exist_ok=False)\n",
    "\n",
    "for pathway_id, pathway_graph in pathways.items():\n",
    "    nx.write_edgelist(pathway_graph, f\"pathway_graphs/{pathway_id}.edgelist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsf_ext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
