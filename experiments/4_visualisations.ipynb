{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "\n",
    "from biosynfoni.moldrawing import draw, _get_highlight_loc_and_col\n",
    "\n",
    "colourDict = {\n",
    "    \"fp\": {  # colours from colorbrewer2.org for qualitative data\n",
    "        \"bsf\": \"#66c2a5\",  # teal\n",
    "        \"maccs\": \"#fc8d62\",  # orange\n",
    "        \"rdk\": \"#8da0cb\",  # purpleblue\n",
    "        \"morgan\": \"#e78ac3\",  # pink\n",
    "    },\n",
    "    \"fp_ls\": {\n",
    "        \"bsf\": \"-\",\n",
    "        \"maccs\": \"-.\",\n",
    "        \"rdk\": (5, (10, 3)),\n",
    "        \"morgan\": \"dotted\",\n",
    "    },\n",
    "    \"taxonomy\": {\n",
    "        \"Viridiplantae\": \"#B9C311\",  # green\n",
    "        \"Bacteria\": \"#9BC2BA\",  # teal\n",
    "        \"Fungi\": \"#CFC0D6\",  # purple\n",
    "        \"Metazoa\": \"#FFAD61\",  # light orange\n",
    "        \"Archaea\": \"#EB6737\",  # soft red\n",
    "        \"Eukaryota\": \"#D2CEC4\",  # pale grey\n",
    "        \"Cellular organisms\": \"#FFEAA0\",  # yellow\n",
    "        \"Opisthokonta\": \"#FFC4CE\",  # pink\n",
    "    },\n",
    "    \"separation\": {\n",
    "        \"1\": \"#081d58\",  #'#57BAC0',  # navy,\n",
    "        \"2\": \"#225ea8\",  #'#77BC4D',  # royal blue,\n",
    "        \"3\": \"#41b6c4\",  #'#F3C55F',  # teal,\n",
    "        \"4\": \"#7fcdbb\",  #'#F48861',  # turquoise,\n",
    "        \"5\": \"#a7d9b4\",  #'#F7A8B8',  # lemon green,\n",
    "        \"6\": \"#c7e9b4\",  #'#F9CDAE',  # pale green,\n",
    "        \"7\": \"#FFEAA0\",  # yellow\n",
    "        \"8\": \"#FF8B61\",  # orange\n",
    "        # \"-1\": \"#c7e9b4\",  #'#797979',  # lemon green,\n",
    "        \"-1\": \"#797979\",  #'#797979',  # grey,\n",
    "        \"random pairs\": \"#c7e9b4\",\n",
    "        \"control\": \"#c7e9b4\",\n",
    "        \n",
    "    },\n",
    "    \"pathways\": {\n",
    "        \"shikimate\": \"#A783B6\",  # purple\n",
    "        \"acetate\": \"#FF8B61\",  # orange,\n",
    "        \"mevalonate\": \"#B9C311\",  # green,\n",
    "        \"methylerythritol\": \"#6FB5C6\",  # blue\n",
    "        \"sugar\": \"#FFC4CE\",  # pink\n",
    "        \"amino\": \"#FFEAA0\",  # yellow\n",
    "        \"amino_acid\": \"#FFEAA0\",  # yellow\n",
    "    },\n",
    "    \"class\": {\n",
    "        # \"Terpenoids\": \"#9BC2BA\",  # soft bluegreen\n",
    "        \"Terpenoids\": \"#B9C311\",  # green\n",
    "        \"Alkaloids\": \"#B4CAD8\",  # purple\n",
    "        \"Shikimates and Phenylpropanoids\": \"#A783B6\",  # purple\n",
    "        \"Fatty acids\": \"#FF8B61\",  # orange\n",
    "        \"Carbohydrates\": \"#FFC4CE\",  # pink\n",
    "        \"Polyketides\": \"#C21100\",  # soft red\n",
    "        \"Amino acids and Peptides\": \"#FFEAA0\",  # yellow\n",
    "        \"No NP-Classifier prediction\": \"#797979\",\n",
    "        \"None\": \"#595959\",\n",
    "        \"Synthetic\": \"#393939\",\n",
    "        \"Multiple\": \"#BBBBBB\",\n",
    "        # lowercase\n",
    "        # \"terpenoids\": \"#9BC2BA\",  # soft bluegreen\n",
    "        \"terpenoids\": \"#B9C311\",  # green\n",
    "        \"alkaloids\": \"#B4CAD8\",  # purple\n",
    "        \"shikimates and phenylpropanoids\": \"#A783B6\",  # purple\n",
    "        \"fatty acids\": \"#FF8B61\",  # orange\n",
    "        \"carbohydrates\": \"#FFC4CE\",  # pink\n",
    "        \"polyketides\": \"#C21100\",  # soft red\n",
    "        \"amino acids and peptides\": \"#FFEAA0\",  # yellow\n",
    "        # chebi:\n",
    "        \"phenylpropanoid\": \"#A783B6\",  # purple\n",
    "        \"fatty_acid\": \"#FF8B61\",  # orange\n",
    "        \"polyketide\": \"#C21100\",  # soft red\n",
    "        \"alkaloid\": \"#B4CAD8\",  # purple\n",
    "        # \"isoprenoid\": \"#9BC2BA\",  # soft bluegreen\n",
    "        \"isoprenoid\": \"#B9C311\",  # green\n",
    "        \"carbohydrate\": \"#FFC4CE\",  # pink\n",
    "        \"amino_acid\": \"#FFEAA0\",  # yellow\n",
    "        \"synthetic\": \"#393939\",  # grey\n",
    "    },\n",
    "    \"NPClassifier prediction\": {\n",
    "        \"Terpenoids\": \"#B9C311\",  # green\n",
    "        \"Alkaloids\": \"#B4CAD8\",  # purple\n",
    "        \"Shikimates and Phenylpropanoids\": \"#A783B6\",  # purple\n",
    "        \"Fatty acids\": \"#FF8B61\",  # orange\n",
    "        \"Carbohydrates\": \"#FFC4CE\",  # pink\n",
    "        \"Polyketides\": \"#C21100\",  # soft red\n",
    "        \"Amino acids and Peptides\": \"#FFEAA0\",  # yellow\n",
    "        \"No NP-Classifier prediction\": \"#797979\",\n",
    "        \"None\": \"#595959\",\n",
    "        \"Synthetic\": \"#393939\",\n",
    "        \"Multiple\": \"#BBBBBB\",\n",
    "    },\n",
    "    \"chebi class\": {\n",
    "        \"phenylpropanoid\": \"#A783B6\",  # purple\n",
    "        \"fatty_acid\": \"#FF8B61\",  # orange\n",
    "        \"polyketide\": \"#C21100\",  # soft red\n",
    "        \"alkaloid\": \"#B4CAD8\",  # purple\n",
    "        # \"isoprenoid\": \"#9BC2BA\",  # soft bluegreen\n",
    "        \"isoprenoid\": \"#B9C311\",  # green\n",
    "        \"carbohydrate\": \"#FFC4CE\",  # pink\n",
    "        \"amino_acid\": \"#FFEAA0\",  # yellow\n",
    "        \"synthetic\": \"#393939\",  # grey\n",
    "    },\n",
    "}\n",
    "fp_ac_to_name = {\n",
    "    \"bsf\": \"Biosynfoni\",\n",
    "    \"maccs\": \"MACCS\",\n",
    "    \"rdk\": \"RDKit\",\n",
    "    \"morgan\": \"Morgan\",\n",
    "}\n",
    "fp_name_to_ac = {v: k for k, v in fp_ac_to_name.items()}\n",
    "colourDict[\"fp\"].update({fp_ac_to_name[k]: v for k, v in colourDict[\"fp\"].items()})\n",
    "colourDict[\"separation\"].update({separation: colour\n",
    "    for separation, colour in zip(\n",
    "        range(1, 7),\n",
    "        sns.color_palette(\"mako\", n_colors=7),\n",
    "        )\n",
    "    })\n",
    "# colourDict[\"separation\"].update({str(k): v for k, v in colourDict[\"separation\"].items()})\n",
    "\n",
    "# set the biosynfoni style\n",
    "plt.style.use(\"biostylefoni.mplstyle\")\n",
    "\n",
    "folder = Path.home() / \"article_bsf\"\n",
    "fig_folder = folder / \"figures\"\n",
    "fig_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1: fingerprint example, pathway similarity example, biosynthetic distance results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## biosynthetic distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/output/biosynthetic_distances.tsv\", sep=\"\\t\"\n",
    ")\n",
    "df.separation = df.separation.astype(str).replace(\"-1\", \"random pairs\")\n",
    "df.separation = df.separation.apply(lambda x: x.zfill(2))\n",
    "df.replace(-1, 0, inplace=True)\n",
    "together = df.melt(id_vars=[\"separation\"], value_vars=[\"bsf\", \"maccs\", \"rdk\", \"morgan\"])\n",
    "together.rename(\n",
    "    columns={\"value\": \"similarity\", \"variable\": \"fingerprint\"}, inplace=True\n",
    ")\n",
    "\n",
    "hue_kws = {\"ls\": [\"-\", \"-.\", (5, (10, 3)), \"dotted\"]}\n",
    "g = sns.FacetGrid(\n",
    "    together,\n",
    "    row=\"separation\",\n",
    "    hue=\"fingerprint\",\n",
    "    hue_kws=hue_kws,\n",
    "    palette=colourDict[\"fp\"],\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    aspect=5,\n",
    "    height=1,\n",
    ")\n",
    "\n",
    "\n",
    "g.refline(y=0, linewidth=1, linestyle=\"-\", color=\"grey\", clip_on=False)\n",
    "g.map(sns.kdeplot, \"similarity\", fill=True, alpha=0.3, lw=0, zorder=-1)\n",
    "g.map(\n",
    "    sns.kdeplot,\n",
    "    \"similarity\",\n",
    "    lw=1.5,\n",
    "    alpha=1,\n",
    "    zorder=30,\n",
    "    fill=False,\n",
    ")\n",
    "\n",
    "# # change the hue_kws to change the linestyle\n",
    "# hue_kws = {\"ls\": [\"-\", \"-\", \"-\", \"-\"]}\n",
    "# g.add_legend(bbox_to_anchor=(0.07, 0.9), loc=\"upper left\")\n",
    "# g.hue_kws = hue_kws\n",
    "# g.map(sns.kdeplot, \"similarity\", fill=False, lw=1.5, zorder=-5, color=\"w\")\n",
    "\n",
    "\n",
    "# for the first column, add the separation as text above the refline\n",
    "for ax, separation in zip(g.axes[:, 0], together.separation.unique()):\n",
    "    ax.text(\n",
    "        0,\n",
    "        0.15,\n",
    "        int(separation) if separation != \"random pairs\" else \"random\\npairs\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=12,\n",
    "        fontweight=\"medium\",\n",
    "    )\n",
    "    # add the number of compounds in the separation\n",
    "    n = len(df[df.separation == separation])\n",
    "    ax.text(\n",
    "        1,\n",
    "        0.1,\n",
    "        f\"n={n}\",\n",
    "        ha=\"right\",\n",
    "        va=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=8,\n",
    "        fontweight=\"medium\",\n",
    "    )\n",
    "\n",
    "\n",
    "g.figure.subplots_adjust(\n",
    "    hspace=-0.6,\n",
    "    # wspace=-1,\n",
    ")\n",
    "\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "\n",
    "handles, labels = g._legend_data.values(), g._legend_data.keys()\n",
    "labels = [fp_ac_to_name[label] for label in labels]\n",
    "g.add_legend(handles=handles, labels=labels,bbox_to_anchor=(0.09, 0.9), loc=\"upper left\")\n",
    "\n",
    "g.despine(bottom=True, left=True)\n",
    "# add legend\n",
    "\n",
    "# crop 10 pixels from the top\n",
    "plt.savefig(\"ridgeplot.png\", bbox_inches=\"tight\", pad_inches=0.1)\n",
    "img = plt.imread(\"ridgeplot.png\")\n",
    "# crop top 10 pixels\n",
    "plt.imsave(\n",
    "    fig_folder / \"biosynthetic_distance.png\", img[200:, :]\n",
    ")  # to cut off the top 10 pixels due to high y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/output/biosynthetic_distances.tsv\", sep=\"\\t\"\n",
    ")\n",
    "df.separation = df.separation.astype(str).replace(\"-1\", \"random pairs\")\n",
    "# make them all 01, 02, 03, 04, 05, 06, 07, 08, 09, 10\n",
    "df.separation = df.separation.apply(lambda x: x.zfill(2))\n",
    "df.replace(-1, 0, inplace=True)\n",
    "\n",
    "# make a boxplot of the data for each column in the dataframe, per separation, all vertical boxplots\n",
    "fp_colours = {\n",
    "    \"bsf\": \"#66c2a5\",\n",
    "    \"maccs\": \"#fc8d62\",\n",
    "    \"rdk\": \"#8da0cb\",\n",
    "    \"morgan\": \"#e78ac3\",\n",
    "}\n",
    "together = df.melt(id_vars=[\"separation\"], value_vars=[\"bsf\", \"maccs\", \"rdk\", \"morgan\"])\n",
    "together.rename(\n",
    "    columns={\"value\": \"similarity\", \"variable\": \"fingerprint\"}, inplace=True\n",
    ")\n",
    "\n",
    "palette = {\n",
    "    separation: colour\n",
    "    for separation, colour in zip(\n",
    "        together.separation.unique()[:-1],\n",
    "        sns.color_palette(\"mako\", n_colors=len(together.separation.unique()) - 1),\n",
    "    )\n",
    "}\n",
    "palette[\"random pairs\"] = \"#888\"\n",
    "g = sns.FacetGrid(\n",
    "    together,\n",
    "    row=\"fingerprint\",\n",
    "    hue=\"separation\",\n",
    "    palette=palette,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    aspect=2,\n",
    "    height=1.5,\n",
    ")\n",
    "g.refline(y=0, linewidth=1, linestyle=\"-\", color=\"grey\", clip_on=False)\n",
    "\n",
    "# add the multiple kde plots for each fingerprint\n",
    "for fp in together.fingerprint.unique():\n",
    "    g.map(sns.kdeplot, \"similarity\", fill=True, alpha=0.1, lw=0, zorder=2)\n",
    "    g.map(\n",
    "        sns.kdeplot,\n",
    "        \"similarity\",\n",
    "        lw=1,\n",
    "        alpha=1,\n",
    "        zorder=3,\n",
    "        fill=False,\n",
    "    )\n",
    "    g.add_legend()\n",
    "    for text in g.legend.texts:\n",
    "        text.set_text(\n",
    "            f\"{int(text.get_text()) if text.get_text() != 'random pairs' else text.get_text()}\"\n",
    "        )\n",
    "    g.map(sns.kdeplot, \"similarity\", fill=True, alpha=0.6, lw=5, zorder=1, color=\"w\")\n",
    "g.figure.subplots_adjust(hspace=-0.5)\n",
    "\n",
    "# add the labels for each refline\n",
    "for ax, fingerprint in zip(g.axes[:, 0], together.fingerprint.unique()):\n",
    "    ax.text(\n",
    "        0,\n",
    "        0.1,\n",
    "        fp_ac_to_name[fingerprint],\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=8,\n",
    "        fontweight=\"medium\",\n",
    "    )\n",
    "\n",
    "    # get the location of the last line for each ax\n",
    "    line = ax.get_lines()[-1]\n",
    "    xdata, ydata = line.get_xdata(), line.get_ydata()\n",
    "    idx = np.where(ydata > ydata.max() / 3)[0][\n",
    "        0\n",
    "    ]  # first index where the ydata is higher than 1/3 of the max\n",
    "    x, y = xdata[idx], ydata[idx]\n",
    "    # add the text\n",
    "    ax.text(\n",
    "        x - 0.02,\n",
    "        y,\n",
    "        \"random pairs\",\n",
    "        ha=\"right\",\n",
    "        va=\"center\",\n",
    "        fontsize=5,\n",
    "        fontweight=\"bold\",\n",
    "        color=palette[\"random pairs\"],\n",
    "    )\n",
    "    line = ax.get_lines()[together.separation.nunique()]\n",
    "    xdata, ydata = line.get_xdata(), line.get_ydata()\n",
    "    # last 10% of the x-axis\n",
    "    idx = ydata.argmax()\n",
    "    x, y = xdata[idx], ydata[idx]\n",
    "    # add the text\n",
    "    ax.text(\n",
    "        x + 0.02,\n",
    "        y - 0.01,\n",
    "        \"compound pairs \\n  with one reaction \\n        between them\",\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=5,\n",
    "        fontweight=\"bold\",\n",
    "        color=palette[\"01\"],\n",
    "    )\n",
    "    if fingerprint == \"bsf\":\n",
    "        maxima = []\n",
    "        n = together.separation.nunique()\n",
    "        for i in range(n - 1):\n",
    "            line = ax.get_lines()[n + i]\n",
    "            xdata = line.get_xdata()\n",
    "            ydata = line.get_ydata()\n",
    "            idx = ydata.argmax()\n",
    "            x, y = xdata[idx], ydata[idx]\n",
    "            maxima.append((x, y))\n",
    "        # add a curved arrow in white connecting the maxima\n",
    "        ax.annotate(\n",
    "            \"\",\n",
    "            xy=maxima[0],\n",
    "            xytext=maxima[-1],\n",
    "            arrowprops=dict(\n",
    "                arrowstyle=\"<-\",\n",
    "                lw=1.5,\n",
    "                color=\"w\",\n",
    "                connectionstyle=\"arc3,rad=0.2\",\n",
    "            ),\n",
    "            zorder=1000,\n",
    "        )\n",
    "\n",
    "\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "# make ticklabels for the x-axis bigger\n",
    "\n",
    "g.despine(bottom=True, left=True)\n",
    "\n",
    "plt.savefig(fig_folder/\"sm_biosynthetic_distance_separations.png\", bbox_inches=\"tight\", pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fingerprint example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "from biosynfoni import draw_with_highlights\n",
    "\n",
    "df = pd.read_csv(\n",
    "    folder / \"data\" / \"input\" / \"coconut_properties.csv\",\n",
    ")\n",
    "fp = np.loadtxt(folder / \"fps\" / \"coconut_bsf.csv\", delimiter=\",\", dtype=int)\n",
    "df[\"n_bits\"] = fp.astype(bool).astype(int).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe by the number of bits set\n",
    "df = df.sort_values(\"n_bits\", ascending=False)\n",
    "row = df.iloc[140]  # 70 is nice\n",
    "\n",
    "mol = Chem.MolFromSmiles(row.canonical_smiles)\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = draw_with_highlights(mol)\n",
    "with open(fig_folder / \"mol.svg\", \"w\") as f:\n",
    "    f.write(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pathway reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/output/reconstructed_pathways.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    "    index_col=0,\n",
    ")\n",
    "# read in lists as lists\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if not pd.isna(x) else x)\n",
    "# find where bsf_independent is same as true but maccs_independent is different\n",
    "\n",
    "df[\"true_r\"] = df[\"true\"].apply(lambda x: x[::-1])\n",
    "\n",
    "\n",
    "def correct(col):\n",
    "    return (df[col] == df[\"true\"]) | (df[col] == df[\"true_r\"])\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "for key, val in {\n",
    "    \"bsf\": \"biosynfoni\",\n",
    "    \"maccs\": \"maccs\",\n",
    "    \"rdk\": \"rdkit\",\n",
    "    \"morgan\": \"morgan\",\n",
    "}.items():\n",
    "    independent = df[correct(f\"{key}_independent\")]\n",
    "    with_hint = df[correct(f\"{key}_f_start\") | correct(f\"{key}_f_end\")]\n",
    "    travellings_salesman = df[correct(f\"{key}_tsp\")]\n",
    "\n",
    "    # independent = df[(df[f\"{key}_independent\"] == df.true )| (df[f\"{key}_independent\"] == df.true_r)]\n",
    "    # with_hint = df[(df[f\"{key}_f_start\"] == df.true) | (df[f\"{key}_f_end\"] == df.true)]\n",
    "\n",
    "    print(\n",
    "        val,\n",
    "        \"independent: \",\n",
    "        independent.shape[0],\n",
    "        \"with hint: \",\n",
    "        with_hint.shape[0],\n",
    "        \"out of \",\n",
    "        df.shape[0],\n",
    "    )\n",
    "    ind_lengths = [len(x) for x in independent[\"true\"]]\n",
    "    with_lengths = [len(x) for x in with_hint[\"true\"]]\n",
    "\n",
    "    print(\n",
    "        \"independent: \",\n",
    "        np.mean(ind_lengths),\n",
    "        np.std(ind_lengths),\n",
    "        \"with hint: \",\n",
    "        np.mean(with_lengths),\n",
    "        np.std(with_lengths),\n",
    "    )\n",
    "    print(\"travellings_salesman: \", travellings_salesman.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_common_subsequence(true_list, list2):\n",
    "    m, n = len(true_list), len(list2)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if true_list[i - 1] == list2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "\n",
    "def percentage(true_list, list2):\n",
    "    return longest_common_subsequence(true_list, list2) / len(true_list)\n",
    "\n",
    "\n",
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "b = [7, 8, 9, 10, 1, 2, 3, 4, 5]\n",
    "\n",
    "print(longest_common_subsequence(a, b))\n",
    "\n",
    "for key, val in {\n",
    "    \"bsf\": \"biosynfoni\",\n",
    "    \"maccs\": \"maccs\",\n",
    "    \"rdk\": \"rdkit\",\n",
    "    \"morgan\": \"morgan\",\n",
    "}.items():\n",
    "    count = 0\n",
    "    for pathway in df.index:\n",
    "        true_pathway = df.loc[pathway, \"true\"]\n",
    "        predicted_pathway = df.loc[pathway, f\"{key}_independent\"]\n",
    "        if not isinstance(predicted_pathway, list):\n",
    "            continue\n",
    "        lcs_length = longest_common_subsequence(true_pathway, predicted_pathway)\n",
    "        if lcs_length >= 0.7 * len(true_pathway):\n",
    "            count += 1\n",
    "    print(\n",
    "        f\"{val}: {count} reactions have an LCS >= 0.7 of the length of the true pathway\"\n",
    "    )\n",
    "    results = []\n",
    "\n",
    "# plot the percentages function result of the independent and with_hint pathways for each key val per length of the true pathway\n",
    "fig, ax = plt.subplots()\n",
    "for key, val in {\n",
    "    \"bsf\": \"biosynfoni\",\n",
    "    \"maccs\": \"maccs\",\n",
    "    \"rdk\": \"rdkit\",\n",
    "    \"morgan\": \"morgan\",\n",
    "}.items():\n",
    "    results = []\n",
    "    for pathway in df.index:\n",
    "        true_pathway = df.loc[pathway, \"true\"]\n",
    "        predicted_pathway = df.loc[pathway, f\"{key}_independent\"]\n",
    "        if not isinstance(predicted_pathway, list):\n",
    "            continue\n",
    "        results.append(\n",
    "            longest_common_subsequence(true_pathway, predicted_pathway)\n",
    "            / len(true_pathway)\n",
    "        )\n",
    "    sns.histplot(results, bins=20, ax=ax, label=val, kde=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"true\"] = df[\"true\"].apply(ast.literal_eval)\n",
    "len(df.loc[\"PWY-8133\"].true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the pathway\n",
    "from rdkit import Chem\n",
    "\n",
    "id_to_mol = {\n",
    "    mol.GetProp(\"compound_id\"): mol\n",
    "    for mol in Chem.SDMolSupplier(f\"{Path().home()}/article_bsf/data/input/metacyc.sdf\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pws = [\n",
    "    \"PWY-6915\",\n",
    "    \"PWY-7135\",\n",
    "    \"PWY-7483\",\n",
    "    \"PWY-7711\",\n",
    "    \"PWY-7736\",\n",
    "    \"PWY-8133\",\n",
    "    \"PWY2DNV-5\",\n",
    "]\n",
    "compare = [\"bsf_f_start\", \"rdk_f_start\"]\n",
    "# for pw in pws[1:]:\n",
    "for pw in pws[0:]:\n",
    "    mols = [id_to_mol[cpd] for cpd in df.loc[pw].true]\n",
    "    # draw mols to grid\n",
    "    print(\n",
    "        *[\n",
    "            id_\n",
    "            for id_ in zip(\n",
    "                df.loc[pw].true, df.loc[pw][compare[0]], df.loc[pw][compare[1]]\n",
    "            )\n",
    "        ],\n",
    "        sep=\"\\n\",\n",
    "    )\n",
    "    break\n",
    "Chem.Draw.MolsToGridImage(\n",
    "    mols,\n",
    "    molsPerRow=5,\n",
    "    subImgSize=(200, 200),\n",
    "    legends=[mol.GetProp(\"_Name\") for mol in mols],\n",
    ")\n",
    "# get similarities between the mols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2: Applicability domain - calculation times, coverage, substructure distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times(fp_name) -> np.array:\n",
    "    return np.loadtxt(\n",
    "        f\"{Path().home()}/article_bsf/fps/coconut_{fp_name}_times.csv\",\n",
    "        delimiter=\",\",\n",
    "        dtype=float,\n",
    "    )\n",
    "\n",
    "\n",
    "def time_size_stats(times, sizes) -> np.array:\n",
    "    \"\"\"\n",
    "    Function to get the data per fingerprint\n",
    "    \"\"\"\n",
    "    assert len(times) == len(sizes), \"The length of times and sizes should be the same\"\n",
    "\n",
    "    unique_sizes = np.unique(sizes)\n",
    "\n",
    "    average_times = []\n",
    "    for size in unique_sizes:\n",
    "        average_times.append(np.mean(times[sizes == size]))\n",
    "\n",
    "    std_times = []\n",
    "    for size in unique_sizes:\n",
    "        std_times.append(np.std(times[sizes == size]))\n",
    "\n",
    "    return np.array(\n",
    "        [\n",
    "            (size, avg_time, std_time)\n",
    "            for size, avg_time, std_time in zip(unique_sizes, average_times, std_times)\n",
    "        ],\n",
    "        dtype=[(\"size\", int), (\"average_time\", float), (\"std_time\", float)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_names = fp_ac_to_name\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "properties_path = Path().home() / \"article_bsf/data/input/coconut_properties.csv\"\n",
    "sizes = pd.read_csv(properties_path, index_col=0)[\"heavy_atom_count\"].values.tolist()\n",
    "for fp_name in actual_names.keys():\n",
    "    ax.set_xlabel(\"Number of heavy atoms\")\n",
    "    ax.set_ylabel(\"Time (ms)\")\n",
    "\n",
    "    data = time_size_stats(times(fp_name)*1000, sizes)\n",
    "    ax.plot(\n",
    "        data[\"size\"],\n",
    "        data[\"average_time\"],\n",
    "        color=colourDict[\"fp\"][fp_name],\n",
    "        label=actual_names[fp_name],\n",
    "        linestyle=colourDict[\"fp_ls\"][fp_name],\n",
    "        zorder=2,\n",
    "    )\n",
    "\n",
    "    # plot the 50% confidence interval around the average time per size\n",
    "    ax.fill_between(\n",
    "        data[\"size\"],\n",
    "        data[\"average_time\"] - 0.5 * data[\"std_time\"],\n",
    "        data[\"average_time\"] + 0.5 * data[\"std_time\"],\n",
    "        color=colourDict[\"fp\"][fp_name],\n",
    "        alpha=0.3,\n",
    "        zorder=1,\n",
    "    )\n",
    "\n",
    "# plot the sizes behind it with the y axis on the right\n",
    "ax_twin = ax.twinx()\n",
    "ax_twin.hist(\n",
    "    sizes,\n",
    "    bins=np.linspace(0, data[\"size\"].max(), data[\"size\"].max()),\n",
    "    alpha=0.1,\n",
    "    color=\"black\",\n",
    "    zorder=0,\n",
    ")\n",
    "ax_twin.set_ylabel(\"Number of molecules\")\n",
    "# set all ticklabelsize to 8\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "ax_twin.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "\n",
    "\n",
    "ax.legend(title=\"Fingerprint\", loc=\"upper left\", bbox_to_anchor=(1.16, 1))\n",
    "fig.savefig(fig_folder / \"generation_times_full.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_names = fp_ac_to_name\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "properties_path = Path().home() / \"article_bsf/data/input/coconut_properties.csv\"\n",
    "sizes = pd.read_csv(properties_path, index_col=0)[\"heavy_atom_count\"].values.tolist()\n",
    "for fp_name in actual_names.keys():\n",
    "    ax.set_xlabel(\"Number of heavy atoms\")\n",
    "    ax.set_ylabel(\"Time (ms)\")\n",
    "\n",
    "    data = time_size_stats(times(fp_name)*1000, sizes)\n",
    "    data = data[data[\"size\"] < 100]\n",
    "    ax.plot(\n",
    "        data[\"size\"],\n",
    "        data[\"average_time\"],\n",
    "        color=colourDict[\"fp\"][fp_name],\n",
    "        label=actual_names[fp_name],\n",
    "        linestyle=colourDict[\"fp_ls\"][fp_name],\n",
    "        zorder=2,\n",
    "    )\n",
    "\n",
    "    # plot the 50% confidence interval around the average time per size\n",
    "    ax.fill_between(\n",
    "        data[\"size\"],\n",
    "        data[\"average_time\"] - 0.5 * data[\"std_time\"],\n",
    "        data[\"average_time\"] + 0.5 * data[\"std_time\"],\n",
    "        color=colourDict[\"fp\"][fp_name],\n",
    "        alpha=0.3,\n",
    "        zorder=1,\n",
    "    )\n",
    "\n",
    "# plot the sizes behind it with the y axis on the right\n",
    "ax_twin = ax.twinx()\n",
    "ax_twin.hist(\n",
    "    sizes,\n",
    "    bins=np.linspace(0, data[\"size\"].max(), data[\"size\"].max()),\n",
    "    alpha=0.1,\n",
    "    color=\"black\",\n",
    ")\n",
    "ax_twin.set_ylabel(\"Number of molecules\")\n",
    "# set all ticklabelsize to 8\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "ax_twin.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "\n",
    "\n",
    "ax.legend(handles=handles, title=\"Fingerprint\", loc=\"upper left\", bbox_to_anchor=(1.16, 1))\n",
    "fig.savefig(fig_folder / \"generation_times_cropped.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(times(\"maccs\")),np.average(times(\"maccs\"))*len(sizes))\n",
    "print(np.average(times(\"morgan\")),np.average(times(\"morgan\"))*len(sizes))\n",
    "print(np.average(times(\"rdk\")),np.average(times(\"rdk\"))*len(sizes))\n",
    "print(np.average(times(\"bsf\")),np.average(times(\"bsf\"))*len(sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substructure occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from biosynfoni.subkeys import get_names, get_smarts\n",
    "\n",
    "\n",
    "ar = np.loadtxt(\n",
    "    f\"{Path().home()}/article_bsf/fps/coconut_bsf.csv\",\n",
    "    delimiter=\",\",\n",
    "    dtype=int,\n",
    ")\n",
    "df = pd.DataFrame(ar, columns=get_names())\n",
    "colours = [\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"#FFEAA0\",\n",
    "        \"#FFEAA0\",\n",
    "        \"#FFC4CE\",  \n",
    "        \"#FFC4CE\",  \n",
    "        \"#FFC4CE\",  \n",
    "        \"#FFC4CE\",  \n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#B9C311\",  \n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(1, 4))\n",
    "# plot the minimum and the maximum of the substructure counts as points, and make a thick line between connect them\n",
    "min_max = df.agg([\"min\", \"max\"])\n",
    "for i in range(min_max.shape[1]):\n",
    "    plt.plot(\n",
    "        [min_max.iloc[0, i], min_max.iloc[1, i]],\n",
    "        [i, i],\n",
    "        linewidth=1,\n",
    "        alpha=0.5,\n",
    "        color=colours[i],\n",
    "    )\n",
    "    # plt.plot(\n",
    "    #     [min_max.iloc[0, i], min_max.iloc[1, i]],\n",
    "    #     [i, i],\n",
    "    #     linewidth=0,\n",
    "    #     markersize=2,\n",
    "    #     marker=\"o\",\n",
    "    #     markerfacecolor=mpl.color_sequences[\"tab10\"][i%10],\n",
    "    #     markeredgecolor=\"none\",\n",
    "    # )\n",
    "mean = df.agg([\"mean\"])\n",
    "\n",
    "for i in range(mean.shape[1]):\n",
    "    plt.plot(\n",
    "        mean.iloc[0, i],\n",
    "        i,\n",
    "        marker=\"|\",\n",
    "        markersize=3,\n",
    "        markeredgecolor=\"black\",\n",
    "        linewidth=0,\n",
    "        alpha=0.5,\n",
    "        zorder=4,\n",
    "    )\n",
    "\n",
    "q1_q3 = df.agg([\"quantile\"], q=[0.25, 0.75])\n",
    "for i in range(q1_q3.shape[1]):\n",
    "    plt.plot(\n",
    "        [q1_q3.iloc[0, i], q1_q3.iloc[1, i]],\n",
    "        [i, i],\n",
    "        marker=\"o\",\n",
    "        linewidth=3,\n",
    "        markersize=2,\n",
    "        markerfacecolor=\"none\",\n",
    "        markeredgecolor=colours[i],\n",
    "        color=colours[i],\n",
    "    )\n",
    "# set correct y labels from df.columns\n",
    "plt.yticks(range(len(df.columns)), df.columns)\n",
    "# reverse order of y labels\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(1, 500)\n",
    "# remove x ticks and labels\n",
    "plt.yticks([])\n",
    "\n",
    "# show y axis line\n",
    "# ax.spines[\"left\"].set_linewidth(0.5)\n",
    "plt.savefig(fig_folder / \"occurrences.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes too long\n",
    "# fig, ax = plt.subplots(figsize=(1, 5))\n",
    "# # plot the minimum and the maximum of the substructure counts as points, and make a thick line between connect them\n",
    "\n",
    "# sns.catplot(data=df, orient=\"h\", alpha=0.01, s=1, ax=ax, kind=\"swarm\", palette=colours)\n",
    "\n",
    "# # set correct y labels from df.columns\n",
    "# plt.yticks(range(len(df.columns)), df.columns)\n",
    "# # reverse order of y labels\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.xscale(\"log\")\n",
    "# plt.xlim(1, 500)\n",
    "# # remove x ticks and labels\n",
    "# plt.yticks([])\n",
    "\n",
    "# # show y axis line\n",
    "# # ax.spines[\"left\"].set_linewidth(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMI map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse, logging, os\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from tqdm import tqdm\n",
    "\n",
    "from figures import set_label_colors\n",
    "\n",
    "\n",
    "def add_minuses(heatmap, array):\n",
    "    for i in range(array.shape[0]):\n",
    "        for j in range(array.shape[1]):\n",
    "            text = \"\"\n",
    "            # if array[i, j] > 0:\n",
    "            #     text = \"+\"\n",
    "            if array[i, j] < 0:\n",
    "                text = \"-\"\n",
    "            heatmap.text(\n",
    "                j + 0.5,\n",
    "                i + 0.5,\n",
    "                text,\n",
    "                horizontalalignment=\"center\",\n",
    "                verticalalignment=\"center\",\n",
    "                color=\"white\",\n",
    "            )\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_labels() -> list[str]:\n",
    "    keys = [\n",
    "        \"coa\",\n",
    "        \"nadh\",\n",
    "        \"nadph\",\n",
    "        \"all standard aminos\",\n",
    "        \"non-standard aminos\",\n",
    "        \"open pyranose\",\n",
    "        \"open furanose\",\n",
    "        \"pyranose\",\n",
    "        \"furanose\",\n",
    "        \"indoleC2N\",\n",
    "        \"phenylC2N\",\n",
    "        \"c5n\",\n",
    "        \"c4n\",\n",
    "        \"phenylC3\",\n",
    "        \"phenylC2\",\n",
    "        \"phenylC1\",\n",
    "        \"isoprene\",\n",
    "        \"acetyl\",\n",
    "        \"methylmalonyl\",\n",
    "        \"ethyl\",\n",
    "        \"methyl\",\n",
    "        \"phosphate\",\n",
    "        \"sulfonate\",\n",
    "        \"fluorine\",\n",
    "        \"chlorine\",\n",
    "        \"bromine\",\n",
    "        \"iodine\",\n",
    "        \"nitrate\",\n",
    "        \"epoxy\",\n",
    "        \"ether\",\n",
    "        \"hydroxyl\",\n",
    "        \"c3 ring\",\n",
    "        \"c4 ring\",\n",
    "        \"c5 ring\",\n",
    "        \"c6 ring\",\n",
    "        \"c7 ring\",\n",
    "        \"c8 ring\",\n",
    "        \"c9 ring\",\n",
    "        \"c10 ring\",\n",
    "    ]\n",
    "    return keys\n",
    "\n",
    "\n",
    "def get_colours() -> list[str]:\n",
    "    colours = [\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"#FFEAA0\",\n",
    "        \"#FFEAA0\",\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#B9C311\",  # green\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "    ]\n",
    "    return colours\n",
    "\n",
    "\n",
    "def _pearson_correlation_matrix(fps: np.array) -> np.array:\n",
    "    # randomly subsample 10000\n",
    "\n",
    "    # fps = fps[np.random.choice(fps.shape[0], 10000, replace=False), 3:]\n",
    "    # fps = fps[:, 3:]\n",
    "    mat = np.corrcoef(fps, rowvar=False, dtype=np.float16)\n",
    "    # print(fps.shape)\n",
    "    # print(mat.shape)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def correlation_heatmap(fps: np.array) -> None:\n",
    "    keys = get_labels()\n",
    "    correlations = _pearson_correlation_matrix(fps)\n",
    "    np.savetxt(\"correlations.tsv\", correlations, delimiter=\"\\t\", fmt=\"%.2f\")\n",
    "    logging.warning(correlations.shape)\n",
    "    hm = sns.heatmap(\n",
    "        correlations,\n",
    "        xticklabels=keys,\n",
    "        yticklabels=keys,\n",
    "        # cmap=\"coolwarm\",\n",
    "        cmap=\"PiYG\",  # more colorblind-friendly diverging colormap\n",
    "        vmin=np.min(fps),\n",
    "        vmax=np.max(fps),\n",
    "        center=0,  # center of the colormap\n",
    "    )\n",
    "    # hm.text(0.5, 0.5, \"test\", horizontalalignment=\"center\", verticalalignment=\"center\")\n",
    "    # for all negative values, add a minus sign\n",
    "    add_minuses(hm, fps)\n",
    "    colours = get_colours()\n",
    "    xt, yt = hm.get_xticklabels(), hm.get_yticklabels()\n",
    "    # set_label_colors(hm.get_xticklabels(), colours)\n",
    "    # set_label_colors(hm.get_yticklabels(), colours)\n",
    "    return hm\n",
    "\n",
    "\n",
    "fps = np.loadtxt(Path.home() / \"article_bsf\" / \"fps\" / \"coconut_bsf.csv\", delimiter=\",\")\n",
    "\n",
    "\n",
    "# Count the number of times each bit is set.\n",
    "cx = Counter()\n",
    "cxy = Counter()\n",
    "\n",
    "for idx in tqdm(range(fps.shape[0])):\n",
    "    for bit_idx, bit in enumerate(fps[idx]):\n",
    "        if bit > 0:\n",
    "            cx[bit_idx] += bit\n",
    "\n",
    "        for bit_idx2, bit2 in enumerate(fps[idx]):\n",
    "            # if bit_idx == bit_idx2:\n",
    "            #     continue\n",
    "            if bit > 0 and bit2 > 0:\n",
    "                # cxy[(bit_idx, bit_idx2)] += 1\n",
    "                cxy[(bit_idx, bit_idx2)] += min(bit, bit2)\n",
    "\n",
    "# Create lookup between key and fingerprint index.\n",
    "x2i, i2x = {}, {}\n",
    "keys = get_labels()\n",
    "for i, x_data in enumerate(keys):\n",
    "    x2i[x_data] = i\n",
    "    i2x[i] = x_data\n",
    "\n",
    "# Build sparse PMI matrix.\n",
    "sx = sum(cx.values())\n",
    "sxy = sum(cxy.values())\n",
    "data, rows, cols = [], [], []\n",
    "for (x_data, y_data), n in cxy.items():\n",
    "    rows.append(x_data)\n",
    "    cols.append(y_data)\n",
    "    data.append(math.log((n / sxy) / (cx[x_data] / sx) / (cx[y_data] / sx)))\n",
    "\n",
    "PMI = csc_matrix((data, (rows, cols)))\n",
    "mat = PMI.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize matrix.\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "hm = sns.heatmap(\n",
    "    mat,\n",
    "    xticklabels=keys,\n",
    "    yticklabels=keys,\n",
    "    # cmap=\"coolwarm\",\n",
    "    cmap=\"PiYG\",  # more colorblind-friendly diverging colormap\n",
    "    vmin=np.min(mat),\n",
    "    vmax=np.max(mat),\n",
    "    center=0,  # center of the colormap\n",
    ")\n",
    "add_minuses(hm, mat)\n",
    "\n",
    "# make ticklabels bold\n",
    "hm.set_yticklabels(hm.get_yticklabels(), fontweight=\"bold\")\n",
    "hm.set_xticklabels(hm.get_xticklabels(), fontweight=\"bold\")\n",
    "\n",
    "# set_label_colors(hm.get_xticklabels(), colours)\n",
    "# set_label_colors(hm.get_yticklabels(), colours)\n",
    "colours = get_colours()\n",
    "set_label_colors(hm.get_xticklabels(), colours)\n",
    "set_label_colors(hm.get_yticklabels(), colours)\n",
    "# get the colorbar and rotate the ticklabels\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "# make it shorter\n",
    "cbar.ax.set_ylabel(\"Pointwise Mutual Information\", rotation=90, labelpad=15)\n",
    "\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.savefig(fig_folder / \"pmi.png\", bbox_inches=\"tight\")\n",
    "\n",
    "# set all tick labels to \"L\"\n",
    "plt.xticks(hm.get_xticks(), [\"    \" for _ in hm.get_xticks()])\n",
    "plt.yticks(hm.get_yticks(), [\"    \" for _ in hm.get_yticks()])\n",
    "\n",
    "plt.savefig(fig_folder / \"pmi_no_labels.png\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "# plt.savefig( bbox_inches=\"tight\")\n",
    "# plt.close()\n",
    "\n",
    "# # get a correlation heatmap as well\n",
    "# corr_hm = correlation_heatmap(fps)\n",
    "# plt.title(\"Pearson correlation - non-overlap Biosynfoni on COCONUT\", size=12)\n",
    "# plt.savefig(args.o.replace(\".png\", \"_correlation.png\"), bbox_inches=\"tight\")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse, logging, os\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# from helper import  set_label_colors\n",
    "\n",
    "\n",
    "def add_minuses(heatmap, array):\n",
    "    for i in range(array.shape[0]):\n",
    "        for j in range(array.shape[1]):\n",
    "            text = \"\"\n",
    "            # if array[i, j] > 0:\n",
    "            #     text = \"+\"\n",
    "            if array[i, j] < 0:\n",
    "                text = \"-\"\n",
    "            heatmap.text(\n",
    "                j + 0.5,\n",
    "                i + 0.5,\n",
    "                text,\n",
    "                horizontalalignment=\"center\",\n",
    "                verticalalignment=\"center\",\n",
    "                color=\"white\",\n",
    "            )\n",
    "    return None\n",
    "\n",
    "\n",
    "def set_label_colors(ticklabels: list, colors: list) -> str:\n",
    "    \"\"\"\n",
    "    Set the colours of labels\n",
    "\n",
    "        Args:\n",
    "            ticklabels (list): list of labels to change\n",
    "            colors (list): list of colours to change to\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    for label, color in zip(ticklabels, colors):\n",
    "        # label.set_color(COLOUR_DICT[axis][label.get_text()])\n",
    "        plt.setp(\n",
    "            label,\n",
    "            backgroundcolor=color,\n",
    "            bbox=dict(\n",
    "                facecolor=color,\n",
    "                alpha=0.5,\n",
    "                # boxstyle=\"round, rounding_size=0.8\",\n",
    "                boxstyle=\"round, rounding_size=0.7\",\n",
    "                edgecolor=\"none\",\n",
    "            ),\n",
    "        )  # , height=0.3))\n",
    "        # t.set_bbox(dict(facecolor=color, alpha=0.5, boxstyle=\"round\"))  # , height=0.3))\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_labels() -> list[str]:\n",
    "    keys = [\n",
    "        \"coa\",\n",
    "        \"nadh\",\n",
    "        \"nadph\",\n",
    "        \"all standard aminos\",\n",
    "        \"non-standard aminos\",\n",
    "        \"open pyranose\",\n",
    "        \"open furanose\",\n",
    "        \"pyranose\",\n",
    "        \"furanose\",\n",
    "        \"indoleC2N\",\n",
    "        \"phenylC2N\",\n",
    "        \"c5n\",\n",
    "        \"c4n\",\n",
    "        \"phenylC3\",\n",
    "        \"phenylC2\",\n",
    "        \"phenylC1\",\n",
    "        \"isoprene\",\n",
    "        \"acetyl\",\n",
    "        \"methylmalonyl\",\n",
    "        \"ethyl\",\n",
    "        \"methyl\",\n",
    "        \"phosphate\",\n",
    "        \"sulfonate\",\n",
    "        \"fluorine\",\n",
    "        \"chlorine\",\n",
    "        \"bromine\",\n",
    "        \"iodine\",\n",
    "        \"nitrate\",\n",
    "        \"epoxy\",\n",
    "        \"ether\",\n",
    "        \"hydroxyl\",\n",
    "        \"c3 ring\",\n",
    "        \"c4 ring\",\n",
    "        \"c5 ring\",\n",
    "        \"c6 ring\",\n",
    "        \"c7 ring\",\n",
    "        \"c8 ring\",\n",
    "        \"c9 ring\",\n",
    "        \"c10 ring\",\n",
    "    ]\n",
    "    return keys\n",
    "\n",
    "\n",
    "def get_colours() -> list[str]:\n",
    "    colours = [\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"#FFEAA0\",\n",
    "        \"#FFEAA0\",\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#FFC4CE\",  # pink\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#A783B6\",\n",
    "        \"#B9C311\",  # green\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"#FF8B61\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "        \"grey\",\n",
    "    ]\n",
    "    return colours\n",
    "\n",
    "\n",
    "def _pearson_correlation_matrix(fps: np.array) -> np.array:\n",
    "    # randomly subsample 10000\n",
    "\n",
    "    # fps = fps[np.random.choice(fps.shape[0], 10000, replace=False), 3:]\n",
    "    # fps = fps[:, 3:]\n",
    "    mat = np.corrcoef(fps, rowvar=False, dtype=np.float16)\n",
    "    # print(fps.shape)\n",
    "    # print(mat.shape)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def correlation_heatmap(fps: np.array) -> None:\n",
    "    keys = get_labels()\n",
    "    correlations = _pearson_correlation_matrix(fps)\n",
    "    np.savetxt(\"correlations.tsv\", correlations, delimiter=\"\\t\", fmt=\"%.2f\")\n",
    "    logging.warning(correlations.shape)\n",
    "    hm = sns.heatmap(\n",
    "        correlations,\n",
    "        xticklabels=keys,\n",
    "        yticklabels=keys,\n",
    "        cmap=\"PiYG\",  # more colorblind-friendly diverging colormap\n",
    "        vmin=np.min(fps),\n",
    "        vmax=np.max(fps),\n",
    "        center=0,  # center of the colormap\n",
    "    )\n",
    "    # for all negative values, add a minus sign\n",
    "    add_minuses(hm, fps)\n",
    "    colours = get_colours()\n",
    "    xt, yt = hm.get_xticklabels(), hm.get_yticklabels()\n",
    "    set_label_colors(hm.get_xticklabels(), colours)\n",
    "    set_label_colors(hm.get_yticklabels(), colours)\n",
    "    return hm\n",
    "\n",
    "\n",
    "fps = np.loadtxt(Path.home() / \"article_bsf\" / \"fps\" / \"coconut_bsf.csv\", delimiter=\",\")\n",
    "\n",
    "\n",
    "# Count the number of times each bit is set.\n",
    "cx = Counter()\n",
    "cxy = Counter()\n",
    "\n",
    "for idx in tqdm(range(fps.shape[0])):\n",
    "    for bit_idx, bit in enumerate(fps[idx]):\n",
    "        if bit > 0:\n",
    "            cx[bit_idx] += bit\n",
    "\n",
    "        for bit_idx2, bit2 in enumerate(fps[idx]):\n",
    "            # if bit_idx == bit_idx2:\n",
    "            #     continue\n",
    "            if bit > 0 and bit2 > 0:\n",
    "                # cxy[(bit_idx, bit_idx2)] += 1\n",
    "                cxy[(bit_idx, bit_idx2)] += min(bit, bit2)\n",
    "\n",
    "# Create lookup between key and fingerprint index.\n",
    "x2i, i2x = {}, {}\n",
    "keys = get_labels()\n",
    "for i, x_data in enumerate(keys):\n",
    "    x2i[x_data] = i\n",
    "    i2x[i] = x_data\n",
    "\n",
    "# Build sparse PMI matrix.\n",
    "sx = sum(cx.values())\n",
    "sxy = sum(cxy.values())\n",
    "data, rows, cols = [], [], []\n",
    "for (x_data, y_data), n in cxy.items():\n",
    "    rows.append(x_data)\n",
    "    cols.append(y_data)\n",
    "    data.append(math.log((n / sxy) / (cx[x_data] / sx) / (cx[y_data] / sx)))\n",
    "\n",
    "PMI = csc_matrix((data, (rows, cols)))\n",
    "mat = PMI.toarray()\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "# hm = sns.heatmap(\n",
    "#     mat,\n",
    "#     xticklabels=keys,\n",
    "#     yticklabels=keys,\n",
    "#     cmap=\"PiYG\",  # more colorblind-friendly diverging colormap\n",
    "#     vmin=np.min(mat),\n",
    "#     vmax=np.max(mat),\n",
    "#     center=0,  # center of the colormap\n",
    "# )\n",
    "# Z-score normalization of the rows\n",
    "zscored_mat = zscore(mat, axis=1)\n",
    "\n",
    "# Update the heatmap with the z-scored matrix\n",
    "hm = sns.heatmap(\n",
    "    zscored_mat,\n",
    "    xticklabels=keys,\n",
    "    yticklabels=keys,\n",
    "    cmap=\"PiYG\",  # more colorblind-friendly diverging colormap\n",
    "    vmin=np.min(zscored_mat),\n",
    "    vmax=np.max(zscored_mat),\n",
    "    center=0,  # center of the colormap\n",
    ")\n",
    "add_minuses(hm, mat)\n",
    "\n",
    "hm.set_yticklabels(hm.get_yticklabels(), fontweight=\"bold\")\n",
    "hm.set_xticklabels(hm.get_xticklabels(), fontweight=\"bold\")\n",
    "\n",
    "\n",
    "plt.ylabel(\"Substructues\")\n",
    "plt.xlabel(\"Substructues\")\n",
    "plt.title(f\"Pointwise Mutual Information of Biosynfoni Substructures\", size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "len(\n",
    "    set(\n",
    "        chain(\n",
    "            *[\n",
    "                match\n",
    "                for match in Biosynfoni(Chem.SDMolSupplier(sdf_path)[0]).matches\n",
    "                for match in match\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# Chem.SDMolSupplier(sdf_path)[0].GetNumHeavyAtoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/data/raw_data/coconut_complete-10-2024.csv\"\n",
    ")\n",
    "df = df[~df.organisms.isna()]\n",
    "\n",
    "# from rdkit.Chem import PandasTools\n",
    "# coconut_ = PandasTools.LoadSDF(f\"{Path().home()}/article_bsf/data/_old_raw_data/COCONUT_DB.sdf\")\n",
    "# print(len(coconut_))\n",
    "\n",
    "# coconut_ = coconut_.query(\"textTaxa != '[notax]'\").copy()\n",
    "# print(len(coconut_))\n",
    "# coconut_\n",
    "# r\"textTaxa.*\\n\\[[^n]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.organisms.str.lower().str.contains(\"fungus\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/data/input/coconut_taxonomy.csv\",\n",
    "    header=None,\n",
    "    names=[\"compounds\", \"taxonomy\"],\n",
    ")\n",
    "print(df_.shape)  # 695133\n",
    "df_ = df_[~df_.taxonomy.isna()]\n",
    "print(df_.shape)  # 11286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the projected data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(projected_X, columns=[\"x\", \"y\"])\n",
    "df[\"class\"] = np.loadtxt(\n",
    "    f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "    delimiter=\",\",\n",
    "    dtype=str,\n",
    "    usecols=1,\n",
    ")[:1000]\n",
    "\n",
    "sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"class\", palette=\"tab20\")\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "X = pd.DataFrame(X, columns=iris.feature_names)\n",
    "from tmap.tda import mapper, Filter\n",
    "from tmap.tda.cover import Cover\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Step1. initiate a Mapper\n",
    "tm = mapper.Mapper(verbose=1)\n",
    "# Step2. Projection\n",
    "lens = [Filter.MDS(components=[0, 1], random_state=100)]\n",
    "projected_X = tm.filter(X, lens=lens)\n",
    "clusterer = DBSCAN(eps=0.75, min_samples=1)\n",
    "cover = Cover(\n",
    "    projected_data=MinMaxScaler().fit_transform(projected_X),\n",
    "    resolution=20,\n",
    "    overlap=0.75,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3: Applications - unsupervised clustering, supervised classification, biosynthetic pathway reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import PandasTools\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/output/bsf_tsne.csv\", header=None, names=[\"bsf_x\", \"bsf_y\"]\n",
    ")\n",
    "df[[\"maccs_x\", \"maccs_y\"]] = np.loadtxt(\n",
    "    f\"{Path().home()}/article_bsf/output/maccs_tsne.csv\", delimiter=\",\", dtype=float\n",
    ")\n",
    "# in this one, the tsne is better comparable if you mirror along the x axis\n",
    "df[\"maccs_x\"] = -df[\"maccs_x\"]\n",
    "\n",
    "df[\"class\"] = np.loadtxt(\n",
    "    f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "    delimiter=\",\",\n",
    "    dtype=str,\n",
    "    usecols=1,\n",
    ")\n",
    "df[\"class\"] = df[\"class\"].apply(lambda x: x.replace(\"_\", \" \"))\n",
    "df[\"id\"] = np.loadtxt(\n",
    "    f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "    delimiter=\",\",\n",
    "    dtype=str,\n",
    "    usecols=0,\n",
    ")\n",
    "\n",
    "# get a df from the sdf\n",
    "sdf_path = Path().home()/\"article_bsf/data/input/chebi.sdf\"\n",
    "df[\"mol\"] = [mol for mol in Chem.SDMolSupplier(sdf_path)]\n",
    "df[\"size\"] = [mol.GetNumHeavyAtoms() for mol in df[\"mol\"]]\n",
    "\n",
    "# remove all molecules that have an \"R\" in them\n",
    "df = df[~df[\"mol\"].apply(lambda x: Chem.MolToSmiles(x).count(\"*\") > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.scatterplot(data=df[~df[\"class\"].str.contains(\";\")], x=\"bsf_x\", y=\"bsf_y\", hue=\"class\", palette=\"Spectral\", alpha=0.5)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), markerscale=3)\n",
    "for handle in plt.gca().get_legend_handles_labels()[0]:\n",
    "    handle.set_alpha(1)\n",
    "    \n",
    "plt.xlabel(\"\"), plt.ylabel(\"\")\n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=False,  left=False, labelbottom=False, labelleft=False)\n",
    "plt.savefig(fig_folder / \"tsne_bsf.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the middle fatty acids\n",
    "sel = df[df[\"class\"] == \"fatty_acid\"] \n",
    "sel = sel[(sel.bsf_x<10)& (sel.bsf_x>-10) & (sel.bsf_y<20) & (sel.bsf_y>-20)]\n",
    "\n",
    "sel\n",
    "Chem.Draw.MolsToGridImage(\n",
    "    sel.mol.values,\n",
    "    molsPerRow=5,\n",
    "    subImgSize=(200, 200),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the middle fatty acids\n",
    "sel = df[df[\"class\"] == \"fatty_acid\"] \n",
    "sel = sel[(sel.bsf_x<10)& (sel.bsf_x>-10) & (sel.bsf_y<-80)]\n",
    "\n",
    "sel\n",
    "Chem.Draw.MolsToGridImage(\n",
    "    sel.mol.values,\n",
    "    molsPerRow=5,\n",
    "    subImgSize=(200, 200),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the leftmost carbohydrate cluster\n",
    "sel = df[df[\"class\"] == \"carbohydrate\"] \n",
    "sel = sel[sel.bsf_x<0]\n",
    "sel = sel[sel.bsf_y>50]\n",
    "sel\n",
    "Chem.Draw.MolsToGridImage(\n",
    "    sel.mol.values,\n",
    "    molsPerRow=5,\n",
    "    subImgSize=(200, 200),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the leftmost carbohydrate cluster\n",
    "sel = df[df[\"class\"] == \"carbohydrate\"] \n",
    "sel = sel[sel.bsf_x<-80]\n",
    "sel\n",
    "Chem.Draw.MolsToGridImage(\n",
    "    sel.mol.values,\n",
    "    molsPerRow=5,\n",
    "    subImgSize=(200, 200),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.scatterplot(data=df[~df[\"class\"].str.contains(\";\")], x=\"maccs_x\", y=\"maccs_y\", hue=\"class\", palette=\"Spectral\", alpha=0.5)\n",
    "sns.scatterplot(data=sel, x=\"maccs_x\", y=\"maccs_y\", c=\"k\",alpha=1)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), markerscale=3)\n",
    "for handle in plt.gca().get_legend_handles_labels()[0]:\n",
    "    handle.set_alpha(1)\n",
    "\n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=False,  left=False, labelbottom=False, labelleft=False)\n",
    "plt.savefig(fig_folder / \"tsne_maccs_carbohydrates.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.Draw.MolsToGridImage(\n",
    "    sel[sel.maccs_y<-100].mol.values,\n",
    "    molsPerRow=5,\n",
    "    subImgSize=(200, 200),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Chem.Draw.MolsToGridImage(\n",
    "    sel[sel.maccs_y>-10].mol.values,\n",
    "    molsPerRow=5,\n",
    "    subImgSize=(200, 200),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "o_f = Path.home() / \"article_bsf\" / \"output\"\n",
    "labels = np.loadtxt(o_f / \"classifications.tsv\", delimiter=\"\\t\", dtype=str)\n",
    "\n",
    "\n",
    "def multilabel_and_dict(classifications: np.array) -> tuple[np.array, dict]:\n",
    "    classes = set(\";\".join(map(str, classifications)).split(\";\"))\n",
    "    class_to_id = {class_: i for i, class_ in enumerate(sorted(classes))}\n",
    "    id_to_class = {i: class_ for class_, i in class_to_id.items()}\n",
    "    classification_array = np.zeros((len(classifications), len(classes)), dtype=int)\n",
    "    for i, classification in enumerate(classifications):\n",
    "        for class_ in re.split(r\"[;,]\", classification):\n",
    "            classification_array[i, class_to_id[class_]] = 1\n",
    "    return classification_array, id_to_class\n",
    "\n",
    "\n",
    "y_true, id_to_class = multilabel_and_dict(labels)\n",
    "\n",
    "\n",
    "df = pd.read_csv(o_f / \"ids.tsv\", sep=\"\\t\", dtype=str, header=None, index_col=0)\n",
    "df[\"y_true\"] = y_true.tolist()\n",
    "df[\"class\"] = labels\n",
    "df[\"k\"] = np.loadtxt(o_f / \"ks.csv\", dtype=int)\n",
    "files = (file for file in o_f.glob(\"*_proba.tsv\") if not file.stem.startswith(\"tax\"))\n",
    "for n, file in enumerate(files):\n",
    "    fp_name = file.stem.split(\"_\")[0]\n",
    "    df[file.stem] = np.loadtxt(file, delimiter=\"\\t\", dtype=float).tolist()\n",
    "    df[file.stem.replace(\"proba\", \"pred\")] = df[file.stem].apply(\n",
    "        lambda x: (np.array(x) > 0.5).astype(int).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# ig, ax = plt.subplots(2, 2, figsize=(5, 5))\n",
    "# separate the binarised predictions from the probabilities per class\n",
    "y = np.array(df[\"y_true\"].tolist())\n",
    "bsf_proba = np.array(df[\"bsf_proba\"].tolist())\n",
    "maccs_proba = np.array(df[\"maccs_proba\"].tolist())\n",
    "morgan_proba = np.array(df[\"morgan_proba\"].tolist())\n",
    "rdk_proba = np.array(df[\"rdk_proba\"].tolist())\n",
    "\n",
    "\n",
    "k_idx = {k: df[df[\"k\"] == k].index for k in range(5)}\n",
    "\n",
    "fp_names = [col.split(\"_\")[0] for col in proba]\n",
    "fp_idx = {fp: i for i, fp in enumerate(fp_names)}\n",
    "\n",
    "\n",
    "def df_class(df, class_i):\n",
    "    df = df.copy()\n",
    "    cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if str(col).endswith(\"pred\") or str(col).endswith(\"proba\")\n",
    "    ]\n",
    "    cols += [\"y_true\"]\n",
    "    df[cols] = np.array(df[cols].values.tolist())[:, :, class_i]\n",
    "    return df\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"precision\": precision_score,\n",
    "    \"recall\": recall_score,\n",
    "    \"f1\": f1_score,\n",
    "    \"roc_auc\": roc_auc_score,\n",
    "    \"average_precision\": average_precision_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(\n",
    "    df[[col for col in df.columns if str(col).endswith(\"pred\")]].values.tolist()\n",
    ")\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example multi-label DataFrame\n",
    "data = df\n",
    "\n",
    "# Flatten to single-class DataFrame\n",
    "cols = [\n",
    "    col\n",
    "    for col in data.columns\n",
    "    if str(col).endswith(\"pred\") or str(col).endswith(\"proba\")\n",
    "]\n",
    "cols.append(\"y_true\")\n",
    "flattened_data = data.explode(cols).reset_index()\n",
    "flattened_data[\"class_id\"] = np.tile(range(len(data[\"y_true\"][0])), len(data))\n",
    "flattened_data\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(df, metrics):\n",
    "    results = []\n",
    "    for k, fold_data in df.groupby(\"k\"):\n",
    "        for cls in fold_data[\"class_id\"].unique():\n",
    "            cls_data = fold_data[fold_data[\"class_id\"] == cls]\n",
    "            for clf in [col for col in df.columns if str(col).endswith(\"pred\")]:\n",
    "                metrics_result = {\n",
    "                    metric.__name__: metric(\n",
    "                        cls_data[\"y_true\"].astype(int), cls_data[clf].astype(int)\n",
    "                    )\n",
    "                    for metric in metrics\n",
    "                }\n",
    "                metrics_result.update({\"classifier\": clf, \"class_id\": cls, \"k\": k})\n",
    "                results.append(metrics_result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "]\n",
    "metric_results = compute_metrics(flattened_data, metrics)\n",
    "melted_results = metric_results.melt(\n",
    "    id_vars=[\"class_id\", \"k\", \"classifier\"],\n",
    "    value_vars=[metric.__name__ for metric in metrics],\n",
    "    var_name=\"metric\",\n",
    "    value_name=\"value\",\n",
    ")\n",
    "melted_results[\"classifier\"] = melted_results[\"classifier\"].str.replace(\"_pred\", \"\")\n",
    "replacements = {\n",
    "    \"bsf\": \"Biosynfoni\",\n",
    "    \"maccs\": \"MACCS\",\n",
    "    \"morgan\": \"Morgan\",\n",
    "    \"rdk\": \"RDKit\",\n",
    "}\n",
    "melted_results[\"classifier\"] = melted_results[\"classifier\"].replace(replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import lines as mlines\n",
    "\n",
    "palette = colourDict[\"fp\"]\n",
    "g = sns.catplot(\n",
    "    data=melted_results,\n",
    "    x=\"classifier\",\n",
    "    y=\"value\",\n",
    "    col=\"class_id\",\n",
    "    row=\"metric\",\n",
    "    hue=\"classifier\",\n",
    "    kind=\"strip\",  # Change to 'strip' for individual dots\n",
    "    height=2,\n",
    "    aspect=0.5,\n",
    "    palette=palette,\n",
    "    # dodge=True,  # Separate dots by classifier\n",
    "    alpha=0.4,  # Make dots slightly transparent for better overlap visibility\n",
    "    jitter=0.0,  # Add jitter to spread the dots\n",
    ")\n",
    "\n",
    "# Remove individual plot titles\n",
    "g.set_titles(\"\")\n",
    "g.tick_params(\n",
    "    axis=\"x\",\n",
    "    labelrotation=90,\n",
    "    size=0,\n",
    ")\n",
    "g.tick_params(axis=\"y\", size=0)\n",
    "g.set_ylabels(\"\")\n",
    "\n",
    "# Customize plot\n",
    "g.set_axis_labels(\"\", \"\")\n",
    "g.fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "# show gridlines\n",
    "for ax in g.axes.flatten():\n",
    "    ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.spines[\"left\"].set_linewidth(0.5)\n",
    "    ax.spines[\"bottom\"].set_linewidth(0.5)\n",
    "    ax.spines[\"right\"].set_linewidth(0.5)\n",
    "    ax.spines[\"top\"].set_linewidth(0.5)\n",
    "    ax.spines[\"right\"].set_visible(True)\n",
    "    ax.spines[\"top\"].set_visible(True)\n",
    "\n",
    "\n",
    "# Add column titles (over the top of the plot grid)\n",
    "for col_idx, col_name in enumerate(g.col_names):\n",
    "    # get the x position of the axes\n",
    "    xs = [(ax.get_position().x0 + ax.get_position().x1) / 2 for ax in g.axes[0, :]]\n",
    "    text = id_to_class[col_idx].replace(\"_\", \"\\n\")\n",
    "    if text == \"phenylpropanoid\":\n",
    "        text = \"phenyl-\\npropanoid\"\n",
    "    g.fig.text(\n",
    "        x=xs[col_idx],  # Center each title over the column\n",
    "        y=g.axes[0, 0].get_position().y1 + 0.03,  # Position above the plots\n",
    "        s=text,\n",
    "        ha=\"center\",\n",
    "        va=\"top\",\n",
    "        fontsize=8,\n",
    "        fontweight=\"regular\",\n",
    "    )\n",
    "\n",
    "# Add row titles (on the left side of the grid)\n",
    "for row_idx, row_name in enumerate(g.row_names):\n",
    "    ys = [(ax.get_position().y0 + ax.get_position().y1) / 2 for ax in g.axes[:, 0]]\n",
    "    g.fig.text(\n",
    "        x=0.03,  # Position to the left of the plots\n",
    "        y=ys[row_idx],\n",
    "        s=row_name.replace(\"_\", \" \"),\n",
    "        ha=\"right\",\n",
    "        va=\"center\",\n",
    "        fontsize=8,\n",
    "        fontweight=\"regular\",\n",
    "        rotation=90,\n",
    "    )\n",
    "\n",
    "# add a legend from ax[0,0]\n",
    "legend_labels = melted_results[\"classifier\"].unique()\n",
    "handles = [\n",
    "    mlines.Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        markeredgecolor=\"none\",\n",
    "        markerfacecolor=palette[l],\n",
    "        markersize=6,\n",
    "        label=l,\n",
    "    )\n",
    "    for l in legend_labels\n",
    "]\n",
    "\n",
    "# Add the legend to the plot (using `fig.legend`)\n",
    "# get x0 and y1 of the first axis\n",
    "x0, y0 = g.axes[0, 0].get_position().x0, g.axes[0, 0].get_position().y0\n",
    "g.fig.legend(\n",
    "    handles=handles,\n",
    "    title=\"classifier\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(x0 + 0.005, y0 + 0.005),\n",
    "    frameon=True,\n",
    "    fontsize=8,\n",
    "    title_fontsize=8,\n",
    ")\n",
    "plt.savefig(fig_folder / \"sm_metrics.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import lines as mlines\n",
    "\n",
    "palette = colourDict[\"fp\"]\n",
    "\n",
    "plt.figure()\n",
    "g = sns.catplot(\n",
    "    data=melted_results[melted_results.metric == \"f1_score\"],\n",
    "    x=\"classifier\",\n",
    "    y=\"value\",\n",
    "    col=\"class_id\",\n",
    "    hue=\"classifier\",\n",
    "    kind=\"strip\",  # Change to 'strip' for individual dots\n",
    "    height=1.7,\n",
    "    aspect=0.5,\n",
    "    palette=palette,\n",
    "    s=40,\n",
    "    # dodge=True,  # Separate dots by classifier\n",
    "    alpha=0.4,  # Make dots slightly transparent for better overlap visibility\n",
    "    jitter=0.0,  # Add jitter to spread the dots\n",
    ")\n",
    "\n",
    "# Remove individual plot titles\n",
    "g.set_titles(\"\")\n",
    "g.tick_params(\n",
    "    axis=\"x\",\n",
    "    labelrotation=90,\n",
    "    size=0,\n",
    ")\n",
    "g.tick_params(axis=\"y\", size=0)\n",
    "g.set_ylabels(\"\")\n",
    "\n",
    "# Customize plot\n",
    "g.set_axis_labels(\"\", \"F1 score\")\n",
    "g.fig.subplots_adjust(wspace=0)\n",
    "\n",
    "# show gridlines\n",
    "for ax in g.axes.flatten():\n",
    "    ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.spines[\"left\"].set_linewidth(0.5)\n",
    "\n",
    "\n",
    "# Add column titles (over the top of the plot grid)\n",
    "for col_idx, col_name in enumerate(g.col_names):\n",
    "    # get the x position of the axes\n",
    "    xs = [(ax.get_position().x0 + ax.get_position().x1) / 2 for ax in g.axes[0, :]]\n",
    "    text = id_to_class[col_idx].replace(\"_\", \"\\n\")\n",
    "    if text == \"phenylpropanoid\":\n",
    "        text = \"phenyl-\\npropanoid\"\n",
    "    g.fig.text(\n",
    "        x=xs[col_idx],  # Center each title over the column\n",
    "        y=g.axes[0, 0].get_position().y1 + 0.18,  # Position above the plots\n",
    "        s=text,\n",
    "        ha=\"center\",\n",
    "        va=\"top\",\n",
    "        fontsize=8,\n",
    "        fontweight=\"medium\",\n",
    "    )\n",
    "\n",
    "# add a legend from ax[0,0]\n",
    "legend_labels = melted_results[\"classifier\"].unique()\n",
    "handles = [\n",
    "    mlines.Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        markeredgecolor=\"none\",\n",
    "        markerfacecolor=list(palette.values())[i],\n",
    "        markersize=7,\n",
    "        label=legend_labels[i],\n",
    "    )\n",
    "    for i in range(len(legend_labels))\n",
    "]\n",
    "\n",
    "# Add the legend to the plot (using `fig.legend`)\n",
    "# get x0 and y1 of the first axis\n",
    "x0, y0 = g.axes[0, 0].get_position().x0, g.axes[0, 0].get_position().y0\n",
    "g.fig.legend(\n",
    "    handles=handles,\n",
    "    title=\"classifier\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    frameon=True,\n",
    "    fontsize=8,\n",
    "    title_fontsize=8,\n",
    ")\n",
    "\n",
    "# set ylim\n",
    "g.set(ylim=(0.71, 1.03))\n",
    "# save the plot\n",
    "plt.savefig(fig_folder / \"f1_score.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import PandasTools\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tax_info = Path.home() / \"taxonomy.tsv\"\n",
    "\n",
    "\n",
    "tax_info = pd.read_csv(tax_info, sep=\"\\t\\|\\t\", index_col=0)\n",
    "tax_info[\"flags\\t|\"] = tax_info[\"flags\\t|\"].str.strip(\"\\t|\")\n",
    "tax_info.rename(columns={\"flags\\t|\": \"flags\"}, inplace=True)\n",
    "\n",
    "tax_info\n",
    "\n",
    "\n",
    "# get a tree of the taxonomies in tax_info with direction\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for i, row in tqdm(tax_info.iterrows(), total=tax_info.shape[0]):\n",
    "    G.add_node(i, **row.to_dict())\n",
    "    if row[\"parent_uid\"] != \"null\":\n",
    "        G.add_edge(row[\"parent_uid\"], i)\n",
    "\n",
    "\n",
    "uid_name = tax_info[\"name\"].to_dict()\n",
    "name_uid = {v.lower(): k for k, v in uid_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_df = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/data/input/temp_coconut.csv\", sep=\",\"\n",
    ")\n",
    "taxonomies = sdf_df[\"organisms\"].str.lower().str.split(\"|\").explode()\n",
    "\n",
    "taxonomies = taxonomies.map(name_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_f = Path.home() / \"article_bsf\" / \"data\" / \"input\"\n",
    "# sdf_df = PandasTools.LoadSDF(i_f / \"coconut.sdf\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxonomies = sdf_df[\"organisms\"].str.lower().str.split(\"|\").unique().explode()\n",
    "# taxonomies\n",
    "\n",
    "\n",
    "# taxonomies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tax_info[tax_info[\"name\"].str.contains(\"bacteria\")]\n",
    "# tax_info[tax_info[\"rank\"].str.contains(\"kingdom\")]\n",
    "tax_info[tax_info[\"rank\"] == \"kingdom\"]\n",
    "\n",
    "# get children of a node\n",
    "# list(G.successors(5267059))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tax_info[tax_info[\"name\"] ==\"Bacteria\"]\n",
    "# tax_info.head(30)\n",
    "tax_info[tax_info[\"rank\"] == \"domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[uid_name[x] for x in list(G.successors(844192))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_by_rank(uid, G, rank=\"kingdom\"):\n",
    "    # go up the tree until you find a kingdom\n",
    "    while \"rank\" in G.nodes[uid].keys() and G.nodes[uid][\"rank\"] != rank:\n",
    "        uid = list(G.predecessors(uid))[0]\n",
    "    return G.nodes[uid]\n",
    "\n",
    "\n",
    "kingdoms = [\n",
    "    (get_by_rank(taxonomy[0], G) if taxonomy else None) for taxonomy in taxonomies\n",
    "]\n",
    "domains = [\n",
    "    (get_by_rank(taxonomy[0], G, rank=\"domain\") if taxonomy else None)\n",
    "    for taxonomy in taxonomies\n",
    "]\n",
    "# kingdoms\n",
    "# G.nodes[taxonomies[1][0]]['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kingdoms = [(kingdom[\"name\"] if kingdom else None) for kingdom in kingdoms]\n",
    "domains = [(domain[\"name\"] if domain else None) for domain in domains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kingdoms), len(sdf_df)\n",
    "kingdoms = pd.Series(kingdoms, name=\"kingdom\", index=sdf_df.index)\n",
    "kingdoms[\"domains\"] = domains\n",
    "\n",
    "kingdoms.to_csv(i_f / \"temp_coconut_tax.csv\", header=True)\n",
    "kingdoms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kingdoms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_f = Path.home() / \"article_bsf\" / \"output\"\n",
    "\n",
    "y = np.loadtxt(o_f / \"y.csv\", delimiter=\",\", dtype=int)\n",
    "ids = np.loadtxt(o_f / \"tax_ids.tsv\", delimiter=\",\", dtype=str)\n",
    "y_proba = np.loadtxt(o_f / \"tax_bsf_proba.tsv\", delimiter=\"\\t\", dtype=int)\n",
    "y_pred = (y_proba > 0.5).astype(int)\n",
    "\n",
    "cl_idx = o_f / \"tax_class_labels.json\"\n",
    "with open(cl_idx, \"r\") as f:\n",
    "    class_labels = json.load(f)\n",
    "\n",
    "# get the classification report\n",
    "report = classification_report(y, y_pred, target_names=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt(\n",
    "    Path.home() / \"article_bsf\" / \"fps\" / \"coconut_bsf.csv\", delimiter=\",\", dtype=int\n",
    ")\n",
    "y = np.loadtxt(\n",
    "    Path.home() / \"article_bsf\" / \"data\" / \"input\" / \"coconut_taxonomy.csv\",\n",
    "    delimiter=\",\",\n",
    "    dtype=str,\n",
    ")\n",
    "ids, y = y[:, 0], y[:, 1]\n",
    "\n",
    "idx = np.where(y != \"\")\n",
    "\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "ids = ids[idx]\n",
    "\n",
    "# y has multiple classes, so we need to split them and then turn it into a binary matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y.split(\";\") for y in y)\n",
    "y\n",
    "class_labels = mlb.classes_\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'bootstrap': False, 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
    "0.7972974395381592\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200, 500],\n",
    "    \"max_depth\": [20, 50, 100],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=0\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)\n",
    "\n",
    "# get the classification report\n",
    "y_pred = grid_search.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the classification report for the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# get the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# plot the confusion matrix\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try other classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifiers = {\n",
    "    \"SVC\": SVC(),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"MLPClassifier\": MLPClassifier(),\n",
    "}\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=class_labels)\n",
    "    print(report)\n",
    "\n",
    "    # get the confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # plot the confusion matrix\n",
    "    import seaborn as sns\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sdf_path = f\"{Path().home()}/article_bsf/data/input/coconut.sdf\"\n",
    "props_path = f\"{Path().home()}/article_bsf/data/input/coconut_properties.csv\"\n",
    "\n",
    "sizes = pd.read_csv(props_path, index_col=0)[\"heavy_atom_count\"].values\n",
    "coverages = np.loadtxt(\n",
    "    f\"{Path().home()}/article_bsf/fps/coconut_coverage.csv\", delimiter=\",\"\n",
    ")\n",
    "\n",
    "\n",
    "cmap = sns.color_palette(\"mako_r\", as_cmap=True)\n",
    "print(\"average coverage\", np.mean(coverages))\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict({\"sizes\": sizes, \"coverages\": coverages}, orient=\"index\").T\n",
    "df = df[df.sizes < 100]\n",
    "plt.hexbin(\n",
    "    df.sizes, df.coverages, gridsize=50, cmap=cmap, edgecolors=\"white\", linewidths=0.1\n",
    ")\n",
    "plt.colorbar(label=\"Number of molecules\")\n",
    "plt.xlabel(\"Molecular size\")\n",
    "plt.ylabel(\"Coverage\")\n",
    "plt.title(\"Biosynfoni's coverage of natural products\")\n",
    "plt.savefig(fig_folder / \"sm_coverage_vs_size_cropped.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "df = pd.DataFrame.from_dict({\"sizes\": sizes, \"coverages\": coverages}, orient=\"index\").T\n",
    "plt.hexbin(\n",
    "    df.sizes, df.coverages, gridsize=50, cmap=cmap, edgecolors=\"white\", linewidths=0.1\n",
    ")\n",
    "plt.colorbar(label=\"Number of molecules\")\n",
    "plt.xlabel(\"Molecular size\")\n",
    "plt.ylabel(\"Coverage\")\n",
    "plt.title(\"Biosynfoni's coverage of natural products\")\n",
    "plt.savefig(fig_folder / \"sm_coverage_vs_size_full.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "mean_coverage = np.mean(coverages)\n",
    "std_coverage = np.std(coverages)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(2, 3))\n",
    "sns.violinplot(data=coverages, inner=\"box\", edgecolor=\"none\", alpha=0.6, density_norm=\"width\");\n",
    "plt.xlabel(\"coconut dataset\")\n",
    "plt.ylabel(\"atom coverage\")\n",
    "plt.savefig(fig_folder / \"sm_coverage_violinplot.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# plt.xlim(0, 200)\n",
    "# plt.ylim(0, 1)\n",
    "# size_coverage = np.array(\n",
    "#     [(s, c) for s, c in zip(sizes, coverages)],\n",
    "#     dtype=[(\"size\", int), (\"coverage\", float)],\n",
    "# )\n",
    "\n",
    "# sns.scatterplot(\n",
    "#     data=pd.DataFrame(size_coverage),\n",
    "#     x=\"size\",\n",
    "#     y=\"coverage\",\n",
    "#     ax=ax,\n",
    "#     edgecolor=\"none\",\n",
    "#     alpha=0.1,\n",
    "#     s=4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1 - Chemical space of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import seaborn as sns\n",
    "\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maccs_path = f\"{Path().home()}/article_bsf/coconut_maccs.csv\"\n",
    "maccs = np.loadtxt(maccs_path, delimiter=\",\", dtype=int)\n",
    "label = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/data/raw_data/coconut_complete-10-2024.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "random_subset = np.random.choice(maccs.shape[0], 10000, replace=False)\n",
    "subset_maccs = maccs[random_subset]\n",
    "subset_labels = label.iloc[random_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.fit_transform(subset_maccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x=embedding[:, 0], y=embedding[:, 1], hue=subset_labels[\"rotatable_bond_count\"]\n",
    ")  # ,  legend=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices of points that have embedding x < -10 and 0 < y < 5\n",
    "points = embedding[\n",
    "    (embedding[:, 0] < -10) & (0 < embedding[:, 1]) & (embedding[:, 1] < 5)\n",
    "]\n",
    "indices = np.where(\n",
    "    (embedding[:, 0] < -10) & (0 < embedding[:, 1]) & (embedding[:, 1] < 5)\n",
    ")[0]\n",
    "\n",
    "\n",
    "of_interest = subset_labels.iloc[indices]\n",
    "\n",
    "# draw molecules from smiles\n",
    "mols = [Chem.MolFromSmiles(smiles) for smiles in of_interest[\"canonical_smiles\"]]\n",
    "\n",
    "Chem.Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the molecules corresponding to the close points\n",
    "sdf = Chem.SDMolSupplier(sdf_path)\n",
    "\n",
    "for i, j in zip(*close_points):\n",
    "    mol_i = sdf[int(random_subset[i][0])]\n",
    "    mol_j = sdf[int(random_subset[j][0])]\n",
    "    break\n",
    "mol_i, mol_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Biosynthetic distance visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanfmt(text):\n",
    "    \"\"\"\n",
    "    Clean a string or list of strings to be used as labels in a plot\n",
    "\n",
    "        Args:\n",
    "            text (str or list): text to clean\n",
    "\n",
    "        Returns:\n",
    "            str or list: cleaned text\n",
    "\n",
    "    Remarks:\n",
    "        - replaces underscores with spaces\n",
    "        - makes all text lowercase\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text.replace(\"_\", \" \").lower()\n",
    "    elif isinstance(text, list):\n",
    "        newtext = []\n",
    "        for t in text:\n",
    "            if isinstance(t, str):\n",
    "                newtext.append(t.replace(\"_\", \" \").lower())\n",
    "            else:\n",
    "                newtext.append(t)\n",
    "        return newtext\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n",
    "def _set_ax_boxplot_i_colour(\n",
    "    ax_boxplot: mpl.container.BarContainer,\n",
    "    i: int,\n",
    "    colour: str,\n",
    "    inner_alpha: float = 0.6,\n",
    "):\n",
    "    \"\"\"\n",
    "    Set the colour of a boxplot element\n",
    "\n",
    "        Args:\n",
    "            ax_boxplot (matplotlib.container.BarContainer): the boxplot to change\n",
    "            i (int): the index of the element to change\n",
    "            colour (str): the colour to change to\n",
    "            inner_alpha (float): the alpha of the inner colour, optional. Default is 0.6\n",
    "\n",
    "        Returns:\n",
    "            matplotlib.container.BarContainer: the changed boxplot\n",
    "\n",
    "    \"\"\"\n",
    "    translucent = mpl.colors.to_rgba(colour, inner_alpha)\n",
    "\n",
    "    ax_boxplot[\"boxes\"][i].set_facecolor(translucent)\n",
    "    ax_boxplot[\"boxes\"][i].set_edgecolor(colour)\n",
    "    ax_boxplot[\"medians\"][i].set_color(colour)\n",
    "    ax_boxplot[\"whiskers\"][i * 2].set_color(colour)\n",
    "    ax_boxplot[\"whiskers\"][i * 2 + 1].set_color(colour)\n",
    "    ax_boxplot[\"caps\"][i * 2].set_color(colour)\n",
    "    ax_boxplot[\"caps\"][i * 2 + 1].set_color(colour)\n",
    "    ax_boxplot[\"fliers\"][i].set_markeredgecolor(translucent)\n",
    "    return ax_boxplot\n",
    "\n",
    "\n",
    "def scatter_boxplots(\n",
    "    df: pd.DataFrame,\n",
    "    col_x: str,\n",
    "    col_y: str,\n",
    "    color_by: str = \"stepnum\",\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Make a scatterplot with boxplots on the axes\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): dataframe to plot\n",
    "            col_x (str): column to plot on the x-axis\n",
    "            col_y (str): column to plot on the y-axis\n",
    "            figtitle (str): title of the figure\n",
    "            color_by (str): column to colour by, optional. Default is \"stepnum\"\n",
    "            *args: other arguments to pass to scatterplot\n",
    "            **kwargs: other keyword arguments to pass to scatterplot\n",
    "        Returns:\n",
    "            plt.Figure: the figure\n",
    "\n",
    "    \"\"\"\n",
    "    # make a square figure\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    # fig, ax = plt.subplots()\n",
    "    # add gridspec for subplots\n",
    "\n",
    "    gs = fig.add_gridspec(\n",
    "        2,\n",
    "        2,\n",
    "        width_ratios=(4, 1),\n",
    "        height_ratios=(1, 4),\n",
    "        left=0.1,\n",
    "        right=0.9,\n",
    "        bottom=0.1,\n",
    "        top=0.9,\n",
    "        wspace=-1,\n",
    "        hspace=-5,\n",
    "    )\n",
    "\n",
    "    sc_ax = fig.add_subplot(gs[1, 0])\n",
    "    legax = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    # Set aspect of the Axes manually to have points on 0 and 1 show better\n",
    "    # ax.set_xlim(-0.05, 1.05)\n",
    "    # ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "    # Get Data\n",
    "    all_data_x = [\n",
    "        np.array(df[df[color_by] == category][col_x].to_numpy(dtype=float))\n",
    "        for category in df[color_by].unique()\n",
    "    ]\n",
    "    all_data_x = [x[~np.isnan(x)] for x in all_data_x]\n",
    "    all_data_y = [\n",
    "        np.array(df[df[color_by] == category][col_y].tolist())\n",
    "        for category in df[color_by].unique()\n",
    "    ]\n",
    "    all_data_y = [y[~np.isnan(y)] for y in all_data_y]\n",
    "\n",
    "    top_bp_ax = fig.add_subplot(gs[0, 0], sharex=sc_ax)\n",
    "    right_bp_ax = fig.add_subplot(gs[1, 1], sharey=sc_ax)\n",
    "\n",
    "    top_bp_ax.tick_params(length=0, labelbottom=False, labelsize=5)\n",
    "    right_bp_ax.tick_params(length=0, labelrotation=90, labelleft=False, labelsize=5)\n",
    "    legax.tick_params(length=0, labelleft=False, labelbottom=False, labelsize=0)\n",
    "    sc_ax.tick_params(length=0)\n",
    "\n",
    "    labels = [\n",
    "        f\"{category}\" if category != \"-1\" else \"control\"\n",
    "        for category in df[color_by].unique()\n",
    "    ]\n",
    "    # make boxplots where the boxes are 5px apart\n",
    "    xplot = top_bp_ax.boxplot(\n",
    "        all_data_x,\n",
    "        vert=False,\n",
    "        patch_artist=True,\n",
    "        labels=labels,\n",
    "        positions=[0.6 * i for i in range(len(all_data_x))],\n",
    "    )\n",
    "    yplot = right_bp_ax.boxplot(\n",
    "        all_data_y,\n",
    "        vert=True,\n",
    "        patch_artist=True,\n",
    "        labels=labels,\n",
    "        positions=[0.6 * i for i in range(len(all_data_y))],\n",
    "    )\n",
    "\n",
    "    i = 0\n",
    "    for category in df[color_by].unique()[::-1]:\n",
    "        colour = colourDict[color_by][category]\n",
    "\n",
    "        label = f\"{category}\" if category != \"-1\" else \"random pairs\"\n",
    "\n",
    "        scatterplot = sc_ax.scatter(\n",
    "            x=col_x,\n",
    "            y=col_y,\n",
    "            data=df[df[color_by] == category],\n",
    "            c=colour,\n",
    "            label=label,\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"none\",\n",
    "            zorder=3,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    for category in df[color_by].unique():\n",
    "        colour = colourDict[color_by][category]\n",
    "        alpha = 0.8\n",
    "        _set_ax_boxplot_i_colour(xplot, i, colour, inner_alpha=alpha)\n",
    "        _set_ax_boxplot_i_colour(yplot, i, colour, inner_alpha=alpha)\n",
    "        label = f\"{category}\" if category != \"-1\" else \"random pairs\"\n",
    "\n",
    "        # scatter empty df, to get legend in right format in right position\n",
    "        leg = legax.scatter(\n",
    "            x=col_x,\n",
    "            y=col_y,\n",
    "            data=df[df[color_by] == category][0:0],\n",
    "            c=colour,\n",
    "            label=label,\n",
    "            alpha=0.6,\n",
    "            edgecolors=\"none\",\n",
    "            s=10,\n",
    "        )\n",
    "        leg.set_facecolor(mpl.colors.to_rgba(colour, alpha=alpha))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # ==================================================\n",
    "\n",
    "    legax.legend(loc=\"lower left\", prop={\"size\": 6}, frameon=False)\n",
    "\n",
    "    # # info for square drawing\n",
    "    # squareside = 0.2\n",
    "    # s_color = \"#7A7979AA\"\n",
    "    # s_color = mpl.colors.to_rgba(\"#7A7979AA\", alpha=0.3)\n",
    "    # linewidth = 1\n",
    "\n",
    "    # ax.set_xticklabels([0,0.2,0.4,0.6,0.8,1.0])\n",
    "    sc_ax.set_xlabel(cleanfmt(col_x), labelpad=10)\n",
    "    sc_ax.set_ylabel(cleanfmt(col_y), labelpad=10)\n",
    "    # ax_xobs[0].set_title(figtitle, loc=\"center\", pad=20)\n",
    "\n",
    "    sc_ax.grid(True, alpha=0.3, linewidth=0.5, mouseover=True)\n",
    "    gs.tight_layout(fig)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f\"{Path().home()}/article_bsf/output/biosynthetic_distances.tsv\", sep=\"\\t\"\n",
    ")  # , index_col=0)\n",
    "df.separation = df.separation.astype(str).replace(\"control\", \"-1\")\n",
    "df.replace(\n",
    "    -1, 0, inplace=True\n",
    ")  # any for which we could not calculate a similarity, we set to 0\n",
    "\n",
    "\n",
    "for fp_name in [\"maccs\", \"morgan\", \"rdk\"]:\n",
    "    fig = scatter_boxplots(\n",
    "        df,\n",
    "        \"bsf\",\n",
    "        fp_name,\n",
    "        color_by=\"separation\",\n",
    "    )\n",
    "    \n",
    "    fig.savefig(fig_folder / f\"sm_biosynthetic_scatterplot_{fp_name}.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scatter_boxplots(df, x, y, color_by=\"separation\", *args, **kwargs):\n",
    "#     fig = plt.figure(figsize=(5, 5))\n",
    "#     gs = fig.add_gridspec(2, 2, wspace=-1)\n",
    "#     sc_ax = fig.add_subplot(gs[1, 0])\n",
    "#     legax = fig.add_subplot(gs[0, 1])\n",
    "#     color_by = \"separation\"\n",
    "\n",
    "#     categories = df[color_by].unique().tolist()\n",
    "#     x_data = [\n",
    "#         np.array(df[df[color_by] == cat][x].to_numpy(dtype=float)) for cat in categories\n",
    "#     ]\n",
    "#     x_data = [k[~np.isnan(k)] for k in x_data]\n",
    "#     y_data = [np.array(df[df[color_by] == cat][y].tolist()) for cat in categories]\n",
    "#     y_data = [k[~np.isnan(k)] for k in y_data]\n",
    "\n",
    "#     top_bp_ax = fig.add_subplot(gs[0, 0], sharex=sc_ax)\n",
    "#     right_bp_ax = fig.add_subplot(gs[1, 1], sharey=sc_ax)\n",
    "\n",
    "#     top_bp_ax.tick_params(length=0, labelbottom=False, labelsize=5)\n",
    "#     right_bp_ax.tick_params(length=0, labelrotation=-30, labelleft=False, labelsize=5)\n",
    "#     legax.tick_params(length=0, labelleft=False, labelbottom=False, labelsize=0)\n",
    "#     sc_ax.tick_params(length=0)\n",
    "\n",
    "#     # labels = df[color_by].unique()\n",
    "\n",
    "#     xplot = top_bp_ax.boxplot(\n",
    "#         x_data,\n",
    "#         vert=False,\n",
    "#         patch_artist=True,\n",
    "#         labels=categories,\n",
    "#         positions=[0.6 * i for i in range(len(x_data))],\n",
    "#     )\n",
    "#     yplot = right_bp_ax.boxplot(\n",
    "#         y_data,\n",
    "#         vert=True,\n",
    "#         patch_artist=True,\n",
    "#         labels=categories,\n",
    "#         positions=[0.6 * i for i in range(len(y_data))],\n",
    "#     )\n",
    "#     [tick.set_rotation(90) for tick in right_bp_ax.get_xticklabels()]\n",
    "\n",
    "#     # colormap is mako, get evenly spaced colours\n",
    "#     cat_ = [cat for cat in categories if cat != \"random pairs\"]\n",
    "#     colours = {\n",
    "#         cat: col\n",
    "#         for cat, col in zip(\n",
    "#             cat_,\n",
    "#             sns.cubehelix_palette(\n",
    "#                 start=0.5, rot=-0.75, reverse=True, n_colors=len(cat_) + 2\n",
    "#             )[1:-1],\n",
    "#         )\n",
    "#     }\n",
    "#     colours[\"random pairs\"] = \"#797979\"\n",
    "\n",
    "#     for category in categories[::-1]:\n",
    "#         sc_ax.scatter(\n",
    "#             x=x,\n",
    "#             y=y,\n",
    "#             data=df[df[color_by] == category],\n",
    "#             c=colours[category],\n",
    "#             label=str(category),\n",
    "#             alpha=0.8,\n",
    "#             edgecolors=\"none\",\n",
    "#             # zorder=3,\n",
    "#         )\n",
    "\n",
    "#     for i, category in enumerate(categories):\n",
    "#         # alpha = 0.6\n",
    "#         alpha = 0.8\n",
    "#         _set_ax_boxplot_i_colour(xplot, i, colours[category], inner_alpha=alpha)\n",
    "#         _set_ax_boxplot_i_colour(yplot, i, colours[category], inner_alpha=alpha)\n",
    "\n",
    "#         leg = legax.scatter(\n",
    "#             x=x,\n",
    "#             y=y,\n",
    "#             data=df[df[color_by] == category][0:0],\n",
    "#             color=colours[category],\n",
    "#             label=str(category),\n",
    "#             # alpha=0.5,\n",
    "#             edgecolors=\"none\",\n",
    "#             s=10,\n",
    "#         )\n",
    "#         leg.set_facecolor(mpl.colors.to_rgba(colours[category], alpha=alpha))\n",
    "\n",
    "#     legax.legend(loc=\"lower left\", prop={\"size\": 6}, frameon=False)\n",
    "\n",
    "#     sc_ax.set_xlabel(cleanfmt(x), labelpad=10)\n",
    "#     sc_ax.set_ylabel(cleanfmt(y), labelpad=10)\n",
    "#     sc_ax.grid(True, alpha=0.3, linewidth=0.5, mouseover=True)\n",
    "\n",
    "#     gs.tight_layout(fig)\n",
    "\n",
    "#     return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # later for visualisation:\n",
    "\n",
    "# def get_square(\n",
    "#     df: pd.DataFrame,\n",
    "#     col1: str,\n",
    "#     col2: str,\n",
    "#     range1: tuple[float, float],\n",
    "#     range2: tuple[float, float],\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"returns the molecule pair's inchis for 'dots' in a given square of the scatter plot\"\"\"\n",
    "#     square = df.loc[\n",
    "#         (df[col1] >= range1[0])\n",
    "#         & (df[col1] <= range1[1])\n",
    "#         & (df[col2] >= range2[0])\n",
    "#         & (df[col2] <= range2[1])\n",
    "#     ]\n",
    "#     return square\n",
    "\n",
    "\n",
    "# def draw_molpair(\n",
    "#     pair: list[Chem.Mol], annotation: str = \"\", highlighting: bool = True\n",
    "# ) -> None:\n",
    "#     for i in range(len(pair)):\n",
    "#         highlighting_info = None\n",
    "#         if highlighting:\n",
    "#             highlighting_info = get_highlight_mapping(mol=pair[i])\n",
    "#         svg_text = moldrawing.draw(\n",
    "#             pair[i], highlight_atoms_bonds_mappings=highlighting_info\n",
    "#         )\n",
    "#         if annotation:\n",
    "#             svg_text = svg_text.replace(\n",
    "#                 \"</svg>\",\n",
    "#                 f'<text x=\"30\" y=\"30\" font-size=\"20\" font-family=\"montserrat\">{annotation}</text></svg>',\n",
    "#             )\n",
    "#         with open(f\"{annotation}_{i}.svg\", \"w\") as f:\n",
    "#             f.write(svg_text)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def draw_squares(\n",
    "#     square_df: pd.DataFrame,\n",
    "#     pair_columns: tuple[str, str] = (\"mol1\", \"mol2\"),\n",
    "#     squarename: str = \"origin\",\n",
    "#     highlighting: bool = True,\n",
    "# ) -> None:\n",
    "#     \"\"\"draws the molecules in the squares\n",
    "#     input: (pd.DataFrame) square_df -- the dataframe containing the squares\n",
    "#     (str) pair_columns -- the name of the column containing the molecule pairs\n",
    "#     (str) squarename -- the name of the square\n",
    "#     \"\"\"\n",
    "#     if square_df.empty:\n",
    "#         return None\n",
    "#     for _, row in tqdm(\n",
    "#         square_df.iterrows(),\n",
    "#         desc=f\"drawing {squarename} squares\",\n",
    "#         total=square_df.shape[0],\n",
    "#         position=1,\n",
    "#     ):\n",
    "#         pair = [row[pair_columns[0]], row[pair_columns[1]]]\n",
    "#         pathway = row[\"pathway\"]\n",
    "#         outfilename = outfile_namer(f\"{squarename}_{pathway}\")\n",
    "#         draw_molpair(pair, annotation=outfilename, highlighting=highlighting)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def loopsquares(\n",
    "#     df: pd.DataFrame,\n",
    "#     x_fp: str = \"biosynfoni\",\n",
    "#     y_fps: list[str] = [\"rdkit\", \"maccs\", \"morgan\"],\n",
    "#     size: int = 0.2,\n",
    "# ) -> None:\n",
    "#     for i, y_fp in tqdm(\n",
    "#         enumerate(y_fps), desc=\"looping squares\", leave=False, position=0\n",
    "#     ):\n",
    "#         _, iwd = output_direr(f\"./{x_fp}_{y_fp}_squares\")\n",
    "#         min_val, max_val = 0.0, 1.0\n",
    "#         min_border = 0.0 + size\n",
    "#         max_border = 1.0 - size\n",
    "#         left_bottom = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (min_val, min_border),\n",
    "#             (min_val, min_border),\n",
    "#         )\n",
    "#         left_top = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (min_val, min_border),\n",
    "#             (max_border, max_val),\n",
    "#         )\n",
    "#         right_bottom = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (max_border, max_val),\n",
    "#             (min_val, min_border),\n",
    "#         )\n",
    "#         right_top = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (max_border, max_val),\n",
    "#             (max_border, max_val),\n",
    "#         )\n",
    "#         exactly_middle = get_square(\n",
    "#             df,\n",
    "#             x_fp,\n",
    "#             y_fp,\n",
    "#             (0.5, 0.5),\n",
    "#             (min_val, max_val),\n",
    "#         )\n",
    "#         draw_squares(left_bottom, squarename=f\"{y_fp}_origin\")\n",
    "#         draw_squares(left_top, squarename=f\"{y_fp}_left_top\")\n",
    "#         draw_squares(right_bottom, squarename=f\"{y_fp}_right_bottom\")\n",
    "#         draw_squares(right_top, squarename=f\"{y_fp}_right_top\")\n",
    "#         if i == 0:\n",
    "#             draw_squares(exactly_middle, squarename=f\"{x_fp}_middle\")\n",
    "#         os.chdir(iwd)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def biosynthetic_distance_analysis(pairs_df, metric):\n",
    "#     df = pd.read_csv(structures_path, sep=\"\\t\", header=None, index_col=0)\n",
    "#     logging.info(\n",
    "#         f\"{old_n_rows[0]-df.shape[0]} pathways dropped due to lack of mol pairs\\n\\n\"\n",
    "#     )\n",
    "\n",
    "#     _, iwd = output_direr(\"./biosynthetic_distance\")  # move to outputdir\n",
    "\n",
    "#     pairs = pairs_per_separation(df)\n",
    "\n",
    "#     dist_df = f\"{outfile_namer(metric)}.tsv\"\n",
    "#     mols_pkl = f\"{outfile_namer('mols')}.pkl\"\n",
    "#     if not os.path.exists(dist_df) or not os.path.exists(mols_pkl):\n",
    "#         df = add_fp_to_df(\n",
    "#             pairs,\n",
    "#             fp_types=FP_FUNCTIONS.keys(),\n",
    "#         )\n",
    "#         df = get_all_similarity_scores(df, metric=metric)\n",
    "#         mols = df.copy()\n",
    "#         # save mols as pickle\n",
    "#         mols.to_pickle(f\"{outfile_namer('mols')}.pkl\")\n",
    "#         # remove mols from df\n",
    "#         df = df.drop(columns=[\"mol1\", \"mol2\"])\n",
    "#         df.to_csv(dist_df, sep=\"\\t\", index=True)\n",
    "\n",
    "#     mols = pd.read_pickle(f\"{outfile_namer('mols')}.pkl\")\n",
    "#     df = mols\n",
    "#     df[\"pathway\"] = df.index\n",
    "\n",
    "#     logging.debug(df.shape, mols.shape, df.columns)\n",
    "#     logging.debug(df, pairs, pairs.columns)\n",
    "\n",
    "#     # if args.annotate:\n",
    "#     #     # pw_tax_file = \"../../../metacyc/pathways_taxid.txt\"\n",
    "#     #     # tax_text_file = \"../../../metacyc/cleaner_classes.dat\"\n",
    "#     #     pw_tax_file, tax_text_file = args.annotate\n",
    "#     #     annotated_df = annotate_pathways(comparison_df, pw_tax_file, tax_text_file)\n",
    "\n",
    "#     df[\"stepnum\"] = df[\"separation\"].apply(str)\n",
    "\n",
    "#     logging.info(\"getting scatterplots...\")\n",
    "#     fp_combs = list(itertools.combinations(fp_names, 2))\n",
    "#     for combination in tqdm(fp_combs, desc=\"getting scatterplots\"):\n",
    "#         scatter = fm.scatter_boxplots(\n",
    "#             df,\n",
    "#             col_x=combination[0],\n",
    "#             col_y=combination[1],\n",
    "#             figtitle=f\"{args.metric} for different reaction step numbers\",\n",
    "#             color_by=\"stepnum\",\n",
    "#         )\n",
    "#         filename = outfile_namer(f\"{combination[0]}_{combination[1]}_{args.metric}.png\")\n",
    "#         fm.savefig(scatter, filename)\n",
    "\n",
    "#     onestep = df[df[\"stepnum\"] == \"1\"]\n",
    "#     onestep.to_csv(f'{outfile_namer(\"onestep\")}.tsv', sep=\"\\t\", index=False)\n",
    "#     logging.info(\"getting squares...\")\n",
    "#     for fp in [\n",
    "#         \"biosynfoni\",\n",
    "#         \"overlap_binosynfoni\",\n",
    "#         \"overlap_biosynfoni\",\n",
    "#         \"interoverlap_biosynfoni\",\n",
    "#     ]:\n",
    "#         loopsquares(\n",
    "#             onestep,\n",
    "#             fp,\n",
    "#             [\"rdkit\", \"maccs\", \"morgan\", \"maccsynfoni\", \"overlap\"],\n",
    "#             size=0.2,\n",
    "#         )\n",
    "#     # loopsquares(\n",
    "#     #     onestep,\n",
    "#     #     \"biosynfoni\",\n",
    "#     #     [\"rdkit\", \"maccs\", \"morgan\", \"maccsynfoni\", \"overlap\"],\n",
    "#     #     size=0.2,\n",
    "#     # )\n",
    "\n",
    "#     # save the biosynfoni version for reference\n",
    "#     logging.info(\"saving current biosynfoni version...\")\n",
    "#     save_version(defaultVersion)\n",
    "\n",
    "#     os.chdir(iwd)\n",
    "#     logging.info(\"done\\nbyebye\")\n",
    "#     exit(0)\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fingerprint heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, logging\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "\n",
    "from biosynfoni.inoutput import outfile_namer\n",
    "from biosynfoni.subkeys import fpVersions, defaultVersion, get_names, get_pathway\n",
    "from figures import (\n",
    "    heatmap,\n",
    "    annotate_heatmap,\n",
    "    savefig,\n",
    "    set_label_colors_from_categories,\n",
    "    custom_cmap,\n",
    ")\n",
    "\n",
    "\n",
    "# def count_distributions(coco, zinc, substructure_names):\n",
    "#     \"\"\"WIP: Plots substructure count distribution for coco and zinc\"\"\"\n",
    "#     npcs = np.loadtxt(\n",
    "#         \"npcs.tsv\", dtype=\"str\", delimiter=\"\\t\"\n",
    "#     )  # just added, not checked\n",
    "#     s_coco = coco[npcs[:, 0] == \"Alkaloids\"]\n",
    "#     # random subsample of zinc\n",
    "#     np.random.seed(42)\n",
    "#     s_zinc = zinc[np.random.choice(zinc.shape[0], size=s_coco.shape[0], replace=False)]\n",
    "\n",
    "#     for i in range(3, len(substructure_names)):\n",
    "#         # np.histogram(coco[:,i])\n",
    "#         # print(np.mean(coco[:,i]))\n",
    "#         fig = plt.figure()\n",
    "#         nonzero = s_coco[:, i][s_coco[:, i] > 0]\n",
    "#         if np.max(nonzero) == 0:\n",
    "#             continue\n",
    "#         n, bins, edges = plt.hist(\n",
    "#             nonzero,\n",
    "#             bins=np.max(nonzero) - 1,\n",
    "#             color=\"green\",\n",
    "#             alpha=0.7,\n",
    "#             histtype=\"step\",\n",
    "#             align=\"left\",\n",
    "#         )\n",
    "\n",
    "#         plt.title(\n",
    "#             f\"substructure counts for {substructure_names[i]}, {len(nonzero)} nonzero values\"\n",
    "#         )\n",
    "#         plt.xticks(bins)\n",
    "#         plt.xlabel(\"substructure counts\")\n",
    "#         plt.ylabel(\"number of compounds\")\n",
    "#         plt.tight_layout()\n",
    "\n",
    "#     for i in range(3, len(substructure_names)):\n",
    "#         # np.histogram(coco[:,i])\n",
    "#         # print(np.mean(zinc[:,i]))\n",
    "#         fig = plt.figure()\n",
    "#         nonzero = s_zinc[:, i][s_zinc[:, i] != 0]\n",
    "#         if np.max(nonzero) < 2:\n",
    "#             continue\n",
    "#         n, bins, edges = plt.hist(\n",
    "#             nonzero,\n",
    "#             bins=np.max(nonzero) - 1,\n",
    "#             color=\"purple\",\n",
    "#             alpha=0.7,\n",
    "#             rwidth=1,\n",
    "#             histtype=\"step\",\n",
    "#             align=\"mid\",\n",
    "#         )\n",
    "#         plt.title(\n",
    "#             f\"histogram of substructure counts for {substructure_names[i]}, {len(nonzero)} nonzero values\"\n",
    "#         )\n",
    "#         plt.xticks(bins)\n",
    "#         plt.xlabel(\"substructure counts\")\n",
    "#         plt.ylabel(\"number of compounds\")\n",
    "\n",
    "#     plt.close()\n",
    "#     return None\n",
    "\n",
    "\n",
    "def heatmap_array(\n",
    "    fps: np.array,\n",
    "    max_height: int = 30,\n",
    "    percentages=False,\n",
    "    accumulative=True,\n",
    "    end_accumulative=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Make an array for a heatmap of fingerprint count per substructure\n",
    "\n",
    "        Args:\n",
    "            fps (np.array): fingerprint array\n",
    "            max_height (int): maximum height of heatmap\n",
    "            percentages (bool): whether to return in percentages\n",
    "            accumulative (bool): whether to return accumulative counts\n",
    "            end_accumulative (bool): whether to return accumulative counts only for the last height\n",
    "        Returns:\n",
    "            np.array: array for heatmap (height x substructures)\n",
    "\n",
    "    Remarks:\n",
    "        - if accumulative is True, then the heatmap will show the number of compounds that have at least that many substructures\n",
    "        - if accumulative is False, then the heatmap will show the number of compounds that have exactly that many substructures\n",
    "        - if end_accumulative is True, then the heatmap will show the number of compounds that have at least that many substructures for the last height\n",
    "\n",
    "    \"\"\"\n",
    "    heat_array = np.zeros((max_height, fps.shape[1]))\n",
    "    for i in range(max_height):\n",
    "        if accumulative:\n",
    "            countrow = np.count_nonzero(fps > i, axis=0)\n",
    "        else:\n",
    "            if end_accumulative and i == max_height - 1:\n",
    "                # for last height, count all remaining values\n",
    "                countrow = np.count_nonzero(fps > i, axis=0)\n",
    "            else:\n",
    "                countrow = np.count_nonzero((fps == i + 1), axis=0)\n",
    "        heat_array[max_height - 1 - i] = countrow\n",
    "\n",
    "    if percentages:\n",
    "        heat_array = heat_array / fps.shape[0] * 100\n",
    "    return heat_array.astype(int)\n",
    "\n",
    "\n",
    "def fp_heatmap(\n",
    "    fp_hm_array: np.array,\n",
    "    subslabels: list = [],\n",
    "    size: tuple[int] = (10, 6),\n",
    "    percentages: bool = False,\n",
    "    annotate: bool = False,\n",
    "    color_scheme: str = \"Purples\",\n",
    "    title: str = \"Representative substructure count for compound collection\",\n",
    "    top_acc_array=None,\n",
    "    standard_colour: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of fingerprint count per substructure\n",
    "\n",
    "        Args:\n",
    "            fp_hm_array (np.array): array for heatmap (height x substructures)\n",
    "            subslabels (list): list of substructure labels\n",
    "            size (tuple): size of plot\n",
    "            percentages (bool): whether to return in percentages\n",
    "            annotate (bool): whether to annotate the heatmap\n",
    "            color_scheme (str): colour scheme for heatmap\n",
    "            title (str): title of plot\n",
    "            top_acc_array (np.array): array for heatmap of top accumulative counts.\n",
    "                                        if None, then no top accumulative counts will be plotted.\n",
    "                                        default is None.\n",
    "            standard_colour (bool): whether to colour substructure labels according to biosynfoni pathway\n",
    "        Returns:\n",
    "            matplotlib.figure.Figure: figure of heatmap\n",
    "    \"\"\"\n",
    "    cbarlab = \"number of compounds\"\n",
    "    if percentages:\n",
    "        cbarlab = \"% of compounds\"\n",
    "\n",
    "    height = fp_hm_array.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=size, dpi=500)\n",
    "    if not subslabels:\n",
    "        subslabels = [f\"subs{i}\" for i in range(1, fp_hm_array.shape[1] + 1)]\n",
    "    subslabels = [x.replace(\"_\", \" \") for x in subslabels]\n",
    "\n",
    "    yaxlabels = [(height + 1 - i) for i in range(1, height + 1)]\n",
    "    if top_acc_array is not None:\n",
    "        yaxlabels[0] = f\"{height}\"\n",
    "        maxtop = top_acc_array[~np.isnan(top_acc_array)].max()\n",
    "        maxfp = fp_hm_array[~np.isnan(fp_hm_array)].max()\n",
    "        maxval = max(maxtop, maxfp)\n",
    "        im2, cbar2 = heatmap(\n",
    "            top_acc_array,\n",
    "            # ['>11']+[(height+1-i) for i in range(1, height + 1)],\n",
    "            yaxlabels,\n",
    "            subslabels,\n",
    "            ax=ax,\n",
    "            cmap=custom_cmap(\"Greys\", first_color=\"#ffffff00\"),\n",
    "            # cmap = \"PiYG\",\n",
    "            cbar_kw={\n",
    "                \"drawedges\": False,\n",
    "                \"shrink\": 0.3,\n",
    "                \"pad\": -0.05,\n",
    "                \"aspect\": 10,\n",
    "            },\n",
    "            vmin=0,\n",
    "            vmax=maxval,\n",
    "        )\n",
    "        # rotate cbar labels -90\n",
    "        cbar2.set_label(f\"{cbarlab} {height}\", rotation=90, va=\"bottom\", labelpad=15)\n",
    "\n",
    "    im, cbar = heatmap(\n",
    "        fp_hm_array,\n",
    "        # [(height+1-i) for i in range(1, height + 1)],\n",
    "        yaxlabels,\n",
    "        subslabels,\n",
    "        ax=ax,\n",
    "        cmap=custom_cmap(color_scheme, first_color=\"#ffffff00\"),\n",
    "        # cmap = \"PiYG\",\n",
    "        cbarlabel=cbarlab,\n",
    "        vmin=0,\n",
    "        cbar_kw={\"drawedges\": False, \"shrink\": 0.3, \"pad\": 0.02, \"aspect\": 10},\n",
    "    )\n",
    "    cbar.set_label(f\"{cbarlab}\", rotation=90, va=\"bottom\", labelpad=15)\n",
    "\n",
    "    # texts = annotate_heatmap(im, valfmt=\"{x:.1f}\")\n",
    "    if annotate:\n",
    "        texts = annotate_heatmap(im, valfmt=\"{x:.0f}\", size=7)\n",
    "    if standard_colour:\n",
    "        set_label_colors_from_categories(\n",
    "            ax.get_xticklabels(),\n",
    "            get_pathway(version=defaultVersion),\n",
    "            colourDict[\"pathways\"],\n",
    "        )\n",
    "    # plt.figure(figsize=(10,6))\n",
    "    ax.set_xlabel(\"substructure\", labelpad=10)\n",
    "    ax.set_ylabel(\"counts\", labelpad=10)\n",
    "    ax.set_title(title, loc=\"center\", pad=20)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def over_under_divide(fps: np.array, limit: int = 10, percentages: bool = True):\n",
    "    \"\"\"\n",
    "    Divide the heatmap array into two arrays: one for values under the limit, and one for values over the limit.\n",
    "    \"\"\"\n",
    "    full = heatmap_array(\n",
    "        fps,\n",
    "        max_height=limit + 1,\n",
    "        percentages=percentages,\n",
    "        accumulative=False,\n",
    "        end_accumulative=True,\n",
    "    )\n",
    "    under, over = full.astype(float).copy(), full.astype(float).copy()\n",
    "    under[0] = np.nan\n",
    "    over[1:] = np.nan\n",
    "    return under, over\n",
    "\n",
    "\n",
    "def fp_heatmap_accumulative(fp_arr: np.array, limit: int = 10, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Make a heatmap of fingerprint count per substructure, with accumulative end counts\n",
    "\n",
    "        Args:\n",
    "            fp_arr (np.array): fingerprint array\n",
    "            limit (int): maximum height of heatmap\n",
    "        Returns:\n",
    "            matplotlib.figure.Figure: figure of heatmap\n",
    "\n",
    "    Remarks:\n",
    "        - the heatmap will show the number of compounds that have at least that many substructures for the last height\n",
    "        - this helps reduce the height of the heatmap, as the top accumulative counts are often much higher than the rest\n",
    "    \"\"\"\n",
    "    under, over = over_under_divide(fp_arr, limit, percentages=True)\n",
    "    hm = fp_heatmap(\n",
    "        under,\n",
    "        *args,\n",
    "        percentages=True,\n",
    "        top_acc_array=over,\n",
    "        **kwargs,\n",
    "    )\n",
    "    return hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = np.loadtxt(folder / \"fps\" / \"coconut_bsf.csv\", dtype=int, delimiter=\",\")\n",
    "substructure_names = get_names(version=defaultVersion)\n",
    "if fps.shape[1] != len(substructure_names):\n",
    "    substructure_names = [str(i + 1) for i in range(fps.shape[1])]\n",
    "\n",
    "# # binary heatmap\n",
    "# fp_heatmap(\n",
    "#     heatmap_array(fps, max_height=1, percentages=True, accumulative=False),\n",
    "#     subslabels=substructure_names,\n",
    "#     title=f\"Distribution of {fp_name} substructure counts\",\n",
    "#     color_scheme=\"Greys\",\n",
    "#     percentages=True,\n",
    "#     size=(15, 1),\n",
    "#     standard_colour=True,\n",
    "# )\n",
    "\n",
    "\n",
    "hm = fp_heatmap_accumulative(\n",
    "    fps,\n",
    "    limit=10,\n",
    "    title=f\"Biosynfoni QR of all compounds in COCONUT\",\n",
    "    subslabels=substructure_names,\n",
    "    color_scheme=\"GnBu\",\n",
    "    standard_colour=True,\n",
    ")\n",
    "\n",
    "hm.savefig(fig_folder / \"sm_qr_coconut.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = np.loadtxt(folder / \"fps\" / \"chebi_bsf.csv\", dtype=int, delimiter=\",\")\n",
    "classes = np.loadtxt(\n",
    "    folder / \"data\" / \"input\" / \"chebi_classes.csv\",\n",
    "    dtype=\"str\",\n",
    "    delimiter=\",\",\n",
    "    usecols=1,\n",
    ")\n",
    "classes[classes == \"fatty_acid;isoprenoid\"] = \"isoprenoid\"\n",
    "classes = np.where(np.core.defchararray.find(classes, \";\") != -1, \"multiple\", classes)\n",
    "classes[classes == \"\"] = \"None\"\n",
    "\n",
    "assert len(classes) == fps.shape[0], \"check classes file\"\n",
    "\n",
    "hms = []\n",
    "for classif in np.unique(classes):\n",
    "    idx = np.where(classes == classif)\n",
    "    focus = fps[idx]\n",
    "    if not classif:\n",
    "        classif = \"None\"\n",
    "\n",
    "\n",
    "    hm =    fp_heatmap_accumulative(\n",
    "            focus,\n",
    "            limit=10,\n",
    "            title=f\"Biosynfoni QR of all {len(focus)} {classif.replace('_', ' ')} compounds\",\n",
    "            subslabels=substructure_names,\n",
    "            color_scheme=\"GnBu\",\n",
    "            standard_colour=True,\n",
    "        )\n",
    "    hms.append(hm)\n",
    "    hm.savefig(fig_folder / f\"sm_qr_chebi_{classif}.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. chemical space visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 6))\n",
    "for i, fp in enumerate([\"bsf\", \"maccs\", \"morgan\", \"rdk\"]):\n",
    "    df = pd.read_csv(\n",
    "        f\"{Path().home()}/article_bsf/output/{fp}_tsne.csv\",\n",
    "        header=None,\n",
    "        names=[\"x\", \"y\"],\n",
    "    )\n",
    "    df[\"class\"] = np.loadtxt(\n",
    "        f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "        delimiter=\",\",\n",
    "        dtype=str,\n",
    "        usecols=1,\n",
    "    )\n",
    "    df[\"id\"] = np.loadtxt(\n",
    "        f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "        delimiter=\",\",\n",
    "        dtype=str,\n",
    "        usecols=0,\n",
    "    )\n",
    "\n",
    "    # remove all molecules that have an \"R\" in them\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=df[~df[\"class\"].str.contains(\";\")],\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        hue=\"class\",\n",
    "        palette=\"Spectral\",\n",
    "        alpha=0.5,\n",
    "        ax=ax.flatten()[i],\n",
    "    )\n",
    "    ax.flatten()[i].set_title(fp, fontweight=\"regular\")\n",
    "    ax.flatten()[i].tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        labelbottom=False,\n",
    "        labelleft=False,\n",
    "    )\n",
    "    ax.flatten()[i].legend().remove()\n",
    "    ax.flatten()[i].set_xlabel(\"\")\n",
    "    ax.flatten()[i].set_ylabel(\"\")\n",
    "for handle in ax[0,1].get_legend_handles_labels()[0]:\n",
    "    handle.set_alpha(1)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "ax[0,1].legend(loc=\"upper left\", bbox_to_anchor=(1, 1), markerscale=3)\n",
    "plt.suptitle(f\"t-SNE of single class Chebi compounds\", fontsize=20, fontweight=\"bold\")\n",
    "plt.savefig(fig_folder / f\"sm_tsne_single.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(6, 6))\n",
    "for i, fp in enumerate([\"bsf\", \"maccs\", \"morgan\", \"rdk\"]):\n",
    "    df = pd.read_csv(\n",
    "        f\"{Path().home()}/article_bsf/output/{fp}_tsne.csv\",\n",
    "        header=None,\n",
    "        names=[\"x\", \"y\"],\n",
    "    )\n",
    "    df[\"class\"] = np.loadtxt(\n",
    "        f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "        delimiter=\",\",\n",
    "        dtype=str,\n",
    "        usecols=1,\n",
    "    )\n",
    "    df[\"id\"] = np.loadtxt(\n",
    "        f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "        delimiter=\",\",\n",
    "        dtype=str,\n",
    "        usecols=0,\n",
    "    )\n",
    "\n",
    "    # remove all molecules that have an \"R\" in them\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=df[~df[\"class\"].str.contains(\";\")],\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        hue=\"class\",\n",
    "        palette=\"Spectral\",\n",
    "        alpha=0.5,\n",
    "        ax=ax.flatten()[i],\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=df[df[\"class\"].str.contains(\";\")],\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        c=\"darkgrey\",\n",
    "        alpha=0.5,\n",
    "        ax=ax.flatten()[i],\n",
    "        label=\"multiple\",\n",
    "    )\n",
    "    ax.flatten()[i].set_title(fp, fontweight=\"regular\")\n",
    "    ax.flatten()[i].tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        labelbottom=False,\n",
    "        labelleft=False,\n",
    "    )\n",
    "    ax.flatten()[i].legend().remove()\n",
    "    ax.flatten()[i].set_xlabel(\"\")\n",
    "    ax.flatten()[i].set_ylabel(\"\")\n",
    "for handle in ax[0,1].get_legend_handles_labels()[0]:\n",
    "    handle.set_alpha(1)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "ax[0,1].legend(loc=\"upper left\", bbox_to_anchor=(1, 1), markerscale=3)\n",
    "plt.suptitle(f\"t-SNE of Chebi compounds\", fontsize=20, fontweight=\"bold\")\n",
    "plt.savefig(fig_folder / f\"sm_tsne.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(6, 6))\n",
    "for i, fp in enumerate([\"bsf\", \"maccs\", \"morgan\", \"rdk\"]):\n",
    "    df = pd.read_csv(\n",
    "        f\"{Path().home()}/article_bsf/output/{fp}_umap.csv\",\n",
    "        header=None,\n",
    "        names=[\"x\", \"y\"],\n",
    "    )\n",
    "    df[\"class\"] = np.loadtxt(\n",
    "        f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "        delimiter=\",\",\n",
    "        dtype=str,\n",
    "        usecols=1,\n",
    "    )\n",
    "    df[\"id\"] = np.loadtxt(\n",
    "        f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "        delimiter=\",\",\n",
    "        dtype=str,\n",
    "        usecols=0,\n",
    "    )\n",
    "\n",
    "    # remove all molecules that have an \"R\" in them\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=df[~df[\"class\"].str.contains(\";\")],\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        hue=\"class\",\n",
    "        palette=\"Spectral\",\n",
    "        alpha=0.5,\n",
    "        ax=ax.flatten()[i],\n",
    "    )\n",
    "    ax.flatten()[i].set_title(fp, fontweight=\"regular\")\n",
    "    ax.flatten()[i].tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        labelbottom=False,\n",
    "        labelleft=False,\n",
    "    )\n",
    "    ax.flatten()[i].legend().remove()\n",
    "    ax.flatten()[i].set_xlabel(\"\")\n",
    "    ax.flatten()[i].set_ylabel(\"\")\n",
    "for handle in ax[0,1].get_legend_handles_labels()[0]:\n",
    "    handle.set_alpha(1)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "ax[0,1].legend(loc=\"upper left\", bbox_to_anchor=(1, 1), markerscale=3)\n",
    "plt.suptitle(f\"UMAP of single class Chebi compounds\", fontsize=20, fontweight=\"bold\")\n",
    "plt.savefig(fig_folder / f\"sm_umap_single.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(6, 6))\n",
    "for i, fp in enumerate([\"bsf\", \"maccs\", \"morgan\", \"rdk\"]):\n",
    "    df = pd.read_csv(\n",
    "        f\"{Path().home()}/article_bsf/output/{fp}_umap.csv\",\n",
    "        header=None,\n",
    "        names=[\"x\", \"y\"],\n",
    "    )\n",
    "    df[\"class\"] = np.loadtxt(\n",
    "        f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "        delimiter=\",\",\n",
    "        dtype=str,\n",
    "        usecols=1,\n",
    "    )\n",
    "    df[\"id\"] = np.loadtxt(\n",
    "        f\"{Path().home()}/article_bsf/data/input/chebi_classes.csv\",\n",
    "        delimiter=\",\",\n",
    "        dtype=str,\n",
    "        usecols=0,\n",
    "    )\n",
    "\n",
    "    # remove all molecules that have an \"R\" in them\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=df[~df[\"class\"].str.contains(\";\")],\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        hue=\"class\",\n",
    "        palette=\"Spectral\",\n",
    "        alpha=0.5,\n",
    "        ax=ax.flatten()[i],\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=df[df[\"class\"].str.contains(\";\")],\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        c=\"darkgrey\",\n",
    "        alpha=0.5,\n",
    "        ax=ax.flatten()[i],\n",
    "        label=\"multiple\",\n",
    "    )\n",
    "    ax.flatten()[i].set_title(fp, fontweight=\"regular\")\n",
    "    ax.flatten()[i].tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        labelbottom=False,\n",
    "        labelleft=False,\n",
    "    )\n",
    "    ax.flatten()[i].legend().remove()\n",
    "    ax.flatten()[i].set_xlabel(\"\")\n",
    "    ax.flatten()[i].set_ylabel(\"\")\n",
    "for handle in ax[0,1].get_legend_handles_labels()[0]:\n",
    "    handle.set_alpha(1)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "ax[0,1].legend(loc=\"upper left\", bbox_to_anchor=(1, 1), markerscale=3)\n",
    "plt.suptitle(f\"UMAP of Chebi compounds\", fontsize=20, fontweight=\"bold\")\n",
    "plt.savefig(fig_folder / f\"sm_umap.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. biosynfoni substructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biosynfoni import subkeys\n",
    "from rdkit import Chem\n",
    "\n",
    "smarts = subkeys.get_smarts(version=subkeys.defaultVersion)\n",
    "mols = [Chem.MolFromSmarts(smart) for smart in smarts]\n",
    "\n",
    "# Draw the molecules in a grid\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "Draw.MolsToGridImage(mols, molsPerRow=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4 - Clustermaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, os, argparse, logging\n",
    "\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import scipy.cluster.hierarchy as sch\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pylab as plt\n",
    "# from matplotlib.patches import Patch\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # matplotlib.use('Agg')       #if in background\n",
    "\n",
    "# from biosynfoni.subkeys import get_names, get_pathway\n",
    "# from utils import set_style\n",
    "# from utils.colours import colourDict\n",
    "# from utils.figures import set_label_colors_from_categories\n",
    "\n",
    "\n",
    "# def cli():\n",
    "#     \"\"\"\n",
    "#     Command line interface for clustermap\n",
    "#     \"\"\"\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     parser.add_argument(\"fingerprints\", help=\"Fingerprint file\")\n",
    "#     parser.add_argument(\"labels\", help=\"Labels file\")\n",
    "#     parser.add_argument(\n",
    "#         \"-s\",\n",
    "#         \"--subsample\",\n",
    "#         required=False,\n",
    "#         type=int,\n",
    "#         help=\"subsample size\",\n",
    "#         default=None,\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"-r\",\n",
    "#         \"--seed\",\n",
    "#         \"--randomseed\",\n",
    "#         required=False,\n",
    "#         type=int,\n",
    "#         help=\"seed for subsampling\",\n",
    "#         default=None,\n",
    "#     )\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "#     args.fingerprints = os.path.abspath(args.fingerprints)\n",
    "#     args.labels = os.path.abspath(args.labels)\n",
    "#     return args\n",
    "\n",
    "\n",
    "# class recursion_depth:\n",
    "#     def __init__(self, limit):\n",
    "#         self.limit = limit\n",
    "#         self.default_limit = sys.getrecursionlimit()\n",
    "\n",
    "#     def __enter__(self):\n",
    "#         sys.setrecursionlimit(self.limit)\n",
    "\n",
    "#     def __exit__(self, type, value, traceback):\n",
    "#         sys.setrecursionlimit(self.default_limit)\n",
    "\n",
    "\n",
    "# class ClusterMap:\n",
    "#     def __init__(self, df, labels, metric, method) -> None:\n",
    "#         self.df = df\n",
    "#         self.indexes = df.index.values\n",
    "#         self.labels = labels\n",
    "#         self.colordict = self.get_colordict()\n",
    "#         self.metric = metric\n",
    "#         self.method = method\n",
    "#         logging.debug(f\"calculating distances with {metric} and {method}...\")\n",
    "#         self.distances = self.get_distances()\n",
    "#         self.clustering = self.get_clustering()\n",
    "#         # self.distances = None\n",
    "#         # self.clustering = None\n",
    "#         # self.tree = self.get_tree()\n",
    "#         self.colors, self.handles = self._get_category_colors_handles(self.labels)\n",
    "#         logging.debug(f\"plotting clustermap with {metric} and {method}...\")\n",
    "#         self.clustermap = self.seacluster()\n",
    "#         self.clusterfig = self.get_clusterplot()\n",
    "#         plt.close()\n",
    "#         pass\n",
    "\n",
    "#     def get_distances(self):\n",
    "#         \"\"\"\n",
    "#         calculates distances from data frame using metric\n",
    "#         \"\"\"\n",
    "#         return sch.distance.pdist(self.df, metric=self.metric)\n",
    "\n",
    "#     def set_distances(self, distances):\n",
    "#         \"\"\"\n",
    "#         sets distances from data frame\n",
    "#         \"\"\"\n",
    "#         self.distances = distances\n",
    "#         return None\n",
    "\n",
    "#     def get_clustering(self):\n",
    "#         \"\"\"\n",
    "#         calculates clustering from distances using method\n",
    "#         \"\"\"\n",
    "#         # plt.title(out_file)\n",
    "#         with recursion_depth(10000):\n",
    "#             clustering = sch.linkage(self.distances, method=self.method)\n",
    "#         # plt.close()\n",
    "#         return clustering\n",
    "\n",
    "#     def get_tree(self):\n",
    "#         \"\"\"returns dendrogram tree\"\"\"\n",
    "#         tree = sch.dendrogram(\n",
    "#             self.clustering, leaf_font_size=2, color_threshold=4, labels=self.indexes\n",
    "#         )\n",
    "#         return tree\n",
    "\n",
    "#     def seacluster(self):\n",
    "#         \"\"\"\n",
    "#         Makes a seaborn clustermap\n",
    "\n",
    "#         Returns:\n",
    "#         seacluster: seaborn clustermap object\n",
    "#         \"\"\"\n",
    "#         # comp_color, comp_handles = get_gnsr_diff_color() #compounds\n",
    "\n",
    "#         cmap = _cmap_makezerowhite(\"mako\")\n",
    "\n",
    "#         # self.distances = self.set_distances(self.get_distances())\n",
    "#         # self.clustering = self.get_clustering()\n",
    "#         # fig, ax = plt.subplots(figsize=(15,6))\n",
    "#         # sns.set(font_scale=0.5)\n",
    "#         with recursion_depth(20000):\n",
    "#             seacluster = sns.clustermap(\n",
    "#                 self.df,\n",
    "#                 method=self.method,\n",
    "#                 metric=self.metric,\n",
    "#                 xticklabels=1,  # every 1: label\n",
    "#                 # robust = True,\n",
    "#                 # square = True,\n",
    "#                 row_colors=self.colors,\n",
    "#                 # col_colors = phyl_color,\n",
    "#                 # z_score = 1,\n",
    "#                 # figsize= (len(list(data_frame)), min(200, len(data_frame.index.values))),\n",
    "#                 cmap=cmap,\n",
    "#                 cbar_kws={\n",
    "#                     \"shrink\": 0.3,\n",
    "#                     \"label\": \"counts\",\n",
    "#                     # \"orientation\": \"horizontal\",\n",
    "#                     # \"labelweight\": \"bold\",\n",
    "#                 },\n",
    "#                 cbar_pos=(1.05, 0.2, 0.03, 0.4),\n",
    "#             )\n",
    "#         # make x tick labels bold\n",
    "\n",
    "#         return seacluster\n",
    "\n",
    "#     def get_clusterplot(self, legend_title: str = \"class\") -> plt.gca:\n",
    "#         \"\"\"returns plt of clustermap with legend of categories\"\"\"\n",
    "\n",
    "#         # plt.figure(figsize=(15,6))\n",
    "\n",
    "#         # plt.setp(seacluster.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "#         # plt.setp(seacluster.ax_heatmap.xaxis.get_majorticklabels(), rotation=30, fontsize=8)\n",
    "#         # plt.setp(seacluster.ax_heatmap.xaxis.get_majorticklabels(), rotation=-30)\n",
    "#         # seacluster.set_xlim([0,2])\n",
    "\n",
    "#         # seacluster.set_title(TITLE, fontsize=16, fontdict={})\n",
    "#         # plt.title(\n",
    "#         #     f\"Hierarchical clustering of compounds and substructures {self.method}, {self.metric}\",\n",
    "#         #     loc=\"center\",\n",
    "#         # )  # + 'z scored')\n",
    "#         self.clustermap.fig.suptitle(\n",
    "#             f\"Hierarchical clustering of compounds and substructures {self.method}, {self.metric}\",\n",
    "#             x=0.6,\n",
    "#             y=1.1,\n",
    "#             weight=\"bold\",\n",
    "#             size=18,\n",
    "#         )\n",
    "#         self.clustermap.ax_heatmap.set_xticklabels(\n",
    "#             self.clustermap.ax_heatmap.get_xmajorticklabels(),\n",
    "#             fontsize=10,\n",
    "#             fontweight=\"semibold\",\n",
    "#         )\n",
    "#         self._set_substructure_colours()\n",
    "\n",
    "#         # seacluster = self.seacluster()\n",
    "\n",
    "#         # improve layout\n",
    "#         # plt.tight_layout()\n",
    "\n",
    "#         # add legend\n",
    "#         handles = self.handles\n",
    "#         legend_colors = [\n",
    "#             Patch(facecolor=handles[name], edgecolor=\"#FFFFFF00\")\n",
    "#             for name in handles.keys()\n",
    "#         ]\n",
    "\n",
    "#         plt.legend(\n",
    "#             legend_colors,\n",
    "#             handles.keys(),\n",
    "#             title=legend_title,\n",
    "#             bbox_to_anchor=(1, 0.9),\n",
    "#             bbox_transform=plt.gcf().transFigure,\n",
    "#             loc=\"upper left\",\n",
    "#             frameon=False,\n",
    "#             edgecolor=\"#FFFFFF\",\n",
    "#             fontsize=10,\n",
    "#         )\n",
    "#         # set legend title size\n",
    "#         plt.setp(plt.gca().get_legend().get_title(), fontsize=10)\n",
    "\n",
    "#         # plt.show()\n",
    "#         # return dendrogram_linkage\n",
    "#         return plt.gca()\n",
    "\n",
    "#     def save_clustermap(self, fmt: str = \"svg\") -> None:\n",
    "#         \"\"\"saves clustermap to file\n",
    "\n",
    "#         Args:\n",
    "#             fmt: str, file format\n",
    "#         Returns:\n",
    "#             None\n",
    "#         \"\"\"\n",
    "#         out_file = f\"clustermap_{self.method}_{self.metric}.{fmt}\"\n",
    "#         # self.clusterfig.savefig(out_file, format=fmt)\n",
    "#         self.clustermap.savefig(out_file, format=fmt)\n",
    "#         # plt.savefig(out_file, format=fmt)\n",
    "#         return None\n",
    "\n",
    "#     def get_dendogram_tree(self):\n",
    "#         \"\"\"returns dendrogram tree object for branch cutting\"\"\"\n",
    "#         return self.clustermap.dendrogram_row.dendrogram\n",
    "\n",
    "#     def get_dendogram_linkage(self) -> np.ndarray:\n",
    "#         \"\"\"returns dendrogram linkage object\"\"\"\n",
    "#         return self.clustermap.dendrogram_row.linkage\n",
    "\n",
    "#     def get_colordict(self) -> dict:\n",
    "#         \"\"\"returns colour dictionary for categories\n",
    "#         Returns:\n",
    "#             colordict: dict, category: color\n",
    "#         \"\"\"\n",
    "#         # colordict = {\n",
    "#         #     \"Terpenoids\": sns.color_palette(\"Set3\")[6],  # green\n",
    "#         #     \"Alkaloids\": sns.color_palette(\"Set3\")[9],  # purple\n",
    "#         #     \"Shikimates and Phenylpropanoids\": sns.color_palette(\"Set3\")[4],  # blue\n",
    "#         #     \"Fatty acids\": sns.color_palette(\"Set3\")[5],  # orange\n",
    "#         #     \"Carbohydrates\": sns.color_palette(\"Set3\")[7],  # pink\n",
    "#         #     \"Polyketides\": sns.color_palette(\"Set3\")[3],  # light red\n",
    "#         #     \"Amino acids and Peptides\": \"bisque\",\n",
    "#         #     # \"No NP-Classifier prediction\": \"grey\",\n",
    "#         #     \"None\": \"grey\",\n",
    "#         #     \"Synthetic\": \"black\",\n",
    "#         # }\n",
    "#         if self.labels[0][0].isupper():\n",
    "#             colordict = colourDict[\"NPClassifier prediction\"]\n",
    "#         else:\n",
    "#             colordict = colourDict[\"chebi class\"]\n",
    "#         return colordict\n",
    "\n",
    "#     def _get_category_colors_handles(\n",
    "#         self, categories: pd.Series\n",
    "#     ) -> tuple[pd.DataFrame, dict]:\n",
    "#         \"\"\"uses colour dictionary to assign colors to the categories\"\"\"\n",
    "#         network_dict = {}\n",
    "#         categories.fillna(\"None\", inplace=True)\n",
    "\n",
    "#         for ind, cat in categories.items():\n",
    "#             # network_dict[ind] = [self.colordict[str(cat).split(',')[0]]] #in case of multiple categories, take the first one\n",
    "#             network_dict[ind] = [self.colordict[str(cat)]]\n",
    "#         network_colors = pd.DataFrame.from_dict(network_dict, orient=\"index\")\n",
    "#         network_colors.columns = [\"\"]\n",
    "#         handles = self.colordict\n",
    "#         return network_colors, handles\n",
    "\n",
    "#     def _set_substructure_colours(self):\n",
    "#         \"\"\"sets substructure colours in clustermap\"\"\"\n",
    "#         pathways = get_pathway()\n",
    "#         substructures = self.df.columns\n",
    "#         subs_to_pathways = {a: b for a, b in zip(substructures, pathways)}\n",
    "#         ticklabels = self.clustermap.ax_heatmap.get_xticklabels()\n",
    "#         # access text from ticklabels\n",
    "#         pathways = [subs_to_pathways[x.get_text()] for x in ticklabels]\n",
    "#         if len(pathways) != len(ticklabels):\n",
    "#             logging.warning(\n",
    "#                 f\"cannot set {pathways} substructure for {ticklabels} colours\"\n",
    "#             )\n",
    "#             return None\n",
    "#         else:\n",
    "#             set_label_colors_from_categories(\n",
    "#                 ticklabels, pathways, colourDict[\"pathways\"]\n",
    "#             )\n",
    "\n",
    "\n",
    "# def _cmap_makezerowhite(\n",
    "#     default_cmap: str = \"mako\",\n",
    "# ) -> mpl.colors.LinearSegmentedColormap:\n",
    "#     # define color map:-------------------------------------------------\n",
    "#     cmap = sns.color_palette(default_cmap, as_cmap=True)  # define the colormap\n",
    "#     # extract all colors from the .jet map\n",
    "#     cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "#     # force the first color entry to be white (to distinguish 0 from low values)\n",
    "#     cmaplist[0] = (1.0, 1.0, 1.0, 0)\n",
    "#     # create the new map\n",
    "#     cmap = mpl.colors.LinearSegmentedColormap.from_list(\"Custom cmap\", cmaplist, cmap.N)\n",
    "#     return cmap\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     set_style()\n",
    "#     args = cli()\n",
    "\n",
    "#     filetype = \"svg\"\n",
    "#     # version = input_file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "#     substructure_names = [x.replace(\"_\", \" \") for x in get_names()]\n",
    "\n",
    "#     fp = pd.read_csv(args.fingerprints, sep=\",\", header=None, dtype=int)\n",
    "#     if fp.shape[1] == len(substructure_names):\n",
    "#         fp.columns = substructure_names\n",
    "#     db_name = args.fingerprints.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "#     fp_name = args.fingerprints.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1]\n",
    "\n",
    "#     npcs = pd.read_csv(\n",
    "#         args.labels,\n",
    "#         sep=\"\\t\",\n",
    "#         header=None,\n",
    "#         dtype=str,\n",
    "#         usecols=[0],\n",
    "#     )\n",
    "\n",
    "#     # as all isoprenoids are fatty acids according to chebi:\n",
    "#     npcs.replace(\"fatty_acid,isoprenoid\", \"isoprenoid\", inplace=True)\n",
    "#     # filter out multiple-prediction compounds\n",
    "#     npcs.fillna(\",\", inplace=True)\n",
    "#     fp = fp[~npcs[0].str.contains(\",\")]\n",
    "#     npcs = npcs[~npcs[0].str.contains(\",\")]\n",
    "\n",
    "#     # # filter out only-zero columns in df ~~~~~~~~~~~~~~~ CHECK IF THIS APPLIES TO YOUR PURPOSES ~~~~~~~~~~~~~~~\n",
    "#     # fp = fp.loc[:, (fp != 0).any(axis=0)]\n",
    "#     # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "#     # subsample indexes\n",
    "#     if args.subsample:\n",
    "#         np.random.seed(args.seed)\n",
    "#         idx = np.random.choice(fp.index, args.subsample, replace=False)\n",
    "#         fp = fp.loc[idx]\n",
    "#         npcs = npcs.loc[idx]\n",
    "\n",
    "#     npcs_series = npcs.iloc[:, 0]\n",
    "\n",
    "#     # check if indexes are the same\n",
    "#     assert fp[fp.index != npcs.index].empty\n",
    "#     assert npcs[npcs.index != npcs_series.index].empty\n",
    "#     assert type(npcs_series) == pd.Series\n",
    "\n",
    "#     # if args.synthetic: #under construction\n",
    "#     #     synthetic_fp = pd.read_csv(args.synthetic, dtype=int)\n",
    "#     #     synthetic_fp = np.random.choice(\n",
    "#     #         synthetic_fp.shape[0], fp.shape[0], replace=False\n",
    "#     #     )\n",
    "#     #     fp = np.concatenate((fp, synthetic_fp))\n",
    "#     #     synthetic_labels = np.array([\"synthetic\" for _ in range(synthetic_fp.shape[0])])\n",
    "#     #     labels = np.concatenate((labels, synthetic_labels))\n",
    "\n",
    "#     iwd = os.getcwd()\n",
    "#     # make a directory in grandparent directory called clustermaps\n",
    "#     # os.chdir(\"../../\")\n",
    "#     os.makedirs(f\"clustermaps/{db_name}/{fp_name}\", exist_ok=True)\n",
    "#     os.chdir(f\"clustermaps/{db_name}/{fp_name}\")\n",
    "\n",
    "#     # # debugging\n",
    "#     # clustermap = ClusterMap(fp, npcs_series, \"euclidean\", \"average\")\n",
    "#     # clustermap.save_clustermap(fmt=filetype)\n",
    "\n",
    "#     for method in tqdm([\"average\", \"complete\", \"single\", \"weighted\"]):\n",
    "#         for metric in tqdm(\n",
    "#             [\n",
    "#                 \"euclidean\",\n",
    "#                 \"cityblock\",\n",
    "#                 \"cosine\",\n",
    "#                 \"correlation\",\n",
    "#                 \"hamming\",\n",
    "#                 \"jaccard\",\n",
    "#                 \"mahalanobis\",\n",
    "#                 \"chebyshev\",\n",
    "#                 \"canberra\",\n",
    "#                 \"braycurtis\",\n",
    "#                 \"dice\",\n",
    "#                 \"kulsinski\",\n",
    "#                 \"matching\",\n",
    "#                 \"rogerstanimoto\",\n",
    "#                 \"russellrao\",\n",
    "#                 \"sokalmichener\",\n",
    "#                 \"sokalsneath\",\n",
    "#                 \"yule\",\n",
    "#             ],\n",
    "#             leave=False,\n",
    "#         ):\n",
    "#             # errors can occur for some metrics if they have too small sample sets, or with certain combinations:\n",
    "#             try:\n",
    "#                 clustermap = ClusterMap(fp, npcs_series, metric, method)\n",
    "#                 clustermap.save_clustermap(fmt=filetype)\n",
    "#             except:\n",
    "#                 logging.warning(f\"failed for {method} and {metric}\")\n",
    "#             pass\n",
    "#         pass\n",
    "\n",
    "#     os.chdir(iwd)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5 - Importances Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sys import argv\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib as mpl\n",
    "\n",
    "# from biosynfoni.subkeys import defaultVersion, get_values, get_pathway\n",
    "# from utils.figures import cat_to_colour\n",
    "# from utils.colours import colourDict\n",
    "# from utils import set_style\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"\n",
    "#     Plot the feature importances from a random forest model as a barplot\n",
    "#     \"\"\"\n",
    "#     importances = np.loadtxt(argv[1], delimiter=\"\\t\", dtype=float)\n",
    "#     bsf_name = defaultVersion\n",
    "#     substructure_names = get_values(\"name\", version=bsf_name)\n",
    "#     pathways = get_pathway(version=bsf_name)\n",
    "#     colors = cat_to_colour(pathways, colourDict[\"pathways\"])\n",
    "#     if len(substructure_names) != importances.shape[1]:\n",
    "#         print(\"WARNING: substructure names not equal to importances\")\n",
    "#         substructure_names = [f\"{i}\" for i in range(importances.shape[1])]\n",
    "#         colors = [\"#888888\" for _ in range(importances.shape[1])]\n",
    "#     set_style()\n",
    "\n",
    "#     means = np.mean(importances, axis=0)\n",
    "\n",
    "#     # set plot size\n",
    "#     # default: 6.4, 4.8\n",
    "#     ratio = importances.shape[1] / 39\n",
    "#     plt.figure(figsize=(ratio * 6.4, 4.8))\n",
    "\n",
    "#     # plot barplot\n",
    "#     barplot = plt.bar(substructure_names, means)\n",
    "#     # add standard deviations as error bars\n",
    "#     stds = np.std(importances, axis=0)\n",
    "#     print(stds.shape)\n",
    "#     e1 = plt.errorbar(substructure_names, means, yerr=stds, fmt=\"o\", color=\"#606060\")\n",
    "#     e2 = plt.errorbar(substructure_names, means, yerr=stds, fmt=\"none\", color=\"#606060\")\n",
    "\n",
    "#     plt.xticks(range(len(substructure_names)), substructure_names, rotation=90)\n",
    "#     # set bar colours\n",
    "#     for i, bar in enumerate(barplot):\n",
    "#         bar.set_color(colors[i])\n",
    "\n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.ylabel(\"feature importance\")\n",
    "#     plt.xlabel(\"substructure\")\n",
    "#     plt.suptitle(\"Feature importances for random forest model\", weight=\"bold\")\n",
    "#     plt.title(\"(averaged over k-fold cross validation with k=5)\", weight=\"light\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(argv[1].replace(\".tsv\", \".png\"), bbox_inches=\"tight\")\n",
    "#     return None\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6 - Confusion Matrix heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse, logging\n",
    "# import os\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def set_style() -> None:\n",
    "#     \"\"\"\n",
    "#     Set the style of the plot to biostylefoni\n",
    "#     \"\"\"\n",
    "#     # get path of this script\n",
    "#     script_path = os.path.dirname(os.path.realpath(__file__))\n",
    "#     parent_path = os.path.dirname(script_path)\n",
    "#     utils_path = os.path.join(parent_path, \"utils\")\n",
    "#     print(utils_path)\n",
    "#     style_path = os.path.join(utils_path, \"biostylefoni.mplstyle\")\n",
    "#     # set style\n",
    "#     plt.style.use(style_path)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def parse_cms_files(m_path: str) -> tuple[np.array, np.array]:\n",
    "#     \"\"\"\n",
    "#     Parse the confusion matrices and names from a file\n",
    "\n",
    "#     Args:\n",
    "#         m_path (str): path to file with confusion matrices\n",
    "\n",
    "#     Returns:\n",
    "#         tuple[np.array, np.array]: array of confusion matrices and array of names (i.e. )\n",
    "#     \"\"\"\n",
    "#     cms = np.loadtxt(\n",
    "#         m_path,\n",
    "#         delimiter=\"\\t\",\n",
    "#         dtype=int,\n",
    "#         skiprows=1,\n",
    "#         usecols=(1, 2, 3, 4),\n",
    "#     )\n",
    "#     # for each row, split the array into a 2x2 array\n",
    "#     cms = cms.reshape(cms.shape[0], 2, 2)\n",
    "\n",
    "#     # now get only the 'index names'\n",
    "#     cm_names = np.loadtxt(\n",
    "#         m_path,\n",
    "#         delimiter=\"\\t\",\n",
    "#         dtype=str,\n",
    "#         skiprows=1,\n",
    "#         usecols=(0),\n",
    "#     )\n",
    "#     return cms, cm_names\n",
    "\n",
    "\n",
    "# def get_matrices(cms: np.array) -> tuple[list[np.array], list[np.array]]:\n",
    "#     \"\"\"\n",
    "#     Take an array of confusion matrices and return a list of matrices and a list of normalised matrices\n",
    "\n",
    "#     Args:\n",
    "#         cms (np.array): array of confusion matrices\n",
    "\n",
    "#     Returns:\n",
    "#         tuple[list[np.array], list[np.array]]: a list of matrices and a list of normalised matrices\n",
    "#     \"\"\"\n",
    "#     matrices = []\n",
    "#     norm_matrices = []\n",
    "#     perc_matrices = []\n",
    "#     for i in range(cms.shape[0]):\n",
    "#         # # make random matrix with values between 0 and 100000\n",
    "#         # matrix = np.random.randint(0, 100000, size=(2, 2))\n",
    "#         matrix = cms[i]\n",
    "#         # normalise matrix\n",
    "#         norm_matrix = matrix / matrix.sum(axis=1, keepdims=True)\n",
    "#         # turn normalised matrix into percentages\n",
    "#         perc_matrix = norm_matrix * 100\n",
    "#         # append matrices to list\n",
    "#         matrices.append(matrix)\n",
    "#         norm_matrices.append(norm_matrix)\n",
    "#         perc_matrices.append(perc_matrix)\n",
    "#     assert len(matrices) == len(perc_matrices), \"#matrices don't match\"\n",
    "#     return matrices, perc_matrices\n",
    "\n",
    "\n",
    "# def main(matrix_path, ):\n",
    "#     matrix_path = Path(matrix_path)\n",
    "#     ml_input = matrix_path.stem.split(\"_\")[-1]\n",
    "\n",
    "#     # read in the confusion matrix and names\n",
    "#     cms, cm_names = parse_cms_files(matrix_path)\n",
    "#     # print(cms, cm_names)\n",
    "\n",
    "#     # get the matrices and the percentage versions for each category\n",
    "#     matrices, perc_matrices = get_matrices(cms)\n",
    "#     assert len(matrices) == len(cm_names), \"#matrices and #categories don't match\"\n",
    "\n",
    "#     # make subplots\n",
    "#     fig, axs = plt.subplots(\n",
    "#         1, len(matrices), figsize=(len(matrices), 2), dpi=500\n",
    "#     )  # , sharey=True) #sharing y makes the y axis ticks appear in each subplot\n",
    "\n",
    "#     # make a heatmap in each subplot\n",
    "#     for i, ax in enumerate(axs):\n",
    "#         cmap_name = \"Greys\"\n",
    "#         cmap = mpl.colormaps[cmap_name]\n",
    "#         # plot heatmap\n",
    "#         im = ax.imshow(perc_matrices[i], cmap=cmap_name, vmin=0, vmax=100)\n",
    "#         # remove ticks\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#         ax.set_xticklabels([])\n",
    "#         ax.set_yticklabels([])\n",
    "#         # set title\n",
    "#         title = cm_names[i].replace(\"_\", \"\\n\")\n",
    "#         axtitle = ax.set_title(title, fontsize=7, fontweight=600, wrap=True)\n",
    "#         # force the wrap line width to be shorter\n",
    "#         axtitle._get_wrap_line_width = lambda: 600.0  #  wrap to 600 screen pixels\n",
    "#         # annotate values in each box, with dark text for light background and light text for dark background\n",
    "#         fontweight = 500\n",
    "#         a_size = 5\n",
    "#         for j in range(2):\n",
    "#             for k in range(2):\n",
    "#                 if perc_matrices[i][j][k] < 50:\n",
    "#                     text = ax.text(\n",
    "#                         k,\n",
    "#                         j,\n",
    "#                         f\"{round(matrices[i][j][k], 2)}\\n({round(perc_matrices[i][j][k], 2)}%)\",\n",
    "#                         ha=\"center\",\n",
    "#                         va=\"center\",\n",
    "#                         color=cmap(1.0),\n",
    "#                         fontsize=a_size,\n",
    "#                         fontweight=fontweight,\n",
    "#                     )\n",
    "#                 else:\n",
    "#                     text = ax.text(\n",
    "#                         k,\n",
    "#                         j,\n",
    "#                         # round(matrices[i][j][k], 2),\n",
    "#                         f\"{round(matrices[i][j][k], 2)}\\n({round(perc_matrices[i][j][k], 2)}%)\",\n",
    "#                         ha=\"center\",\n",
    "#                         va=\"center\",\n",
    "#                         color=cmap(0.0),\n",
    "#                         fontsize=a_size,\n",
    "#                         fontweight=fontweight,\n",
    "#                     )\n",
    "\n",
    "#     # set ticks\n",
    "#     axs[0].set_yticks([0, 1])\n",
    "#     axs[0].set_yticklabels([\"P\", \"N\"], fontsize=6, fontweight=500)\n",
    "#     axs[0].set_xticks([0, 1])\n",
    "#     axs[0].set_xticklabels([\"P\", \"N\"], fontsize=6, fontweight=500)\n",
    "\n",
    "#     # set y label\n",
    "#     axs[0].set_ylabel(\"truth\", fontsize=7, fontweight=600)\n",
    "#     axs[0].set_xlabel(\"prediction\", fontsize=7, fontweight=600)\n",
    "\n",
    "#     # set common title\n",
    "#     fig.suptitle(\n",
    "#         f\"confusion matrices for multilabel RF on {ml_input}\",\n",
    "#         fontsize=9,\n",
    "#         fontweight=600,\n",
    "#     )\n",
    "\n",
    "#     # set suptitle on y axis (for later when looping across all folders)\n",
    "#     # fig.text(0.02, 0.5, \"confusion matrices for multilable RF on\", fontsize=8, fontweight=600, rotation=90, va=\"center\")\n",
    "\n",
    "#     # set tight layout\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # set colorbar\n",
    "#     cbar = fig.colorbar(im, ax=axs, shrink=0.8, orientation=\"horizontal\")\n",
    "#     cbar.ax.tick_params(labelsize=6)\n",
    "#     # add label to colorbar\n",
    "#     cbar.ax.set_xlabel(\"% of compounds\", fontsize=7)\n",
    "\n",
    "#     # get path to folder where confusion matrices are, using os.path.dirname\n",
    "#     save_path = \"/\".join(matrix_path.split(\"/\")[:-1])\n",
    "#     logging.info(matrix_path, save_path)\n",
    "#     # save figure\n",
    "#     plt.savefig(\n",
    "#         matrix_path.replace(\"_matrix.txt\", \"_heatmap.png\"), dpi=500, bbox_inches=\"tight\"\n",
    "#     )\n",
    "#     plt.clf()\n",
    "#     plt.close()\n",
    "#     exit(0)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7 - Butina Clustering with distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters = Butina.ClusterData(\n",
    "#         dist_matrix, num_fps, 0.2, isDistData=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains per length cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_per_length = np.loadtxt(\n",
    "    Path.home() / \"article_bsf\" / \"output\" / \"num_chains_per_length.csv\",\n",
    "    dtype=int,\n",
    "    delimiter=\",\",\n",
    ")\n",
    "num_per_length\n",
    "\n",
    "# plot on log scale y\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    num_per_length[:, 0],\n",
    "    num_per_length[:, 1],\n",
    "    marker=\"o\",\n",
    "    markerfacecolor=mpl.color_sequences[\"tab10\"][0],\n",
    "    markeredgecolor=\"none\",\n",
    "    markersize=5,\n",
    ")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"chain length\")\n",
    "plt.ylabel(\"number of chains\")\n",
    "# add grid\n",
    "plt.grid(True)\n",
    "# add finer grid\n",
    "plt.grid(which=\"minor\", linestyle=\"--\")\n",
    "plt.title(\"Number of chains per length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory: chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from biosynfoni.inoutput import *\n",
    "\n",
    "pathway_data = pd.read_csv(\n",
    "    \"~/article_bsf/data/input/metacyc_pathways.tsv\", sep=\"\\t\", index_col=0\n",
    ")\n",
    "pathway_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for idx, info in pathway_data.groupby(\"pathway_id\"):\n",
    "    lengths.append(len(info[\"reaction_id\"].tolist()))\n",
    "\n",
    "# histogram of chain lengths\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.show()\n",
    "\n",
    "# lengths above 10\n",
    "lengths = [length for length in lengths if length > 10]\n",
    "\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_info = pathway_data[[\"reaction_id\", \"left\", \"direction\", \"right\"]]\n",
    "reaction_info[reaction_info[\"left\"].str.contains(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pathway_graphs(pathway_data):\n",
    "    pathways = {}\n",
    "    for pathway_id, info in pathway_data.groupby(\"pathway_id\"):\n",
    "        pathways[pathway_id] = nx.DiGraph()\n",
    "        for _, row in info.iterrows():\n",
    "            pathways[pathway_id].add_edge(\n",
    "                row[\"left\"], row[\"right\"], reaction_id=row[\"reaction_id\"]\n",
    "            )\n",
    "    return pathways\n",
    "\n",
    "\n",
    "def get_longest_chains(pathways: dict):  # , with_compounds: list | None = None):\n",
    "    for pathway_id, pathway_graph in pathways.items():\n",
    "        # if not with_compounds is None:\n",
    "        #     nodes_to_remove = [node for node in pathway_graph.nodes if node not in with_compounds]\n",
    "        #     pathway_graph.remove_nodes_from(nodes_to_remove)\n",
    "        # if graph is cyclic, iterate over all nodes to find the longest path with all_simple_paths\n",
    "        if not nx.is_directed_acyclic_graph(pathway_graph):\n",
    "            longest_path = []\n",
    "            for node in pathway_graph.nodes:\n",
    "                for path in nx.all_simple_paths(\n",
    "                    pathway_graph, source=node, target=pathway_graph.nodes\n",
    "                ):\n",
    "                    if len(path) > len(longest_path):\n",
    "                        longest_path = path\n",
    "        else:\n",
    "            longest_path = nx.dag_longest_path(pathway_graph)\n",
    "        yield pathway_id, longest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = get_pathway_graphs(pathway_data)\n",
    "longest_chains = dict(\n",
    "    get_longest_chains(pathways)\n",
    ")  # , with_compounds=compounds[\"UNIQUE-ID\"].tolist()))\n",
    "\n",
    "longest_chains = dict(\n",
    "    sorted(longest_chains.items(), key=lambda x: len(x[1]), reverse=True)\n",
    ")\n",
    "\n",
    "# get the edge information\n",
    "# nx_graph[longest_path[i]][longest_path[i+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(longest_chains[\"PWY-8152\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph\n",
    "nx.draw(pathways[\"PWY-8152\"], with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the graphs\n",
    "if not os.path.exists(\"pathway_graphs\"):\n",
    "    Path(\"pathway_graphs\").mkdir(exist_ok=False)\n",
    "\n",
    "for pathway_id, pathway_graph in pathways.items():\n",
    "    nx.write_edgelist(pathway_graph, f\"pathway_graphs/{pathway_id}.edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biosynfoni import Biosynfoni\n",
    "from rdkit import Chem\n",
    "\n",
    "mol = Chem.MolFromSmiles(\"CCO\")\n",
    "bsf = Biosynfoni(mol).fingerprint\n",
    "bsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsf_ext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
